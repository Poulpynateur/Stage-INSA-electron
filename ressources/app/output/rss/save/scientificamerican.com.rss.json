[{"authors":"Abraham Loeb","pub_date":"May 14, 2019","abstract":"On a recent trip, my flight home from Washington was delayed by a day  as a consequence of thunderstorms in the Boston area, and so I ordered a taxi to a nearby hotel. When I entered his car, the driver, named Nasir, asked: “Have you seen the recent image of black hole in M87 and heard about the discovery of an interstellar meteor just reported in the media?”\n\nIt took me no time to admit “as a matter of fact, I was involved in both studies”, and to follow with a dialogue about the related details and uncertainties. Even though my visit to D.C. in the preceding days focused on defining future priorities in the fields of physics and astronomy, this conversation was its highlight. What made this random encounter so uplifting? \n\nEarly in my career I noticed that my mentors regard interactions with the media as unnecessary and sometimes even damaging to the nature of scientific research. The rationale for this state of mind was that media coverage is often superficial and the public is not sufficiently informed and technically educated to weigh in with the scientific discourse in a meaningful way. In the spirit of “professional shoemaking should be left the those who know how to make shoes”, scientists should avoid the limelight as much as possible. \n\nLater in my career I realized that it is actually our duty as scientists to communicate results that are of interest to the public rather than stash them in the ivory tower of academia behind opaque walls made of technical language and complex equations.  There are three fundamental reasons for that. \n\nFirst, academic research is supported by the public through federal research grants as well as student and postdoctoral fellowships. In return, the public deserves to know what academia is doing with these funds. Widespread attention from the public has the benefit of providing feedback in highlighting topics that are of greater interest and relevance to the society we live in.  \n\nAn example of a research topic that is out of step with public interest and in need of such feedback is the search for alien technological civilizations.  About a quarter of all stars host rocky planets with surface temperatures similar to Earth’s, opening possibilities for a chemistry of life in liquid water. On Earth, the leap from a soup of chemicals to the first living cells was far more challenging than the transition from simple cell organisms to complex life. \n\nHence, it should be natural for astronomers to search for signs of both microbial and technological life as mainstream activities. Even if most extraterrestrial civilizations are dead by now, one can engage in “space archaeology” by searching for their relics in the form of radioactive products from a nuclear war, industrial pollution of planetary atmospheres, megastructures, photovoltaic cells on planetary surfaces or space debris of defunct technological equipment. \n\nDespite this natural expectation, there is a taboo on discussing the search for alien civilizations in the mainstream of astronomy, while the search for microbial life is considered legitimate. This state of affairs is in stark contrast to the public interest in both searches.\n\nSecond, the exposure to exciting scientific work could inspire kids all over the world to become scientists. The future of innovation rests on attracting the best minds to blue-sky scientific research. And there is also the broader benefit of enriching the appreciation of science for those curious kids who later become policy makers or business executives.\n\nThird, science communication serves the important purpose of educating the general public on the latest frontiers and breakthroughs. This, in turn, could stimulate industrial applications of scientific developments for practical use by inspiring technology entrepreneurs and innovators to establish new businesses.\n\nTextbooks portray a misleading impression that science is about well-formulated and agreed-upon results. But the reality “under the hood” is very different. Much of the scientific process involves a debate with multiple opinions arising from uncertainties and inconclusive evidence. Some of my colleagues argue that scientists should therefore be publicly silent and shy away from discussing ongoing research that is plagued with uncertainties. \n\nIn other words, scientists should have their debates behind closed doors until they reach consensus on their results. If the public notices scientific disputes, science will lose its credibility in the public’s eyes, and conclusive results such as “global warming” will not receive their deserved respect among policy makers.\n\nBut this argument goes against the idea of Socratic dialogue as a method for finding the answer to a question. For science to maintain credibility, it is crucial that we exhibit transparency to debating as its most fruitful phase. At its core, science is a human activity, and scientists often follow common sense and sometimes prejudice, just like detectives in a crime scene. \n\nWhen the scientific community reaches consensus on the basis of overwhelming evidence, its view will appear credible even more when contrasted with the more common phase of uncertainty. As long as the scientific process is honest and the pimples on the face of young research are not covered by makeup, the public will appreciate its authenticity. There is a condescending tone to the act of closing off the walls around academia, while keeping only distinguished professionals as part of the conversation before the discussion concludes and policy makers are approached.\n\nWith this attitude from scientists, it is only natural for populist movements to be suspicious of academia and consider it part of the elite whose deliberations are often hidden from view.  The public should not be approached as a passive audience but rather be engaged in an honest dialogue. \n\nWe live at a time when machine learning, artificial intelligence (AI) and social media threaten to replace the traditional Socratic dialogues among humans. These technologies advance so rapidly that a student asked me recently in class: “Will AI take over the scientific endeavor or will humans always be needed?” My answer was that data analysis and theoretical simulations are already carried by computers, but human innovation is still required in guiding the overall process. And given the need for humans, we should keep the public abreast with our latest scientific findings—since it is the entire reservoir of humans from which we should draw our best ideas to define our common future. \n\nWhat started as an unfortunate delay in my return home, ended up as a stimulating exchange with a taxi driver who provided inspiration for my future scientific projects. Honest dialogues add value to the sum of the independent parties engaged in them; they offer a win-win strategy to both science and society.","title":"Should Scientists Keep Their Private Debates Private?","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/5F9A14FE-D774-4C91-897F318F1A4C52F8_source.jpg?w=590&h=800&CB1BFC3E-DEA9-4E17-BB006451D63790D5","link":"https://blogs.scientificamerican.com/observations/should-scientists-keep-their-private-debates-private/"},{"authors":"Rachel Crowell","abstract":"Humans have long drawn inspiration from bird wings to design mechanical ones—and now a team of mathematicians has taken this biomimicry to a new level. By 3-D-printing a variety of wing shapes, racing them in a laboratory and feeding the data into an algorithm that simulates evolution, the researchers found that a teardrop-shaped wing is fastest for both flapping flight and swimming.\n\nThis is the first time such a combined process has been used to find an optimal wing shape for fast flight, says Leif Ristroph, a mathematician at New York University’s Courant Institute of Mathematical Sciences and senior author of the new study.\n\nSpecific aspects of the teardrop shape help to make the optimal wing faster than its competitors, Ristroph says. These include its front-to-back asymmetry (when viewed from the side), characterized by a rounded front, forward placement of its thickest point and a slender, trailing tail. The razor-thin back edge resembles that of a bird wing, which typically narrows to a single feather. The finding suggests birds’ wings have evolved to be as thin as possible, the researchers write in the study, which was published in January in the Proceedings of the Royal Society A.\n\nRistroph and his collaborators 3-D-printed a first “generation” of 10 plastic wings. They attached each wing to a motor-driven horizontal rod that caused it to flap up and down in water. They measured its swimming speed and extrapolated its flying speed. They tested a variety of shapes, including ones based on conventional airplane wings, flattened spheres and a peanutlike structure, Ristroph says.\n\nThe researchers fed the wing speed data into the evolutionary algorithm, which produced a second generation of eight “daughter” wings. Faster wing shapes were more likely to be passed on to the next generation, but the algorithm also allowed “mutations” that could yield new shapes. The two fastest wings from the first generation were also added to the second. The process of 3-D printing and laboratory racing was then repeated with the second generation of 10 wings. Altogether the researchers created 15 generations of wings. The fastest wing—the teardrop shape—evolved in the 11th generation and persisted in the following ones. The algorithm’s attempts to improve this shape in subsequent generations yielded ones that were too slender to 3-D-print.\n\nThe study “is tremendously interesting,” says Geoffrey Spedding, an aerospace engineer at the University of Southern California, who was not involved with the work. He notes that the optimal wing is “more like a fish fin,” which makes it better suited for swimming or propelling objects forward than for generating lift, as in airplane flight.","title":"Simulating Evolution to Determine the Fastest Wing","origin":"Engineering","image":"https://static.scientificamerican.com/sciam/cache/file/D5A4BFEF-E0F0-4AA6-B8F538395E8A83EB_source.jpg?w=590&h=800&A474CA2A-0C27-4637-B1BAAEAAEB35A7AF","link":"https://www.scientificamerican.com/article/simulating-evolution-to-determine-the-fastest-wing/"},{"authors":"Bob Hirshon","pub_date":"May 13, 2019","abstract":"The residue of ancient urine can reveal the presence of early, stationary herder-farmer communities.","title":"Ancient Whiz Opens Archaeology Window","origin":"Chemistry 60-Second ScienceSubscribe:Apple iTunesRSS","image":"https://static.scientificamerican.com/sciam/cache/file/B3C90CFD-5734-4C66-ADA95A18E37A8E4F_source.jpg?w=590&h=800&EC3ADCA4-58F6-447B-85EE16D30B7D9E9F","link":"https://www.scientificamerican.com/podcast/episode/ancient-whiz-opens-archaeology-window/"},{"authors":"Daniel Cusick, E&E News","pub_date":"May 13, 2019","abstract":"The swollen, churning, unrelenting river that’s flooding towns from Minnesota to Louisiana this month is not Mark Twain’s Mississippi River.\n\nSure, there were big floods during the 20th century, including historic tides in 1927, 1937, 1965, 1973, 1983 and 1993.\n\nBut the spring floods of 2019—which experts generally agree are the most damaging in 25 years—are among a new generation of Mississippi River crests that bear only passing resemblance to the floods of distant past.\n\nExperts say the new floods come faster and more furiously than their 20th-century counterparts. They last longer and are less predictable. And they cause more property damage, especially in the basin’s upper reaches where wetlands, forest and prairie have been replaced by subdivisions, office parks and drain-tiled farm fields.\n\n“As Dorothy said in 1939, ‘Toto, I have a feeling we’re not in Kansas anymore,’” said Gerald Galloway, one of the nation’s leading experts on Mississippi River hydrology and a professor of civil and environmental engineering at the University of Maryland, where he is an affiliate of the Center for Disaster Resilience.\n\nGalloway would know. In 1994, as a brigadier general in the Army Corps of Engineers, he led the interagency committee charged with identifying the root causes of the 1993 Mississippi River flood and proposing a long-term approach to floodplain management.\n\nThe 1994 panel, reporting to Vice President and future climate activist Al Gore, identified several key steps the federal government should take to reduce future flood risk: First, increase spending on levee repair, maintenance and security; second, improve coordination among federal, state and local authorities who oversee the river and its floodplain; and third, foster engagement with floodplain residents, farmers and businesses about how to mitigate risk from rising water.\n\n“Twenty-five years later, we’re still having the conversations. Unfortunately, not much has changed in the way we go about our business on the river,” Galloway said last week. As Gilbert White, a pioneer in U.S. natural hazards research, used to say, “‘The half-life of the memory of a flood is remarkably short.’ Once it’s past, we get back to regular business where potholes seem to eclipse levee failures,” Galloway said.\n\nBut where policy changes have been static, physical and environmental changes to the river have been ongoing. The climate is becoming warmer and more volatile, exacerbating known risks and creating new ones to the river’s environmental, social and economic health.\n\nThe most recent National Climate Assessment, for example, states that worsening flooding on U.S. rivers has caused “more long-term interstate freeway closures, while high and low extremes in water levels in the Mississippi River and other waterways have disrupted navigation and commerce.” Over the 21st century, between 5,000 and 6,000 bridges will be compromised from unprecedented flooding, while “increases in rainfall intensity can accelerate bridge foundation erosion and compromise the integrity and stability of scour-critical bridges,” the NCA said.\n\nCommunities may have little choice but to adapt, relocate or die, as the cost of living with chronic riverine flooding goes well beyond what many communities can afford.\n\nEarly estimates from AccuWeather place the damage from this spring’s Mississippi River floods at $12.5 billion, the equivalent of a $1 billion disaster for every riverfront city of 50,000 or more between St. Cloud, Minn., and New Orleans.\n\nThat compares with $21 billion for the 1993 Great Flood, according to a NOAA tabulation of billion-dollar weather and climate disasters since 1980. Adjusted for inflation, the 1993 flood would be a $37 billion event today.\n\nFrom 2000 to 2018, the Mississippi has experienced six major flood events—in 2002, 2008, 2011, 2014, 2016 and 2017, according to experts. Four of those were spring floods much like last week’s flood, fueled by a combination of snowmelt and spring rainfall.\n\nExperts who study climate change and river flooding say connections between the two phenomena have been less studied than other climate change imprints such as sea-level rise. Winter snowmelt and spring rains have always been part of life on the river.\n\nBut Andreas Prein, a climate scientist and expert on extreme weather events at the National Center for Atmospheric Research, made clear that extreme weather events are almost always spurred by anomalies in climate conditions, and the increased frequency and intensity of Mississippi River floods suggest that climate warming is at play.\n\n“Mississippi River flooding doesn’t occur from one day to the other, so there’s always a story involved with these types of major events,” Prein said last week. “In this case, we saw a record wet winter followed by a very wet spring and highly saturated soils.\n\n“This is already telling you something about atmospheric conditions,” he added, but it is difficult to separate climate warming from other variations in weather, such as El Niño-Southern Oscillation patterns that involve changes in water temperatures in the central and eastern Pacific Ocean.\n\nAccording to NOAA, the Northern Hemisphere is experiencing a persistent weak El Niño that could last through this summer, meaning warmer, wetter conditions will persist in the United States.\n\n“What we see from climate change is that these precipitation extremes are getting worse,” Prein said. “Climate attribution studies are trying to dig into that.”\n\nBut Prein and colleague Andrew Newman, an NCAR expert in hydrology and hydrometeorology, said land-use changes, stormwater flows and channelization of the Mississippi are “probably overwhelming climate change” as drivers of flood risk. Climate change, they said, acts like an accelerant on flood conditions.\n\nEither way, the Mississippi River “is a very different river today than we saw 80 years ago,” Prein said.\n\nLarry Larson, the co-founder and director emeritus of the Association of State Floodplain Managers, said that “there are all kinds of ways you can get flooded on major rivers,” but there’s no overlooking the frequency and intensity of recent precipitation events, especially in the lower and central Mississippi River Basin.\n\n“You add that rainfall to peak snowmelt coming down from places like Minnesota and Wisconsin, and there’s just no getting around it,” he said. “These rivers will stay up for weeks and weeks, and we have got to start talking about pulling back. You can’t keep that river pinched in. You’ve got to open it up and give the river some room.”\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"Today’s Floods Occur Along “a Very Different” Mississippi River","origin":"Natural Disasters","image":"https://static.scientificamerican.com/sciam/cache/file/AA788379-120A-4B09-A3BE1D87D7FD830B_source.jpg?w=590&h=800&1B3B0183-5D99-4B15-AEEDFCD52638F245","link":"https://www.scientificamerican.com/article/todays-floods-occur-along-a-very-different-mississippi-river/"},{"authors":"Rebecca Boyle","pub_date":"May 13, 2019","abstract":"On December 12, 1972, Gene Cernan parked his moon buggy in the southeastern edge of the Sea of Serenity, in a valley named Taurus-Littrow. A gray hill called the North Massif loomed in the distance. On its western side was a slumping escarpment, nicknamed the Lee-Lincoln scarp. It was a landslide, forming a low wall that seemed to cross the valley, like a shrug in a shoulder of the moon. Cernan and his seatmate, fellow astronaut Harrison “Jack” Schmitt, stared at it and snapped some pictures. \n\n“Hey, look at how that scarp goes up the side there,” said Schmitt, a geologist. “There's a distinct change in texture. Look over by Hanover [crater].”\n\n“Okay. Oh, man; yeah, I can see what you’re talking about now. It looks like the scarp overlays the North Massif, doesn’t it?” Cernan said.\n\n“Yeah,” Schmitt said. To Houston, he narrated what he saw: “The appearance you have of the scarp–North Massif contact is one of the scarp being smoother-textured, less cratered, and certainly less lineated. And I wouldn't be a bit surprised if it's, as Gene says, younger.”\n\nSchmitt meant that the scarp had formed after the mountain was raised. Something moved the mountain, in other words. Something deep within the moon had stirred, and its surface shifted.\n\nThis could have happened tens of millions of years prior. But at other locations on the moon, it is happening now. Scientists have for the first time connected seismic data to the changing lunar landscape, showing that the moon is tectonically active today and is building new outcrops and calving boulders in response. Regular moonquakes along a network of faults are energetic enough to rattle a moonwalking astronaut, and to shake the foundations of any future habitats, according to the new study, which appears in Nature Geoscience.\n\n“If you’re interested in an outpost, and you expect to be there for some time, you need to be mindful that if you are too close to one of these faults, your structure is going to be shaking,” says Tom Watters, a geophysicist at the Smithsonian Institution’s National Air and Space Museum.\n\nMoonquakes, Revisited\n\nDuring the Apollo era, seismic instruments left by Cernan, Schmitt and their predecessors showed that the moon experienced occasional quakes. These are mostly related to internal cooling and the tidal forces of Earth’s gravitational tug. And they were mostly deep within the moon, and not powerful enough to affect changes on the moon’s surface. \n\nWhen NASA’s Lunar Reconnaissance Orbiter (LRO) started taking high-resolution images in 2009, scientists realized the moon had numerous scarps like Lee-Lincoln, including many smaller ones just a few meters high. The latter are small cliff-like features, almost impossible to see from orbit, Watters says, and only LRO’s high-resolution cameras could make them out.\n\n“You can think of them as like stairsteps when you are coming up on them,” he says. “You’re not going to walk over one and not know it’s there, but if you don’t have the right resolution and the right lighting conditions, you’re not going to see them.” \n\nWith LRO’s high-resolution pictures, scientists started scrutinizing numerous scarps and counting craters, a proxy for figuring out a scarp’s age. In 2012, Watters figured out that the scarps and related features—long, thin valleys called grabens—formed recently, maybe as recently as 50 million years ago. \n\n“We were all converging on the idea that these things are really young. That always leads you to the intriguing possibility that maybe these things are still active, and maybe these faults are showing us current tectonic activity on the moon,” Watters says. “But we were sort of out of ways to really refine the ages.” And there was no way to connect moonquakes to changing surface features.\n\nTectonic activity on the moon—and Mars, for that matter—is not the same as it is on Earth. Our planet has plate tectonics, in which the Earth’s cracked crust dives down, melts and recycles itself. Collisions at the boundaries of Earth’s plates are the main cause of earthquakes, volcanoes, and seafloor spreading. The moon and Mars have no mobile plates, so the internal tremors are a result of interior heat. In the case of the moon, quakes happen because it is losing its primordial heat—literally, the warmth of its creation—and contracting as it cools. \n\nThe four Apollo seismic stations, which operated from 1969 until 1977, counted several deep quakes and just 28 shallower ones, some of which were equivalent to about a magnitude 5 tremor on the Richter scale. Renee Weber, a seismologist at NASA’s Marshall Space Flight Center, says the shallow quakes are more like those we experience on Earth. \n\nOnce LRO images showed multiple scarps—plus rock piles, landslides and other features that suggest the moon is shaking—she and colleagues decided to go back through the Apollo records, trying to tie specific moonquakes to features on its face. \n\nThe team had to perform a series of complicated calculations and simulations, in part because the Apollo records are so difficult to use. Apollo was the first time anyone tried to digitize seismological data, Weber says. What is more, the moon’s crumbly regolith dampens seismic waves, making them harder to trace back to their origin. \n\nAfter several years of analysis, the team was able to determine the epicenters of eight Apollo moonquakes, and tie them to specific faults observed with LRO. They were even able to correlate them to the moon’s orbital position around Earth, finding that more moonquakes occur during apogee, when the moon is at its most distant and Earth’s gravitational pull wanes.\n\nWhile the Apollo seismic data showed the moon was shaking and stirring, the LRO cameras were necessary to show how this internal turmoil was altering the surface, says Patrick McGovern, a lunar scientist at the Lunar and Planetary Institute in Houston who was not involved in the work. \n\n“Before something like LRO, we were blind to exactly how that was manifesting itself. The thing with LRO is that we can see all these fault scarps, and we can tie that together to the data from the seventies, to say how much activity there is and how it is distributed,” he says. “It was sort of like we had half the picture, and now we have the whole picture.”\n\nInterplanetary Seismology\n\nThe quakes happen because the moon is contracting as it cools, Watters and Weber say. Imagine an overripe piece of fruit: As the inside shrinks and dries out, the skin ripples and sags.\n\n“When you have a solid surface that is brittle, and you radiate heat, the planet will shrink. Cooling things shrink,” Weber says. “The surface kind of buckles, like a grape turning into a raisin. The surface area of the skin isn’t changing; it just gets convoluted and folded up on itself.” In other words, the shrugging scarp of Lee-Lincoln glimpsed by Cernan and Schmitt (and later by LRO) is a wrinkled grape skin, the result of one of these faults.\n\nCharting these and other recent moonquakes could shed more light on lunar history and structure, says Francis Nimmo, a geophysicist at the University of California, Santa Cruz, who was not involved in the new research. It could even aid scientists attempting to understand the origins of temblors elsewhere—namely, Mars.\n\nThe moonquake history comes as scientists are downloading the first sets of data from the InSight lander on the Red Planet, a seismology mission tasked with probing that world’s deep interior. So far, Mars seems to be slightly less seismically active than people expected. “One of the big differences between the moon and Mars is that tides are more important on the moon. The fact that the moon is seismically active may have a lot to do with the fact that it is being squeezed and stretched with these tides,” Nimmo says.\n\nWeber, who is an investigator on the InSight team, says she hopes future crewed or robotic landings could deploy a broader seismic network for long-term monitoring. Such a network could ensure the safety of any astronauts who follow in Cernan and Schmitt’s footsteps, according to McGovern. \n\n“It may turn out that it’s not the hugest deal, or it may turn out to be some places are safer than others,” McGovern says. Maybe Taurus-Littrow and the Lee-Lincoln scarp wouldn’t be the best place to revisit.\n\nOn December 13, 1972, the day after they studied the scarp, Cernan and Schmitt parked closer to the base of North Massif. At Geology Station 6, the duo clambered out near a great gray boulder, broken in half during its roll from the massif. It towered over Schmitt.\n\n“Hey,” he called to Cernan. “I'm standing on a boulder track. How does that make you feel?\" \n\n“Like I'm coming over to do some sampling,” Cernan said. He paused for a beat. “Think how it would have been if you were standing there before that boulder came by.” \n\n“I’d rather not think about it,” Schmitt replied.\n\nThat particular boulder had come by some 22 million years ago, according to later geochemical analysis. But Watters’ study shows that others like it could come by tomorrow—or anytime, shaken loose by the interior stirrings of a world that is still active, and in a way, still alive.","title":"Apollo-era Tremors Reveal a Dynamic, Active Moon","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/31742AEE-AFC6-460A-BD97862BE61A5FD3_source.jpg?w=590&h=800&F7466ED4-4DA3-4F8E-9ED033CC5B620D78","link":"https://www.scientificamerican.com/article/apollo-era-tremors-reveal-a-dynamic-active-moon/"},{"authors":"Ayana Elizabeth Johnson","pub_date":"May 13, 2019","abstract":"The third annual March for Science was in New York City on May 4. What follows here is my keynote speech about political attacks on science, the importance of safeguarding the role of science in policy making, the value of diverse scientists, the role of the ocean in the Green New Deal, and the critical need for building community around solutions.\n\nAs a marine biologist, a policy nerd and a Brooklyn native, I’m excited that the flagship March for Science this year is in my hometown. I am also glad to be here as one of the original leaders of the March for Science. I was national co-director of partnerships for the first march two years ago, building and coordinating a coalition of about 400 organizations advocating for the role of science in policy making.\n\nMy favorite sign from that first march was an umbrella (the weather did not cooperate then either) that had painted on it “Because of science we knew it was going to rain.” Scientists make the best signs. And many are continuing to stand up for science. Our power is in numbers, in coordinated efforts, in showing up for each other, in collaboration.\n\nI also served on the inaugural March for Science diversity committee to help ensure our movement was inclusive and welcoming. Because it matters who does science: Who the scientists are determines what science gets done. The fishing research I have done was most certainly informed by having a Jamaican father who showed me the cultural value of seafood, beyond its ecological and economic importance. Ocean Policy Lab, the think tank I am currently building, is focused on policy for coastal cities—because as a New Yorker I am deeply concerned by how woefully unprepared coastal cities are for the ravages of climate change, from sea level rise to strengthened storms.\n\nDiversity in science is not just for optics. We need scientists from diverse backgrounds in all senses of the word—race, ethnicity, gender, class, ability, geography, etc. Only this will ensure we are asking a diversity of research questions. And while we’re on the topic of diversity, to be honest, I’m sick of people being so damn surprised that someone who looks like me is a PhD scientist. This is what a scientist looks like.\n\nThe primary reason I march for science is to stand up for the critical role science plays in policymaking. As documented by the Union of Concerned Scientists, which is doing incredible work to track these abuses of power, in the last two years there were 80 significant attacks on science by the Trump administration—from halting or editing scientific studies that go against their political agenda, to politicizing who receives research grants, to restricting government scientists’ attendance at scientific conferences, to hampering access to data, to straight-up censorship. And then there is the silencing of science by simply leaving positions vacant. As of January, an unprecedented 43 top government science positions were unfilled.\n\n\n\tCredit: Union of Concerned Scientists\n\n\nAccording to a survey of federal government scientists, conducted by Union of Concerned Scientists with Iowa State University:\n\n\n\t50 percent of federal scientists say political interests have hindered their agencies' ability to make science-based decisions. Let me repeat that: Half of federal scientists report that politicians are messing with science.\n\t47 percent of scientists at the National Park Service and 35 percent at the Environmental Protection Agency report they had been asked to omit the phrase \"climate change\" from their work. That’s insane.\n\tUnsurprisingly, morale is down at these agencies.\n\n\nAnd then there’s what’s being done to scientific advisory committees. These committees are comprised of scientists who volunteer their time to be useful to the government. Serving on a science advisory board, serving as a peer reviewer for government reports, these are acts of patriotism. Yet these committees are being disbanded and compromised, or simply not having meetings.\n\n\n\tThe Environmental Protection Agency’s Scientific Advisory Board now has four times more industry representatives, compared to two years ago.\n\tThe Food and Drug Administration disbanded its Food Advisory Committee, whose advice had been relied on for 25 years.\n\tThe Department of Commerce disbanded the Advisory Panel for the Sustained National Climate Assessment, which had been doing the critical work of interpreting climate science for businesses, the public, and local governments.\n\tThe Center for Disease Control was prohibited from using the terms \"diversity,\" \"vulnerable,\" and \"science-based\" in their budget documents. Seriously. It’s wild.\n\n\nSo much damage has been done. There is so much to undo and rectify. Yes, people have been fighting back—writing public comments on proposed regulations, objecting to political appointments, politely protesting—but it remains an uphill battle, and maybe we need to be less polite. And definitely, we need use this next election to change who is in the White House and in halls of power across the nation.\n\nOne big opportunity with Congress is the Scientific Integrity Act. Introduced by Senator Brian Schatz of Hawaii and Representative Paul Tonko of New York, it would protect federal government scientists from political interference. We must to ensure this bill gets passed. Congress needs to step up. We must safeguard the role of science in policy making.\n\nAnd then there’s the science of climate change. There’s the abandonment of the United Nations’ Paris Agreement, which was based on global scientific consensus. There’s the National Climate Assessment that this administration released on the Friday after Thanksgiving, Black Friday, in attempt to bury it—but the scientific community refused to let that happen. There’s also the ample opposition to the Green New Deal from within both major political parties—without offering any robust alternatives that could actually address the scientific projections of our acceleration toward climate catastrophe.\n\nThe Green New Deal resolution is a 14-page document—double-spaced and large font; please everyone take 10 minutes to read it so we can all have an informed discussion about it and what the policy details to should be to make this aspirational document reality.\n\nAs a marine biologist, my particular interest in the Green New Deal is the massive role the ocean can play in both climate solutions and bolstering our economy if we (a) restore and protect coastal ecosystems, (b) invest in renewable offshore energy, (c) invest in the “blue economy,” and (d) vastly expand regenerative ocean farming.\n\nBecause of science, we know that marshes, wetlands, seagrasses and mangroves can absorb and sequester up to five times more carbon per acre than terrestrial forests. We know these ecosystems also provide better and less expensive flood and storm protection than seawalls. We know wetlands prevented $625 million in damages during Hurricane Sandy. We know poor communities and communities of color often bear the greatest brunt of the impacts from climate change–strengthened storms. We know that every dollar spent now to reduce risks from disasters will save around seven dollars in damages later.\n\n\n\tCredit: Ryan Muir.\n\n\nScience also tells us the importance of regenerative farming, farming that restores ecosystems as it grows food instead of degrading them. Regenerative farming can both draw down atmospheric carbon and support biodiversity—not just on land but also in the ocean. We know that growing seaweeds, oysters, clams and mussels near the coast would absorb tons of carbon, provide habitat, and buffer the impact of storm surges on local communities. We know a diet containing these shellfish has a lower carbon footprint than being vegan. We know adding seaweed to cows’ diets can reduce their methane emissions by nearly 60 percent.\n\nBecause of science, we know to anticipate three to 12 feet of sea level rise in the coming decades. We know this sea level rise could mean 13.1 million people in the U.S. will need to migrate. We know coastal states and cities are simply not prepared for what is coming, because we are not taking the science seriously.\n\nZooming out, from Project Drawdown, we know there are over 100 proven solutions to drawdown greenhouse gases and mitigate climate change. From Environmental Voter Project, we know that around 10 million registered environmentalists did not vote in the last presidential election, way more than enough to flip the outcome.\n\nSo let’s connect these dots, between the plethora of existing solutions and our collective political power. It’s not enough to be a scientist or to love science. We must be informed and active citizens. We must vote. We must campaign for candidates who value science. We must leverage the skills, dollars and networks we have. We must organize. We must follow the leads of the Youth Climate Strike and the Sunrise Movement. We must create broader and more diverse coalitions than we ever imagined possible. Most importantly, we must build community around solutions. Our climate, health, economies, safety and communities depend on it.","title":"We Must Defend Science in the Face of Political Attacks","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/5A997B9C-042E-4B1C-953DCD369A5562CB_source.jpg?w=590&h=800&B0F323E6-2F8A-402E-A6B931F98FA5EC37","link":"https://blogs.scientificamerican.com/observations/we-must-defend-science-in-the-face-of-political-attacks/"},{"authors":"John M. McLaughlin","pub_date":"May 13, 2019","abstract":"Back when I didn’t know squat, but had energy and naivete to spare, I started a school for students whose learning challenges, depression or anxiety made attendance at a large, comprehensive public high school problematic. They were also students traditional private and parochial schools didn’t want. A combination of 1960s social activism and a Fortune 50 executive father who drilled into me the value of self-employment drove me to borrow $2,000 from Commerce Union Bank, take an ad out in The Tennessean and hang out a shingle.\n\nThat was 1977. Jimmy Carter was president, Jimmy Buffett was singing Margaritaville and Jimmy Fallon was turning three. When the school year began, I had one student and no idea what I had stepped into. The Education for All Handicapped Children Act had not been implemented, America was not yet a nation at risk and “alternative education” had not been coined as a term of art for what I was doing. When spring came, I had 11 students, and 15 signed up for the coming fall. There was no looking back.\n\nSometimes, being dumber than a post, understanding there’s no way out but through, and believing in patience, kindness and curriculum, pays off. Over the last 42 years, the school has lifted the trajectory of several thousand lives, a mere drop in the bucket of alternative education.\n\nSome 650,000 students are enrolled in alternative public school education, according to the National Center for Education Statistics. There is no universal definition of alternative education. It means different things to different school districts. Uses for alt ed vary from short-term discipline to creative paths to graduation to a dumping ground. There’s an association for alternative education that brings teachers together annually to share what’s working in their schools.\n\nThere are also naysayers like the Southern Poverty Law Center, which sees alternative schools in some Southern states as racist tools. What’s clear, however, is that alternative education, no matter how it is used, has more than a toehold in public education.\n\nFor almost four decades, public schooling has been enmeshed in a reform movement. Initially driven by concern that students in other nations were surpassing American school kids’ performance in math and the sciences, reform has staked out as its major themes raising standards, increasing rigor and making a high school diploma more meaningful as an academic achievement. But along with higher expectations have come some unintended consequences.\n\nAmerica’s public high schools enroll just over 15 million students. As rigor has increased, so has the number of students pushed into the “at-risk” category. Generally, these students are overage, undercredited and several years behind in reading and math. Many have adult responsibilities, like children, siblings or parents for whom they care. Many hold jobs to help support their family. Some fight addiction. Others struggle with abuse, hunger, homelessness or exploitation.  At-risk students are the clients of alternative education.\n\nIt’s a reasonable estimate that at least 15 percent of our high school kids are at risk; that’s over 2 million lives. Not all at-risk students are in alternative education, but all alternative education students are at risk. Shorter school days, lower student-to-teacher ratios, credit recovery, attendance incentives, job training and mentoring are components of many successful alt ed programs. Does alt ed cheapen a diploma, or is it unfair to students who stick with the traditional path? I think not.\n\nAlmost 1,500 years ago, Benedict of Nursia wrote a simple book containing 73 rules that became the guideline for most Christian monasteries. Benedict emphasized the importance of rigor and standards. But he also stressed the importance of exceptions. Give monks what they need to pray and work, but make exceptions for the weak, the old and the disadvantaged. Public schools are not based on The Rule of St. Benedict, but alternative education is an excellent example of its wisdom. Have rigor and high expectations for students, but for those who need something else, provide it.\n\nWhile rigor and standards are always important, the challenges faced by at-risk students create a rigor of their own. It takes an adult level of determination to finish high school while nursing a baby, fighting addiction or lacking a permanent address. For public school districts to create alternative schools when they are needed is smart. To continually craft those schools for the maximum positive impact on their students is even smarter.\n\nSpring is the high-water mark for enrollment in alternative education programs.  They generally start with their lowest census in the fall, gain after the first report card and more after the semester change, and peak in spring as students, teachers and parents cling to options that keep graduation hopes alive. High school graduation is a major milestone in our society. Let’s have multiple routes to that milestone, reflecting the complexity of our society and the diversity of the rigors that define the lives of so many high school students.\n\nNote: a version of this piece originally appeared in the 74.","title":"Alternative Education: Rigor Redefined","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/F00923AE-5B98-4576-A45472DC2CB01E45_source.jpg?w=590&h=800&083C93DD-565B-4475-90CB000C13DE0D64","link":"https://blogs.scientificamerican.com/observations/alternative-education-rigor-redefined/"},{"authors":"Hanneke Weitering, SPACE.com","pub_date":"May 10, 2019","abstract":"Blue Origin is shooting for the moon!\n\nThe private spaceflight company revealed the first life-size mockup of its new lunar lander, named “Blue Moon,” at the Washington Convention Center yesterday (May 9). \n\n“This is an incredible vehicle, and it’s going to the moon,” Blue Origin founder and chief executive Jeff Bezos told a room full of spectators after the curtain dropped to reveal the big, shiny spacecraft. \n\nBlue Moon is designed to carry rovers and other large payloads to the lunar surface, but it could also take astronauts to the moon, said Bezos, who also founded Amazon.com and is the richest person in the world. To modify Blue Moon for a crewed spaceflight, the company would top the spacecraft with an attachable, pressurized ascent vehicle. \n\nBefore launching astronauts to the moon, Blue Origin would first test out the lunar lander with an uncrewed mission, Bezos said. \n\nWhile Bezos did not explicitly state that Blue Origin plans to offer its new vehicle to NASA for the agency’s ambitious push to land American astronauts on the moon in 2024, a newly posted description on the company’s website states that the crew-carrying variant of Blue Moon “has been designed to land an ascent vehicle that will allow us to return Americans to the moon by 2024.” \n\n(Blue Origin representatives had mentioned Blue Moon before, but they hadn’t given us a good look until this week.)\n\nNASA has not yet selected a lander for that historic trip, so Blue Moon may be a contender. Just last month, Lockheed Martin revealed its proposed plans to build a lunar lander. Lockheed’s lander (which has yet to receive a proper name) would be part of the company’s “early Gateway” infrastructure for a sustainable human presence on the moon.\n\nWhether NASA astronauts can really make it to the moon by 2024 is still a subject of debate, but a few things are certain: private companies and other space agencies around the world are gearing up for a new wave of lunar exploration, and Blue Origin has entered the new moon race. \n\nCopyright 2019 Space.com, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.","title":"Blue Origin Unveils “Blue Moon,” Its Big Lunar Lander","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/8B925766-F527-4324-B9A114CE76B766E8_source.jpg?w=590&h=800&55909832-0B53-4FEB-B3C6C74F72D592AA","link":"https://www.scientificamerican.com/article/blue-origin-unveils-blue-moon-its-big-lunar-lander/"},{"authors":"Sandro Galea","pub_date":"May 9, 2019","abstract":"This month, the world saw the first-ever image of a black hole. The picture was captured by the Event Horizon Telescope, a network of radio telescopes operated by a global team of scientists. The black hole is 53.49 million light-years away, at the center of the Messier 87 galaxy. Taking a picture of such a distant object was an immense feat of science and engineering. The roots of this achievement stretch from Einstein’s first theorizing about the existence of black holes, all the way to the creation of cutting-edge technology that allowed us to finally see one.\n\nSuch stories are reminders of why it sometimes feels like science can do anything, from exploring the cosmos, to peering into the distant past, to blurring the boundary between life and death. And that feeling often extends to the science that informs our health. On that front, the 20th century brought a host of major discoveries, from penicillin to the double helix. As the Digital Age ushers in new advances, it is as easy as it has ever been to imagine that science really can solve all our health problems one day.\n\nOur behavior suggests we may even hope that, through the power of science, we can one day innovate our way out of the human condition—the inevitability of age and death. Consider: the United States spends far more on health care than any other country in the world. The vast majority of this spending goes to the drugs and treatments that are the fruits of scientific discovery. With this sky-high spending have come sky-high expectations.\n\nWe eagerly await the drugs that will cure dreaded diseases like cancer and AIDS. We are fascinated by the evolution of precision medicine, with its possibility of tailoring treatment to an individual’s specific lifestyle and genetic code. And we thrill at the notion that technology might extend life indefinitely, that we can someday “hack” mortality, if we can only get the science right.\n\nThese hopes inform a spirit of exploration, one that we should nurture. Yet unbounded confidence in science can also distract us from the core forces that underlie our lives and health—forces far larger than any theorem, technology or cure.\n\nEach day, we are deeply influenced by the social, economic and environmental conditions that surround us. These conditions are at the heart of how our lives unfold, deciding whether we are sick or well. We must have the humility to acknowledge the influence of these forces. When we do not, we open the door to hubris, and risk undermining the very goals we accumulate knowledge to pursue.\n\nThere are ample examples of how we have neglected the foundational forces that shape health, even as we have poured resources into developing new treatments. Take asthma. If a child has asthma, science can indeed provide her with medicine for her illness. But why does she have asthma to begin with? Could it be because she is a child of color, a demographic with a higher asthma risk? Or because she grew up in an economically disadvantaged neighborhood, located near a pollution center like a major roadway, as such neighborhoods often are?\n\nOr could it even be because of political decisions to build the neighborhood in such an inopportune location? We are less likely to ask these questions when we think that the only action we need take to address an illness like asthma is to design ever-better treatments for it. While we often do not think of health in this way, we are effectively letting six million children live with a preventable disease like asthma because we are distracted by the flashy potential of high-tech science, at the expense of solutions that are at hand. \n\nWhat about the continued existence of HIV, a disease for which we have excellent treatments, but which nevertheless persists in some countries due to the forces of poverty, stigma and political negligence? In such cases, our medical advances are simply not enough. We need the humility to recognize that we cannot end these diseases without tackling forces that exist outside the realm of scientific innovation, whose influence can only be checked by collective effort and the application of political will.     \n\nThere is nothing wrong with making better medicines. A cure for asthma or HIV would indeed be welcome. But would it not be better to live in a world where these diseases no longer exist? To get this world, we must have the humility to see that there is more to health than our capacity to cure disease and extend life. Health emerges from our shared context—from the air we breathe, the water we drink, our economy, politics, schools, workplace safety laws, corporate practices and other large-scale influences.\n\nI discuss these influences in my new book, Well: What We Need to Talk About When We Talk About Health. Engaging with them, to improve health, means first recognizing their scope, how they are bigger than any one person, and that they can only be properly addressed when we work together, with humility.\n\nTake another look at the black hole image. It is a ring of light against vast darkness. This sliver of light, framed by the dark of space, is a useful metaphor for the relative smallness of what we know compared to the tremendous scope of what we do not. Our health, like our universe, is shaped by forces that dwarf even our most brilliant advances and discoveries. It is only by having the humility to recognize this that we can begin to move, collectively, towards a healthier future.","title":"Humility Is the First Step toward a Healthier World","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/FA118E13-9551-4DA8-B0F44BC85E8AC486_source.jpg?w=590&h=800&05000FA2-0B63-4D16-829C5FFC5B804862","link":"https://blogs.scientificamerican.com/observations/humility-is-the-first-step-toward-a-healthier-world/"},{"authors":"Evelyn Lamb","pub_date":"May 3, 2019","abstract":"Approximation is a recurring theme in mathematics. Sometimes it seems like all of mathematics is saying, “Well, I know how to solve the problem in this domain. Is there a way I can approximate other domains with this domain?” A lot of calculus boils down to approximating arbitrary functions with linear functions. (For our purposes, “linear” means “completely well-behaved.”) Fourier analysis, which forms the backbone of signal processing, is all about approximating complicated periodic functions with sums of simple sine waves. Scores of mathematicians spend their time thinking about what conditions allow us to approximate functions by simpler functions. A mathematical space called Swiss cheese is yet another example of the ubiquity of approximation.\n\nLike the deli counter staple, mathematical Swiss cheeses are full of holes. To make a Swiss cheese, we start with a closed disc or filled-in circle, the set of all points in the plane that are less than or equal to a given distance (the radius) from a central point. \n\n\n\t\n\t\tWhat a lovely, cheesy disc! Credit: Evelyn Lamb\n\t\n\n\nNow we punch it full of holes in a particular way. We want to remove open discs (filled-in discs, but without their boundaries), and we have some rules about the removed discs. If you look up definitions of Swiss cheeses in math, you will see a various definitions, but just like Emmentaler and Gruyére, they are just different particular varieties that all count as Swiss cheese. \n\nThis being theoretical math, we remove an infinite number of discs, but we require that the sum of the areas of the removed discs is less than the area of the original disc (often quite a bit less), that no two removed discs overlap, and that the resulting space has no interior. That is, if we zoom in on any part of the space, no matter how small, there are holes in it. It’s hard to imagine such a space (and impossible to draw it, which didn't stop me), but there are ways to make sure the definition works mathematically.\n\n\n\t\n\t\tAn approximation of a mathematical Swiss cheese. It's very difficult to draw a picture with interesting features at arbitrarily small scales. Credit: Evelyn Lamb\n\t\n\n\nSwiss mathematician Alice Roth, the first person to describe these spaces, was trying to understand the limits of approximations of continuous functions by rational functions in the complex plane. A rational function is the ratio of two polynomials. Polynomials might be familiar to you from algebra classes. They are some of the simplest and easiest to understand functions. They have expressions like z+5 or z3-9z+7. Rational functions have expressions like (z3-9z+7)/(z+5).\n\nIs it always possible to approximate continuous functions by rational functions, or are there some spaces where this fails? Roth and other mathematicians showed that there are continuous functions on Swiss cheeses that cannot be approximated by rational functions.\n\nI am both a mathematician and a lover of cheese, so when I first heard that there were mathematical objects called Swiss cheeses, I was intrigued. The related research paper titles were delightful. Abstract Swiss Cheese Space and the Classicalisation of Swiss Cheeses. Swiss cheeses, rational approximation and universal plane curves. On the volume of the intersection of two Wiener sausages. (That last paper describes Swiss cheese-related calculations on another punny mathematical space called a Wiener sausage. Mathematicians like food.) Everything about this was relevant to my interests. When I learned about the history of the name, it got even better.\n\nWhen she first described them, Alice Roth did not use the term Swiss cheese. As far as I can tell, she didn’t name them anything in particular. She used them as an important example in her doctoral thesis at the Swiss Federal Institute of Technology in Zürich, won an award for that thesis, and graduated with her Ph.D. She had a thirty-year career as a high school teacher, during which she did not publish any mathematical research. After retiring, she jumped back into research, still in the same field she had studied thirty years before, and continued doing important work in her late 60s and early 70s. (Take that, G. H. Hardy and your “math is a young man’s game” nonsense!) Sadly, she died of cancer at age 72, while she was still full of mathematical creativity and enthusiasm.\n\nDuring Roth’s teaching career, while she was absent from the research world, Swiss cheeses were rediscovered independently in the 1950s by Soviet-born Armenian mathematician Sergey Mergelyan, who constructed them for similar reasons, probing the limitations of approximation in various settings. At some point, because of all the holes, someone started referring to them as Mergelyan’s Swiss cheeses. When Roth returned to research, she saw her examples attributed to Mergelyan in publications and corrected the record. The name Swiss cheese turned out to be even more appropriate than the person who coined it could have realized.\n\nFor more on Alice Roth, her Swiss cheese, and her other contributions to approximation theory, check out “Alice in Switzerland: The Life and Mathematics of Alice Roth” by Ulrich Daepp, Paul Gauthier, Pamela Gorkin, and Gerald Schmieder.","title":"The Serendipity of Swiss Cheese","origin":"Roots of Unity","image":"https://static.scientificamerican.com/blogs/cache/file/427AD491-3876-431F-9CA35E53EC6F19A4_source.jpg?w=590&h=800&A8960A06-8DE4-4DC6-A7DAD9E0273D1D5B","link":"https://blogs.scientificamerican.com/roots-of-unity/the-serendipity-of-swiss-cheese/"},{"authors":"Steve Mirsky","pub_date":"May 13, 2019","abstract":"In the first chapter of the new book Upheaval: Turning Points for Nations in Crisis, author Jared Diamond describes a crisis of his own. He was 21 and had always excelled academically—until he entered a doctoral program in physiology at the University of Cambridge.\n\nDiamond was charged with measuring the movement of sodium and potassium ions across the electricity-generating membranes of eels. But he had never been good with his hands and was utterly unable to design and build the equipment he needed to perform that task.\n\nSo Diamond switched to a technically easier assignment, which required simply weighing a fish gallbladder to determine its fluid content, then measuring a voltage. But even this simple method to analyze sodium and water transport gave him fits, as no voltages appeared. He seriously considered quitting and finding another career, but decided to give it one more semester.\n\nTwo young faculty researchers helped Diamond solve his technical issues, and he started to get results. He went on to finish his PhD and reinvent himself as an ornithologist and historian. More than 50 years later he is an internationally recognized scientist and writer, having won the U.S. National Medal of Science, a MacArthur Foundation fellowship (commonly called the “genius grant”) and a Pulitzer Prize for his book Guns, Germs and Steel: The Fates of Human Societies. His youthful failure was in fact a springboard.\n\nI have not achieved Jared Diamond’s level of success, but I strongly relate to his story. As Digital Science is running a social media campaign about acknowledging and learning from failure (you can share your own failures with #failtales), I thought I’d tell my story.\n\nI too had a history of academic achievement. I finished an undergraduate degree in chemistry and was accepted at Cornell University for graduate school. The chairman of the chem department was Roald Hoffmann, who had recently won the Nobel Prize and who was my advisor during my first semester. I later chose an advisor with whom I planned to do research for a doctoral thesis.\n\nGraduate school was a shock to my system. For the first time in my life, I hit a wall in my ability to understand information I was expected to digest. I found it increasingly difficult to concentrate on my work and became depressed.\n\nSo I played hooky. And where was the perfect place to not work while looking like one was working? Why, the library. My own science was going nowhere, but I still loved science. So I started reading science magazines. Stephen Jay Gould was writing his monthly columns in Natural History, and I became fascinated with evolutionary theory. I could hardly wait for the next issue of the New Yorker that featured another installment of a five-part series by E.J. Kahn about staple foods—which 35 years later I still remember were corn, wheat, potatoes, soy and rice. And from Scientific American I read articles about everything.\n\n(A few years ago I saw the Kahn staple-food series described as one of the most tedious pieces of magazine journalism every published. I laughed, because for me they were as thrilling as reading Dumas: corn was The Count of Monte Cristo, wheat was The Three Musketeers.)\n\nOne day at the beginning of the second semester of my second year of grad school, I was browsing through an issue of Science when I saw an advertisement for a Mass Media Science and Engineering Fellowship from the American Association for the Advancement of Science. Graduate students in the sciences who received the fellowship would spend the summer at a newspaper, magazine, radio outlet or television outlet as science reporters. I remember reading the ad and thinking, “Weird.” But the next day I looked at the ad again and thought, “Wait. This is what you should be doing.” I applied for and got the fellowship, along with about another 15 grad students around the country.\n\nI announced that I would be leaving Cornell at the end of the semester to do the fellowship and then pursue a career in science journalism. I could take oral exams for a “terminal” Master’s Degree. I studied my butt off and fortunately closely reviewed some material that I was actually asked about during the three-hour ordeal. I got the degree, which I often think of as the “lovely parting gift” that unsuccessful contestants received on game shows. Hoffmann asked me to reconsider leaving the program, but I was sure I was doing the right thing, for me. I left a couple of days later for my fellowship site, WSVN-TV in Miami. After two winters in upstate New York, I would spend the summer of 1985 in south Florida. (I can’t recommend either.)\n\nI took to science journalism—it fulfilled my terms of gratification. The journalist David Epstein exactly captured my feelings in his new book Range: “I worked in labs during and after college and realized that I was not the type of person who wanted to spend my entire life learning one or two things new to the world, but rather the type who wanted constantly to learn things new to me and share them.” Bingo!\n\nWhile in Miami I saw another ad, this one in Broadcasting magazine, advertising an on-air position opening at a small radio station back in upstate New York. I had always loved radio—as a kid I listened to Jean Shepherd, Barry Farber and Big Wilson, names that may ring a bell to a certain demographic—and I parlayed my summer TV gig into a year as a radio morning man. I got a job offer at a 50,000-watt station in Albany, but turned it down to go home to New York City and try writing for print.\n\nI eventually applied for a job at Scientific American—which I did not get. But a few years later I started freelancing for SciAm and then was hired as a writer and editor. I have been writing a monthly column in the magazine for more than 23 years. (Gould did his at Natural History for 25 years, a mark I hope to equal.)\n\nThe radio experience came in handy when, in 2005, Scientific American decided to start podcasts and asked me to head up that effort. We have now produced more than 4,000 episodes of our short podcasts, primarily 60-Second Science, and almost 500 of the in-depth Science Talk.\n\nI kept in touch with Roald Hoffmann over the years. At one point I ran into him at an event in New York City where an acquaintance of mine attempted to introduce us. Roald stopped my friend and said, “Oh, I know Steve. He’s one of our most successful failures.”","title":"If At First You Don't Succeed","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/64434CF6-863F-4716-B814445485156197_source.jpg?w=590&h=800&FF2AC74D-512E-4EC4-A9E7DF7C284DA72A","link":"https://blogs.scientificamerican.com/observations/if-at-first-you-dont-succeed/"},{"authors":"Ralph Nader","pub_date":"May 9, 2019","abstract":"“Fundamental Canon No. 1” of the American Society of Engineers states that “Engineers shall hold paramount the safety, health, and welfare of the public.” Most engineering societies have this principle in their codes of ethics. This duty frames the decades of struggles by conscientious engineers—whether employees or consultants—who strive to balance professional ethics with occupational survival.\n\nCompared to the technologically stagnant dark days in the auto industry of cruel suppression of technical dissent over safety and toxic emissions, a censorship that carried over to the industry-controlled Society of Automotive Engineers, today’s engineers are working in an improved environment for taking their conscience to work. Yet much more remains to be done to safeguard the ability of engineers to speak truth to the powers-that-be.\n\nFor starters, the word whistle-blower—once popularly meant to describe a snitch or a disgruntled employee—now describes an ethical person willing to put his or her job on the line in order to expose corrupt, illegal, fraudulent and harmful activities. Indeed, in the aftermath of recent Boeing 737 MAX crashes, the media routinely and positively refers to disclosures by “Boeing whistle-blowers.” Congressional investigating committees and federal agencies have called for whistle-blowers to come forward and shed light on corporate misdeeds and governmental agency lapses.\n\nTo put it mildly, this was not always the case. In 1971, I convened the Conference on Professional Responsibility—a sober name for a group of whistle-blowers from corporations, government and unions. They were ragged as “malcontents” or “occupational-suiciders.” In fact, they were courageous, accurate, morally right, and willing to lose everything to expose wrongdoing.\n\nKeynoters at the whistle-blower conference were Senator William Proxmire, who protected government whistle-blowers on military defense issues, and Robert Townsend, author of the best-selling Up the Organization. Townsend drew from his business experience to explain the critical role whistle-blowing could play in giant corporations. Law Professor Arthur Miller reviewed the lack of legal protection and vulnerability of whistle-blowers and presented what the law should provide “in its institutions and principles.” (See Whistle Blowing: The Report of the Conference on Professional Responsibility, by Ralph Nader, Peter Petkas and Kate Blackwell, 1972).\n\nAfter this watershed conference, much began to change. Numerous health and safety statutes now protect government employees who report noncompliance with environmental, worker safety and labor standards. Starting in 1978, a Merit System Protection Board was established and later strengthened under President George Herbert Walker Bush to give federal employees some, but not enough, due process against retaliation. Several states followed with their own whistle-blower protections.\n\nIn 1977 an NGO called the Government Accountability Project (GAP) started offering pro bono representation to many government and corporate whistle-blowers. After the enactment of the 1986 False Claims Act, federal employees exposing fraud against the government were able to secure a sizable portion of any resultant verdict or settlement against those ripping off the taxpayers. This law alone has recovered over $60 billion from the fraudsters. Private law firms and the Justice Department are regularly involved in pursuing these claims.\n\nThe vast world of state and federal procurement/military contracts and infrastructure is known to be rife with “waste, fraud and abuse.” Engineers are most likely to see such violations first. Decades ago, foreshadowing the many challenges in engineering, the Society of Professional Engineers, in its code of ethics, instructed engineers on their obligation to report safety and fraud violations to the appropriate outside authorities, should they find no recourse inside their place of employment.\n\nWith $5 trillion of deferred maintenance for our public works, as measured by the American Society of Civil Engineers, the challenges to the assertion of engineering conscientiousness will be ever larger.\n\nWe need more public interest engineering advocacy groups and initiatives to open up new frontiers of excellence and service as well as to support engineers inside the corporate framework. It was a Caltech professor, Arie Jan Haagen-Smit, not GM engineers or chemists, who proved in the 1950s the connection between motor vehicles and the lethal photochemical smog over the cities and suburbs of California. This led to smog-control regulations and ethical and legal foundations for industrial air pollution controls.\n\nEngineer Ralf Hotchkiss, rendered a paraplegic before college, courageously revolutionized the functional and economical design of superior wheelchairs, including showing natives how to utilize local materials in poor countries. He also helped break the virtual wheelchair monopoly of a British multinational company in the process. We need more engineers who embody the three principles of any profession—independence, scholarly pursuits, and commitment to public service. Those are the vital ethical pillars to helping engineers withstand the great pressures to place commercial priorities over their engineering integrity and limit harm to the public. We see the push to relegate engineers to indentured status in industries such as the chemical, nuclear, weapons systems, mining, auto, aviation, railroad and medical devices industries, as well as the new unregulated areas of biotechnology, nanotechnology and artificial intelligence.\n\nThere has been progress in legal protections for whistle-blowers, more civil litigations and, importantly, higher public expectations and popular support for these unsung protectors. There is, however, much more work to do, especially in educating the engineering school curricula and encouraging the numerous engineering societies to take their codes of ethics seriously. But as Nassim Taleb, author of The Black Swan, has written, “Mental clarity is the child of courage, not the other way around.”\n\nIn 1966, in an address to a chapter of the American Society of Engineering Education (reprinted in the new book Ethics, Politics, and Whistleblowing in Engineering, by Nicholas Sakellariou and Rania Milleron [my niece], CRC Press), I said “the [engineering] profession must assert itself towards its most magnificent aspirations—for so much of our future is in your trust.”\n\nWell, isn’t that a great understatement today!?","title":"When Engineers Become Whistleblowers","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/75FD8177-0CC5-4829-BEBE66F3248FBBB7_source.jpg?w=590&h=800&C9D7CD35-1DEE-4719-9C05247151A6C23F","link":"https://blogs.scientificamerican.com/observations/when-engineers-become-whistleblowers/"},{"authors":"Caleb A. Scharf","pub_date":"April 25, 2019","abstract":"As scientific fields go, both physics and cosmology arguably get to have the most fun. I don’t mean in terms of day-to-day humdrum research, but in terms of speculation at the frontiers of knowledge.\n\nConsider for example the pleasures of the multiverse. The harder astronomers work to pin down the fundamental parameterizations of the cosmos, from its matter contents to its ordinary energy and dark energy, the more it looks like a reality borne from the physics of inflation. This is a phenomenon that produces exponential expansion of space, resulting in the noise of quantum fluctuations on teeny tiny scales ending up as the seeds of structure on cosmic scales – like galaxies and stars. It also propels a universe towards a spatially flat geometry. And inflation, as we currently think of it, seems to almost inevitably lead to many, many, many universes. \n\nThat’s fun (in the loosest definition of that term) because with enough physical realities maybe there really are repeats of everything that we know – right down to you, your dog, what you had for breakfast, and the text of this article that you’re reading right now.\n\nThen there are more philosophically motivated arguments that perhaps our universe is the result of experimentation or deliberate simulation. Maybe it was born in a super-powerful particle accelerator out of something like an inflating, energetic monopole, or in a hugely advanced quantum computer capable of modeling an entire cosmos of atoms and photons. In either case the line between real and unreal is irrevocably blurred. For example, to simulate a universe that exhibits the mind-boggling complexity that we experience – or think that we experience – requires the construction of a model that is pretty much as mind-bogglingly complex and physical as if it actually existed as a mind-bogglingly complex and physical reality.\n\nThere are even arguments for why it is actually quite likely for us to be ‘inside’ such a simulation (where ‘quite likely’ is philosopher-speak for ‘who knows, but it’s good for the lecture circuit’). Specifically, even if only a very few species (assuming an external physical reality like the one we experience) are sophisticated enough to construct a universe simulation, they might end up running huge numbers of such simulations. Perhaps to explore the lives of their ancestors, or perhaps to show off to the neighbors. \n\nIn all cases, the consequence of there being vast numbers of simulated realities would be that it is far more likely that you are simulated than real – it’s just a numbers game. Indeed, since we are not yet technologically sophisticated enough to build such models the odds may be even greater that we are in fact a simulated ancestor species. \n\nBut whether this is a simulation, or a bona-fide physical reality produced by someone’s laboratory tinkering, an important question is raised.\n\nThat is: why aren’t things a bit better?\n\nI mean, come on. A universe with an accelerating cosmic expansion – as we seem to have - is astonishingly inconvenient. In a few hundred billion years it will become extremely difficult, if not impossible, for a sentient species to make any kind of meaningful sense out of the cosmos – as distant matter becomes effectively unseeable due to the expansion of spacetime. There are other issues too. Already the rate of star formation has dropped to a mediocre level, ensuring a future consisting mostly of dismal little red dwarfs and few new planets. And what about the peculiarities of physics – from quantum mechanics to thermodynamics and all of this ‘emergent phenomena' stuff? Honestly, it does seem a bit patched together.\n\nWhich brings me to a disquieting conclusion and new twist to the idea that we might exist within a manufactured universe. Even for some hyper-advanced intelligent species, building or simulating universes would have to be quite costly in terms of resources. Therefore, it’s not unreasonable to expect that some corners have to be cut, some expenses kept under control. \n\nI’m reminded of the legend of the dry comment often attributed to the astronaut Alan Shepard when asked how he felt sitting atop an enormous rocket about to blast off to space. His response was (with some likely paraphrasing added over the years) “I just kept looking around at all those dozens of instruments in front of me and reminding myself that every one was supplied by the lowest bidder.” \n\nPerhaps this is indeed the ultimate answer to why our universe is a little squirrely. While it is remarkable how well much of it can be understood – albeit with centuries of effort on our part – in other respects it is also highly resistant to being easily decoded. Built by the lowest bidder it would suffer from some corner-cutting, some inconsistencies and illogical quirks. \n\nAnd that leads to the ultimate question, the one that we all seek the answer to. \n\nHow do I get in touch with customer service?","title":"The Lowest Bid Universe","origin":"Life, Unbounded","image":"https://static.scientificamerican.com/blogs/cache/file/AEBD30B0-065B-4003-9107B8672FDED09C_source.jpg?w=590&h=800&F547C62E-DB43-43FA-97F9D4286B14D052","link":"https://blogs.scientificamerican.com/life-unbounded/the-lowest-bid-universe/"},{"authors":"Susana Martinez-Conde and Stephen L. Macknik","pub_date":"May 7, 2019","abstract":"The man and the woman sat down, facing each other in the dimly illuminated room. This was the first time the two young people had met, though they were about to become intensely familiar with each other—in an unusual sort of way. The researcher informed them that the purpose of the study was to understand “the perception of the face of another person.” The two participants were to gaze at each other’s eyes for 10 minutes straight, while maintaining a neutral facial expression, and pay attention to their partner’s face. After giving these instructions, the researcher stepped back and sat on one side of the room, away from the participants’ lines of sight. The two volunteers settled in their seats and locked eyes—feeling a little awkward at first, but suppressing uncomfortable smiles to comply with the scientist’s directions. Ten minutes had seemed like a long stretch to look deeply into the eyes of a stranger, but time started to lose its meaning after a while. Sometimes, the young couple felt as if they were looking at things from outside their own bodies. Other times, it seemed as if each moment contained a lifetime. Throughout their close encounter, each member of the duo experienced their partner’s face as everchanging. Human features became animal traits, transmogrifying into grotesqueries. There were eyeless faces, and faces with too many eyes. The semblances of dead relatives materialized. Monstrosities abounded.\n\nThe bizarre perceptual phenomena that the pair witnessed were manifestations of the “strange face illusion,” first described by the psychologist Giovanni Caputo of the University of Urbino, Italy. Urbino’s original study, published in 2010, reported a new type of illusion, experienced by people looking at themselves in the mirror in low light conditions.\n\nAs we noted in an ensuing Scientific American Mind article,\n\n“Caputo asked 50 subjects to gaze at their reflected faces in a mirror for a 10-minute session. After less than a minute, most observers began to perceive the “strange-face illusion.” The participants’ descriptions included huge deformations of their own faces; seeing the faces of alive or deceased parents; archetypal faces such as an old woman, child or the portrait of an ancestor; animal faces such as a cat, pig or lion; and even fantastical and monstrous beings. All 50 participants reported feelings of “otherness” when confronted with a face that seemed suddenly unfamiliar. Some felt powerful emotions.”\n\nIn his subsequent research, Caputo observed that the strange face phenomenon was not limited to one’s face reflected in the mirror, but it extended to other people’s faces, in situations where pairs of experimental participants gazed at each other for sustained periods of time in a dimly lit room. \n\n\n\tExperimental setup. Credit: Drawing by Alberto Conti\n\n\n\n\nMost recently, in a study published last month in the Journal of Trauma and Dissociation, Caputo sought to test a large sample of participants, which comprised 90 healthy young adults. Notably, the participant population included 15 portrait artists, who were able to produce artistic depictions of their perceptual experiences at the end of the experiment. Four of such portraits are included below: a stranger with eyewear, a monkey-woman, an alien face, and a cartoonish human-rabbit face.  \n\n\n\tFour examples of strange-face illusions sketched by portrait artists: (a) Stranger with eyewear, (b) Monstrous monkey-woman, (c) Alien face, (d) Cartoon-like human-rabbit face. Credit: Giovanni Caputo\n\n\nThe mechanisms underlying the strange face illusion remain somewhat obscure. The perceptual vanishing of objects and scenes during prolonged gazing, known as Troxler fading, could be part of the explanation. When we stare at an unchanging face for a long time (our own face in the mirror, or the face of the person sitting in front of us), our visual neurons decrease their activity, making facial features fade and disappear (and then reappear when we blink or move our eyes). In the absence of such visual information, our brain is bound to “fill in” the gaps according to our neural wiring, expectations, and experiences—sometimes with fantastical results. \n\nFuture research may offer a more complete picture of why the strange face illusion arises. In the meantime, you may want to avoid candle-lit romantic dinners—or looking too long into the eyes of your beloved.","title":"Locking Eyes with a Monster","origin":"Illusion Chasers","image":"https://static.scientificamerican.com/blogs/cache/file/8920FEFD-183D-4CF9-84230C2D69E1B285_source.jpg?w=590&h=800&11360235-E9E8-4B5A-8FB3EE0168C8F33C","link":"https://blogs.scientificamerican.com/illusion-chasers/locking-eyes-with-a-monster/"},{"authors":"Meredith Bashaw, Stephanie Allard","pub_date":"May 10, 2019","abstract":"I yawn and stretch, then climb to the top of the moss pile to soak up some warmth. Next I’ll check out that spot by the water where I found those yummy bugs yesterday. It’s shaping up to be another good day.\n\nThe critter above is a Houston toad (Anaxyrus houstonensis), an endangered species of amphibian. He lives at the Houston Zoo and is part of a zoo-based breeding program called the Houston Toad Recovery Project.\n\nThere sometimes exists a public perception that zoo animals live in sterile cages and suffer unrelenting boredom or even fear. Historically, zoos were created primarily for entertainment purposes and simply prioritized keeping animals visible and habitats clean. While this does help visitors see animals and animals stay healthy, it isn’t sufficient for allowing animals to lead rich and fulfilling lives. Fortunately for both human and nonhuman animals, modern accredited zoos and aquariums like the Houston Zoo hold themselves to higher standards.\n\nAccredited zoos agree to undergo voluntary review by a panel of industry experts to ensure that everything from their financial security to their animal care is state of the art. These zoos and their accrediting organizations have become focused on animal well-being, recognizing that animals in their care need to thrive rather than just survive.\n\nThey also increasingly include conservation in their mission statements and contribute expertise, time and funding to supporting that effort. Accredited zoos have transformed their operations to benefit animals in their care and in the wild, while still providing the public a fun, awe-inspiring experience.\n\nHow do they achieve such lofty goals? Increasingly, they use science. Between 1993 and 2013, zoos and aquariums accredited by the Association of Zoos and Aquariums (AZA) published 5,175 peer-reviewed scientific manuscripts on a wide array of topics, including animal care and conservation.\n\nZoos and partner organizations conduct animal welfare research to evaluate how animals in their care see (or hear or smell) the world and what behaviors motivate them. Keepers then find innovative ways to enrich animals’ lives by creating opportunities for these skills and behaviors. For ectothermic animals like reptiles and amphibians, thermoregulation and foraging are highly-motivated behaviors, so creating opportunities for these behaviors improves well-being.\n\nThe Houston toad above, for instance, isn’t simply hand-fed a diet of bugs. Instead, the zoo simulates the same processes the toad would need to perfect in order to find food in the wild, placing bugs inside crevices and other hiding spots.\n\nFood puzzles use that concept to give carnivores mental and physical exercise, as well as the thrill of the hunt. Zoos recognize that while achieving a goal—like getting food—is valuable to animals, so is the process of using their skills to reach that goal. As a result, zoos increasingly design environments to empower animals to make meaningful choices about what to do, when, and with whom and to enable them to exert some control over their surroundings.\n\nWhile animals are already reaping the benefits of advances in research and zoo design, there’s still much we don’t know about how animals of different species perceive their environments and what they value. As research improves our understanding of animals’ perspectives, zoos will need to stay nimble and continually improve so that every animal in their care can thrive.\n\nZoos also conserve wildlife and wild places around the world. Zoos accredited by the AZA spent more than $200 million on field conservation initiatives in 2017, and zoos belonging to other regional accrediting organizations are also active in conservation. AZA zoos’ efforts benefitted 863 species in 128 countries, including the Houston toad.\n\nThe Houston Zoo first started breeding Houston toads to supplement the wild population in 1978. The zoo reestablished an “assurance population” in 2007; the captive colony maintained by the institution ensures that prolonged drought, wildfires, highways and development won’t result in these toads’ extinction. Today, the Houston Zoo partners with the U.S. Fish and Wildlife Service, the Texas Parks and Wildlife Department, Texas State University and the Fort Worth Zoo to breed Houston toads and restock local ponds; in 2017 alone, the Houston Zoo released 930,000 captive-bred eggs into the Houston toad’s native habitat.\n\nThese types of programs are critical to safeguarding species in the wild. Biodiversity is threatened around the globe, with amphibians in particularly acute crisis. It is imperative that zoos continue to strengthen their conservation efforts. Captive toads in the Houston Zoo’s breeding program won’t necessarily make their way back into the wild, but their kids will.","title":"Modern Zoos Aren’t Just for Entertainment","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/458BEFED-D86E-48F7-86D3DF5BF530BA9E_source.jpg?w=590&h=800&0C1E1DC7-610C-4AE7-97C6EA033BDA38D2","link":"https://blogs.scientificamerican.com/observations/modern-zoos-arent-just-for-entertainment/"},{"authors":"Jonathan O'Callaghan","pub_date":"May 13, 2019","abstract":"This Wednesday SpaceX will launch its first batch of Starlink satellites—a “mega constellation” of thousands of spacecraft to provide high-speed Internet access to billions of people at any location on the planet. Starlink is only the first of many such projects; there are at least eight more mega constellations in the works from other companies. Although they promise to revolutionize global telecommunications, these efforts are not free of peril: as the number of satellites inexorably grows, so, too, does the risk of creating dangerous debris that could threaten the continued safe use of Earth orbit. “This is something we need to pay attention to,” says Glenn Peterson, a senior engineering specialist at the Aerospace Corporation, headquartered in El Segundo, Calif. “We have to be proactive.”\n\nToday Earth orbit is a busy place. Almost 2,000 active satellites whiz around our planet, along with nearly 3,000 dead satellites and 34,000 pieces of “space junk” larger than 10 centimeters in size. Whenever debris or a defunct spacecraft gets too close for comfort to an active satellite—typically when a collision risk rises to one part in several thousand—the satellite’s operator must perform a collision-avoidance maneuver. The International Space Station, for example, is moved when the chance of a collision isgreater than one in 10,000.\n\nThese close encounters already occur thousands of times each year, but the sheer vastness of mega constellations such as Starlink will change the game, resulting in an estimated 67,000 annual collision-avoidance maneuvers if all of them are launched. As Earth orbit becomes jam-packed with satellites, the risk increases. A worst-case scenario would be the Kessler syndrome, a positive feedback loop in which debris-generating collisions create more and more collisions, which in turn create more and more debris, rendering parts of Earth orbit essentially unusable.\n\nNine companies total—including SpaceX, Amazon, Telesat and LeoSat—have been licensed by the U.S. Federal Communications Commission to launch such constellations. SpaceX alone plans to launch nearly 12,000 satellites by the mid-2020s, which will operate either at an altitude about 500 kilometers in low-Earth orbit (LEO) or a higher altitude of roughly 1,200 kilometers in nongeostationary orbit (NGSO). It is the first company of the nine to launch any fully functional satellites of its constellation. OneWeb, the next front-runner, has plans for a 650-strong constellation in NGSO. Six of its test satellites were launched this past February, and its first proper launch of three dozen or so satellites are planned for later this year. Monthly launches of 30 to 36 satellites will follow, with the service coming online in 2021. Every other company has similar plans for incrementally launching hundreds to thousands of satellites of its own.\n\nRisk versus Reward\n\nThe benefits of mega constellations would be manifold. Blanketing the entire planet with high-bandwidth, low-latency, always-on Internet access means ships out at sea, high-flying planes and people in remote, undeveloped areas (even Antarctica!) will suddenly be connected as never before. “Connectivity is just not [currently] available to everybody,” says Mike Lindsay, a space mission designer at OneWeb. “Half the world lacks an affordable access point to broadband Internet.”\n\nQuestions remain, however, on how to safely operate so many satellites in orbit. If the satellites fail, they could easily add to the growing problem  of space junk. At altitudes of 500 kilometers, failed satellites will not be a huge problem: within several years, atmospheric drag will naturally pull them back toward Earth to burn up on reentry. Indeed, to combat space junk, SpaceX recently modified its license with the FCC to lower the planned altitudes of more than 1,500 of its satellites by half. But at an altitude of 1,200 kilometers, where satellites remain aloft for longer, the dilemma becomes clear: “It’ll be thousands of years at those altitudes,” says Hugh Lewis, a professor of engineering and physical sciences at the University of Southampton in England, who developed a model called DAMAGE to track and monitor space debris.\n\nThere are no binding rules currently in place for how long a satellite can safely linger in orbit. The United Nations recommends that satellites be deorbited no more than 25 years after the end of their missions, but these guidelines lack strict penalties for noncompliance. “They are voluntary guidelines,” says Brian Weeden, director of program planning at the Secure World Foundation. The longer a satellite is in orbit, the greater the odds of it colliding with another one are. And such collisions are not unprecedented—in 2009 the American Iridium 33 satellite slammed into the defunct Russian Kosmos 2251 satellite, producing thousands of new pieces of debris.\n\nSome companies are being proactive in how to approach this problem. OneWeb, for example, will attach a handle to each of its satellites, offering an easy way for future orbital scrappers to haul them back down for disposal. No company has yet proved such technology, but progress is being made by entities such as the Japan-based Astroscale. “It is expected that a very small percentage of satellites will fail in such a way that the satellite operator is unable to deorbit them,” says Harriet Brettle, a business analyst at Astroscale. But “Astroscale and other emerging companies are looking to provide a backup service that will remove such failed satellites and maintain a sustainable space environment.”\n\nOther companies licensed by the FCC, however, plan to solely use the onboard propulsion of each of their satellites to ensure a safe deorbit. In principle, doing so seems fine, but in practice, satellite failure rates are not negligible. Even a 99 percent reliability rate for mega constellations would still result in hundreds of dead satellites adrift in orbit. As these numbers stack up, the chance of catastrophe would only grow.\n\n“The real problem is that we don’t have a great track record of getting [satellites] back out of orbit,” says Stijn Lemmens, a space debris analyst at the European Space Agency. “Long-term environment simulations indicate that we would need to reduce the orbital lifetime of about 90 percent of all objects that are launched into orbit. And in reality, we see this is happening successfully for about 5 to 15 percent. So we’re way off the target goal.”\n\nNoisy Skies\n\nAnother issue is the radio-based communications of the satellites themselves. Each satellite constellation will be awarded a chunk of the electromagnetic spectrum in which to communicate, but picking out a satellite amids the noise of so many can be tricky. With thousands more satellites set to enter orbit, actually communicating with a single one among those flying  overhead could be difficult. “The radio frequency interference is a big thing that is overshadowed by the potential collision risk,” Weeden says.\n\nThese mega constellations could cause problems for astronomy, too. Already, astronomers using optical telescopes have to contend with satellites occasionally crossing their view. Such interference could increase by a factor of several times with the emergence of mega constellations, says Mark Hammergren, a planetary scientist at the Adler Planetarium in Chicago. And for radio astronomers, things could become even more vexing. “Any time a satellite would pass through the observing beam of a radio telescope, there’s a chance that its transmission might be received and interpreted as a celestial signal,” Hammergren says.\n\nWednesday’s Starlink launch will be rightly lauded as a means to bring the Internet to the masses, but the greater plan of more than doubling the number of active satellites in orbit unavoidably comes with huge complications and seemingly scant room for contingencies. Even if launches and operations unfold smoothly for every mega constellation operator, just one of them experiencing financial difficulties could make the risk of space junk suddenly skyrocket. “The worst case is: you launch all your satellites, you go bankrupt, and they all stay there,” Lemmens says. “Then you have thousands of new satellites without a plan of getting them out of there. And you would have a Kessler-type of syndrome.”","title":"SpaceX's Starlink Could Cause Cascades of Space Junk","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/B6F541A6-4D9A-465B-9D5052911235B36E_source.jpg?w=590&h=800&8181615B-3C69-48AF-A8A0B0A8A2EF8E5B","link":"https://www.scientificamerican.com/article/spacexs-starlink-could-cause-cascades-of-space-junk/"},{"authors":"Colleen Chierici","pub_date":"May 9, 2019","abstract":"It’s been four years since I donated my kidney in a so-called “paired exchange,” allowing my friend Tinh to receive the kidney she needed.\n\nI met Tinh during nursing school in September of 2012. We quickly became friends, spending grueling hours in our university’s library, preparing ourselves for our future nursing careers.\n\nHer kidney disease developed from a strep throat infection she caught in 2006. Post-streptococcal glomerulonephritis is a rare condition that affects the kidneys because of the body’s immune response against the strep infection.\n\nI made my decision to donate my kidney to her shortly after the birth of my daughter in September of 2013. Tinh had received a kidney from her mother 2010, but the transplant failed, leading her to restart dialysis.\n\nI imagined the pain her mother and loved ones must have felt to watch her go through such an ordeal. I would want someone to step up for my daughter if I could not give her what she needed to survive. Once I made my decision, however, and passed all the medical, social and psychological screening at Northwestern Memorial Hospital, we got the news that I wasn’t an exact match.\n\nSo the transplant center gave me the option to do a paired exchange, meaning that Tinh would receive a kidney from someone else, and my kidney would go to another person who was a match for me.\n\nFor the laparoscopic transplant surgery in January 2015, I stayed in the hospital overnight and went home the next day. I was back at work three weeks after my kidney was removed. My health is the same as it was before, and my life continues on as normal. That’s how it can be for anyone on the transplant list, but that isn’t always the case.\n\nCurrent numbers show there are 113,000 men, women and children on the national transplant waiting list. In 2018, only 36,528 transplants were performed. These statistics make it clear thousands of people who will never receive the organ they desperately need. Twenty people die each day waiting for a transplant. Many wait knowing that death is a possible outcome.\n\nLuckily, Tinh received her kidney and she is flourishing: she went back to school, she travels and she has a successful career. But surgery is not the end of treatment for her or for any organ recipients. She needs lifelong follow-up and medication to survive. The medication is expensive and many cannot or do not know how to pay for the medications.\n\nSome insurers do not coverage for the anti-rejection medications essential to an organ recipient’s survival. If a patient does not take these medications as prescribed, the body’s immune system will destroy the new organ.\n\nChronic rejection is the leading cause of transplant failure. If a transplanted kidney fails, a patient has the option to go back on dialysis. If a heart, lung, or liver transplant fails, the patient will be put back on a waiting list for another transplant. Many will die before getting one.\n\nMedicare offers kidney recipients some respite, as anyone under the age of 65, with end-stage renal disease will receive coverage for dialysis and kidney transplantation. Depending on what part of Medicare they had while receiving a kidney transplant, some recipients will receive coverage for anti-rejection meds for the rest of their lives.\n\nOther recipients will receive coverage for 36 months after a successful transplantation. For those who don’t receive life-long coverage, anti-rejection medications can cost $10,000 to $14,000 per year.\n\nOther organ recipients such as liver, lung and heart transplant recipients do not receive the same financial offset as kidney recipients, because failure of these organs are not covered the same way under Medicare.\n\nSome individuals waiting for life-saving transplants are turned away due to inability to pay for anti-rejection medications post-transplant, and turn to crowdfunding sources such as GoFundMe.\n\nFor instance, social media recently joined in the cause for patient Hedda Elizabeth Martin, who was reportedly not considered a candidate for a heart transplant, because of concerns on how she would pay for anti-rejection medication.\n\nLast year, there was much press surrounding 11-year-old Sofia Sanchez, who had two wishes granted: dancing with the musical artist Drake, and receiving a heart transplant at Lurie Children’s Hospital. A happy ending to a transplant story is what everyone wants to hear. That is not always the case.\n\nAs a registered nurse, I can possibly understand why an organ would not be allocated to an individual who cannot afford anti-rejection medication; it would be perhaps seen as not the best use of a viable organ. Perhaps the rationale is that organs are scarce and they need to go to patients who have the best chance of survival. However, a patient’s chance of survival based on their economic ability to afford the medication is unconscionable. It is not only the wealthy who deserve organ transplants.  \n\nNo legal protections for organ recipients exist in the form of federal regulations that mandate insurers to provide lifelong coverage for anti-rejection medications.\n\nSome organizations have joined a coalition named Honor the Gift, which seeks to extend Medicare coverage of anti-rejection medication beyond 36 months for kidney transplant recipients, but this does not include recipients of other organ transplants.\n\nLast April, during Donate Life Month, I celebrated as part of the largest gathering of living donors in Chicago, breaking a Guinness World Record with 410 kidney and liver donors coming together to raise awareness.\n\nAwareness of organ donation is more important than ever: the United Network for Organ Sharing has decided to broaden the geographic regions where livers are shared to decrease wait times for livers nationally.\n\nBut this new system will increase organ transplant disparity, because patients in wealthier areas, who are more likely to receive an organ because they can afford the care associated with it, will have access to the organs that were previously being transplanted in poorer areas. The best way to combat the scarcity of organs and ensure everyone has a fair chance of receiving one is by increasing organ donation, live and deceased.\n\nI count myself lucky to have been able to help my friend with an organ donation she needed. She is fortunate to have excellent insurance and so is able to afford her anti-rejection medications.\n\nEvery person in need of an organ donation in this country deserves the right to a healthy future, regardless of economic circumstances. This month and all year, it is essential that healthcare advocates, insurers and healthcare providers all do the right thing for every patient.","title":"We Need to Make Organ Transplantation Easier","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/5F76BF1E-9042-4013-A5C2D17D334754B0_source.jpg?w=590&h=800&3B9BA15C-27C1-4288-8ECCD26EB1F6D35C","link":"https://blogs.scientificamerican.com/observations/we-need-to-make-organ-transplantation-easier/"},{"authors":"Kate Marvel","pub_date":"May 12, 2019","abstract":"Imagine spending your whole career working on a question to which you don’t want to know the answer. We know that greenhouse gas emissions can and do warm the planet, but we don’t know one very basic thing: how hot, exactly, is it going to get? The main reason for this, of course, is that human behavior is so hard to predict. How will the people of the late twenty-first century get their energy? Will they need as much as we do, or will they have reconciled themselves to fundamentally different lives?\n\nPerhaps that decision will have been made for them by war or societal collapse. None of this is knowable. But even if we could remove all the uncertainty associated with politics, economics, technology, and demography, we still wouldn’t be sure. There are many things we don’t understand about our rapidly-warming planet.\n\nTo some extent, we know why we don’t know. I have been sternly informed by communication experts that “global warming” is a better term for what’s happening than “climate change.” I have also been told the opposite. But the two are inseparable: they feed back upon each other. Rising temperatures change the planet, and these changes can speed up or, if we are very lucky, slow down the warming we’ve caused.\n\nWe are not very lucky. Most of these changes will make things worse. The polar ice that we are currently melting is a good example. Right now, it reflects sunlight back to space, cooling the planet like a sunshield on a car windscreen. When it goes, it will leave behind dark land or ocean to absorb rather than reflects the sun. A little bit of warming can become much more.\n\nTo study the effects of these changes, we use something artificial but useful: the concept of climate “sensitivity.” In our climate models, we abruptly double atmospheric carbon dioxide from its preindustrial value of 280 parts per million, let the model Earth evolve for a few hundred years, and then measure the increase in its temperature. In the first generation of climate models, this varied from about a degree and a half Celsius to about four and a half degrees. The best guess was about three degrees C. The next time we did this, having improved the models substantially, the best guess was three degrees C, and the range was between 1.5 and 4.5 degrees. Decades of new science and advances in computing power later, and nothing about these estimates or their uncertainty has substantially changed.\n\nWe don’t know everything, but we don’t know nothing. All climate models simulate a changing planet in response to a changing temperature. And, increasingly, we know why they disagree on that final warming. In the climate models that warm more, low, thick clouds appear to be changing in ways that reduce their sun-blocking power. In the models that warm less, these changes are smaller.\n\nSo scientists have devoted their time to measuring clouds, understanding them, and figuring out how to represent them in climate models. This work has paid off: the range of uncertainty is now changing. Unfortunately, it’s increased. Climate models that use more modern techniques to simulate clouds are now projecting more warming: five or six degrees Celsius in response to a doubling of carbon dioxide. To put those numbers in context, four and a half degrees is the difference between now and the last Ice Age.\n\nI find these high numbers hard to believe, but as a scientist it’s my job to find things hard to believe. My skepticism is rooted in clues from the planet’s past. At the height of the last Ice Age, temperatures were cooler and carbon dioxide levels lower. It’s hard to reconcile these measurements with extremely high climate sensitivities. But it’s almost impossible to reconcile them with extremely low ones.\n\nClues from the more recent past might seem to paint a more reassuring picture. We have, after all, emitted carbon dioxide, and the planet has warmed in response. Our Earth is about a degree Celsius warmer than it was before the Industrial Revolution. This is dangerous, but not yet catastrophic, and some have suggested it might be indicative of a planet relatively insensitive to carbon dioxide. But the past is not the future, and we have good reason to believe that there are no analogues for the future into which we are hurtling. Right now, heat is being mixed into the deep ocean, which is cold and vast but not infinite. It will warm up in time, over hundreds or thousands of years, and the changes it will trigger may be different than any we have ever observed. Clouds may dissipate, ice will melt, and the warming will get worse.\n\nThese uncertainties matter in the real world. If the climate is very sensitive to carbon dioxide- if the changes provoked by warming themselves create much more warming- then our time frame for action is reduced. If the climate is relatively insensitive, then perhaps we’ll have a little more breathing room. But we’ve ruled out a climate sensitivity of zero. Warming is real, it’s happening, and it’s likely to get worse. Uncertainty is no excuse for inaction. Even in the improbable event that climate sensitivity is very low, “business as usual” still warms the planet and leads to unpleasant consequences. In the event that climate sensitivity is high, “business as usual” means disaster.\n\nClimate models, like all models, are imperfect representations of the real world. They tell us something useful about the planet we’re changing, but not how much, exactly, we’ll change it. The only way to be sure is to actually double atmospheric carbon dioxide and wait until the planet approaches a new equilibrium, measuring the changes along the way. This is an uncontrolled experiment I hope we will never do. But I’m afraid we’re well on our way to finding out.","title":"Global Warming: How Hot, Exactly, Is it Going to Get?","origin":"Hot Planet","image":"https://static.scientificamerican.com/blogs/cache/file/80C4493E-6185-4B03-8BB3D50C6EFE5DB1_source.gif?w=590&h=800&F16593DB-37EB-46A1-ADBFDD2EC7B05A93","link":"https://blogs.scientificamerican.com/hot-planet/global-warming-how-hot-exactly-is-it-going-to-get/"},{"authors":"Jean Chemnick, E&E News","pub_date":"May 10, 2019","abstract":"EPA Administrator Andrew Wheeler used an overseas gathering of environment ministers this week to hint that the United States might overhaul the way it uses climate data and modeling. Five days after his assertion was included in an official document from the Group of Seven meeting in Metz, France, it remains unclear if Wheeler revealed a potential policy to reexamine climate modeling.\n\nIt’s become common for the United States to have its own climate and energy paragraph in multilateral statements, and on Monday, Wheeler broke away from the six other nations on issues like the Paris Agreement, providing support for poor and climate-affected countries, and overseas investments in fossil fuels.\n\nThat much was normal. It’s happened ever since President Trump took office in January 2017.\n\nBut Wheeler added something new that’s raising concern among some environmentalists that the United States might be formally questioning climate science inside federal agencies.\n\n“The United States reaffirms its commitment to re-examine comprehensive modeling that best reflects the actual state of climate science in order to inform its policy-making decisions, including comparing actual monitored climate data against the modeled climate trajectories on an on-going basis,” says the U.S. portion of the communiqué.\n\nGreens who follow the G-7 process were dismayed.\n\nAlden Meyer, director of policy and strategy at the Union of Concerned Scientists, called the language “pretty troubling,” and Luca Bergamaschi of the Britain-based E3G called it “a major step back.”\n\nThey read Wheeler’s language as an attempt to undercut a report last year by the U.N. Intergovernmental Panel on Climate Change. The report drew on thousands of peer-reviewed studies to warn of the importance of holding postindustrial warming to no more than 1.5 degrees Celsius.\n\nWheeler has been critical of the IPCC’s conclusions and of the National Climate Assessment, a U.S. report that issued similar warnings last year. He’s not alone in the Trump administration. In December, U.S. delegates to the U.N. climate talks in Katowice, Poland, joined Russia and Saudi Arabia to block language to “welcome” the IPCC’s findings.\n\nIt’s unclear if Wheeler meant to slight the IPCC on Monday. In fact, he joined his counterparts from France, Canada, the United Kingdom, Italy, Germany and Japan in praising the international body’s work to “strengthen the science-policy interface on the environment including by providing reliable assessments of the state of knowledge in response to the requests of policy makers and build capacity to use science effectively in decision-making at all levels.”\n\nThe statement leaves little to “re-examine” from the IPCC’s work.\n\nSo, was he announcing an alternative climate modeling initiative, either at EPA or another federal agency?\n\n“Currently, there are no specific efforts underway at EPA,” said agency spokesman James Hewitt. He didn’t respond to follow-ups about future plans or initiatives at other agencies.\n\nMeyer and others suggested that Wheeler might be referring to plans within the White House to convene a task force within the National Security Council to undermine the scientific underpinnings of the National Climate Assessment. But that proposal—to be spearheaded by William Happer, a senior director on the National Security Council—has yet to be accepted by Trump. NSC didn’t respond to inquiries (Climatewire, Feb. 21).\n\nMyron Ebell, a senior fellow at the Competitive Enterprise Institute, said a White House meeting last week to brief the president on the Happer proposal “went well.” But he said the concept remains controversial among some senior officials.\n\n“The president is enthusiastic about setting up the Happer commission,” said Ebell, who oversaw the EPA transition team before Trump’s inauguration. But he noted that Wheeler would have been unlikely to reference a program that Trump has yet to bless at an international forum.\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"Trump Administration Might “Re-Examine” Climate Modeling","origin":"Policy & Ethics","image":"https://static.scientificamerican.com/sciam/cache/file/9B94D236-E595-4388-B447F424BD452366_source.jpg?w=590&h=800&C4DF7DF0-B393-40EE-8EF6903C3A248653","link":"https://www.scientificamerican.com/article/trump-administration-might-re-examine-climate-modeling/"},{"authors":"Kelly Reidy","pub_date":"May 10, 2019","abstract":"Dragons are not new. Game of Thrones tells us that they date back to some arguably medieval time, which may or may not predate the adventures of Smaug, the dragon from The Hobbit. In the nonfiction world, Christian legend tells of St. George slaying a dragon, and that tale probably derives from pre-Christian stories. Dragons show up in Chinese mythology as well—and in Bhutan, the Druk, or thunder dragon, is emblazoned on the national flag. And in fact, anthropologists have found dragons in art spanning thousands of years and independently created by people from all over the world.\n\nThe ubiquity of dragons across time and space may be related to fears inherited from some of humans’ most adorable ancestors: vervet monkeys. In his book An Instinct for Dragons, David E. Jones cites a study showing that these primates have an innate fear of lions, snakes and eagles. That’s a recipe for a dragon if I’ve ever heard one! Thus, humans may be evolutionarily predisposed to fear these animals.\n\nBut this only leads to more questions: What about the fire-breathing capabilities of European dragons, or the rain-bringing skills of Asian dragons, or the people-eating habits of Maori dragons? And why do some dragons fly while others slither?\n\nThe appearance, behavior and general level of horror of dragons vary wildly across cultures. These differences can tell us something about the natural history of their creators; this is where both local fears and local fauna play a role.\n\nIn northern China, around 300 B.C., workers digging a canal came across a fossilized animal skeleton. Remember that the theory of evolution wasn’t a thing yet, so people assumed this was the skeleton of an existing creature rather than the extinct nonavian dinosaur that it probably was. It went on record as a dragon skeleton—more fuel for the long-existing fire of Chinese dragon mythology.\n\nDragons appear in Chinese art from at least as far back as 1100 B.C. These dragons are relatively tame-looking and typically serpentine, with multiple sets of legs and a vaguely lion-like head. They don’t have wings, but they can fly. Two ancient Chinese rulers declared themselves to be direct descendent of dragons, and so dragons in many Chinese cultures became symbols of power. Contrary to the gut feeling you might be having right now, these dragons are generally seen as wise and benevolent—heroic, even—bringing rain to dry crops and pretty much saving entire civilizations.\n\nIn Europe, on the other hand, dragons are usually the bad guys. European dragon myths feature dragons as vicious monsters whose raison d’être involves getting slain by saints who need hero credibility. St. George, known primarily as a dragon-slayer, is now the patron saint of England and even has his own holiday on April 23.\n\nAppearance-wise, these European dragons are a little wackier than their Asian cousins. They look more like snake/eagle/lion combinations straight out of your worst fever dreams. Usually they have legs and wings and a snake tongue, sometimes fur, sometimes scales, sometimes both. For good measure, they can also breathe fire—the fire-breathing animals in Hieronymus Bosch’s delightful Renaissance-era paintings of hell may have been an inspiration for this feature. The very real and very prehistoric-looking Nile crocodile might also have been an influence, as it regularly swam up to European shores from Egypt and traipsed around on land.\n\nFurther south, in New Zealand, the taniwha are dragon-like creatures from Maori mythology. In this case, take the basic snake/eagle/lion innate-fear combo and add something more local: the great white shark. In fact, the Maori word for great white shark is mangō-taniwha. But don’t worry too much, as these creatures can be benevolent protectors—sometimes. At other times, they can be totally horrifying people-eaters. As a cherry on top of that nightmare cake, note also that in some stories, taniwha have shape-shifting abilities.\n\nAfter thousands of years of international dragon mythology, you’d be forgiven for thinking that their moment has passed.\n\nBut dragons continue to spark our curiosity and captivate our imaginations; today, they make appearances in pop culture via The Lord of the Rings, Dungeons & Dragons (and by extension, Stranger Things), Game of Thrones and even in band names like Imagine Dragons and DragonForce.\n\nThese pop dragons are mostly European-style in appearance, but their roles are more complex than the traditional Western “set ‘em up, knock ‘em down” scheme. They run the gamut from the occasionally disagreeable allies in Game of Thrones to the well-spoken monster in The Hobbit.\n\nEither way, stay vigilant, dear reader, because if Game of Thrones has taught us anything, it’s that “the night is dark and full of terror.”","title":"Here Be Dragons","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/40605986-E95F-4666-AA679D0D6D54725C_source.jpg?w=590&h=800&13F244E9-0C39-47D0-9EDA5DE9BA857B00","link":"https://blogs.scientificamerican.com/observations/here-be-dragons/"},{"authors":"Liza Mundy","pub_date":"Scientific American May 2019 Issue","abstract":"Sprightly yellow seems to be the hue of choice for corporate wellness chains designing a logo to attract health-minded women. There is the cleansing grapefruit of SoulCycle, the happy buttercup of Drybar. And last year vans started materializing at busy pedestrian spots in Manhattan and Los Angeles that sported the shade of sunflowers. These vans are mobile fertility clinics, inviting women to pop in and learn how to safeguard their reproductive germ line by freezing their eggs. “Own your future,” the ads on the side promise. “Your fertility, understood.”\n\nThe vehicles are emissaries of Kindbody, a boutique fertility practice that courts the same clientele that frequents spin classes and blow-dry bars. It is one of a small but growing number of outfits that offer fertility services, including retrieving a woman’s eggs, or oocytes, to be frozen for later use. Because eggs are one of the most important factors in female fertility, and both their quality and quantity declines with age, banking eggs promises to lengthen a woman’s window of fertility and postpone the decision of whether to have kids. As a rival service, Extend Fertility, puts it, “Women have more options today than ever before. And we’re giving you one more—the option to start your family when you’re ready.”\n\nThe appearance of boutique egg-freezing outfits is one of the most high-profile—but not the only—recent developments in assisted reproductive technology, which is the science (and commerce) of helping people have the babies they want. These stand-alone clinics exist thanks to a convergence of female financial empowerment, venture capital backing and real medical progress. And it is not just mobile clinics behind the push. Egg freezing is on the rise at gold-standard fertility clinics, such as the one at the University of Southern California. There, according to clinic director Richard Paulson, it accounts for almost 40 percent of egg-retrieval cycles—in which women inject themselves with hormones to stimulate their ovaries to release multiple eggs, and doctors then collect those eggs while the women are under anesthesia. (The other 60 percent of cycles at the clinic involve women undergoing infertility treatment who intend to use the eggs soon.)\n\nUltimately these providers are making the case that egg freezing has come far enough to justify the $10,000-plus bet women place by investing in the procedure and medications not covered by insurance (that price tag does not include the storage fees women must pay yearly to keep the eggs on ice). This confidence stems from significant breakthroughs in the science of fertility and conception made over the past decade, notably a process that allows doctors to flash-freeze eggs. Physicians have also come a long way in the science of in vitro fertilization (IVF)—the process that comes after egg freezing—which unites a thawed egg (or a fresh one) with a sperm for conception in a petri dish and then grows the resulting embryo to the point where it can be put back inside a woman’s uterus to implant.\n\nAll this amounts to a sea change in the science of making babies, one that suggests, in theory, that women are not bound by the traditional notion of the ticking biological clock. Yet in practice, the reality is more complicated. Women must consider other factors besides their eggs, such as their overall health and the health of the sperm they plan to use, in deciding when to get pregnant. And just how good of a bet these new technologies truly are remains to be determined: the vast majority of frozen eggs at clinics have yet to be thawed. The question remains: Will they all be viable? Can science really safeguard fertility for later?\n\nThe freezing boom\n\nIn some places, such as the San Francisco Bay Area, the rise in egg freezing is linked in part to nearby tech companies such as Facebook and Google, which now (and with some fanfare) cover the procedure for employees. In Silicon Valley, egg freezing has become part of the benefits package a prudent career woman may consider availing herself of, a kind of 401(k) for future family formation. The boom also stems from other converging trends. One is the millennial generation’s comfort with social media; boutique clinics have strong presences on Instagram and Twitter, as do a growing number of traditional clinics. Even online dating—which has sold the hope that much messiness of the human heart can be solved by downloading an app—has an impact. “Women have said to me, instead of looking at every date as ‘Is this someone I could marry?’ they can set that aside,” says Marcelle Cedars, director of the University of California, San Francisco’s Center for Reproductive Health.\n\nThe rise in freezing also bespeaks a public inured to paying a monthly fee for products. What egg freezing is—among other things—is one more paid-subscription service, like Netflix or Zipcar. Oocytes, once frozen, must be kept frozen until used. After a woman goes through the not easy or cheap process of having eggs retrieved, she will be powerfully motivated to continue paying the storage fee, which can be as much as $500 or $1,000 a year. Every batch of eggs in liquid nitrogen represents an income stream for years, for the clinic and its investors.\n\n\n\nVitrification devices such as the S-Cryolock (shown) help to freeze eggs and embryos almost instantly to prevent damage. Credit: Jamie Chung\n\n\n\nBut the freezing trend is also the outcome of science. Asked to reflect on stages of progress in the field, Paulson casts his mind back to when in vitro was in its infancy. The first IVF baby was Louise Brown, born in 1978, now a mother herself. The technology for the scheme was nonexistent to the point where doctors had to fashion their own utensils to retrieve eggs and incubate embryos; when the late gynecologist Patrick Steptoe and the late physiologist Robert Edwards were performing the experiments that would result in Brown’s birth, they kept embryos warm in a pouch created in the skin of a living rabbit.\n\nInto the 1980s IVF patients could expect, at best, a 10 to 15 percent delivery rate. “We were able to help a handful of people,” says Alan Penzias, an associate professor at Harvard Medical School and a doctor at Boston IVF. “But not the majority. Most people failed.”\n\nThe retrieval of eggs—the well-protected female germ line—has always been hard. The 1980s saw basic techniques developed and refined; at first, doctors had to perform laparoscopic surgery to extract a single egg the instant it was ovulated. They learned to administer hormones that could cause eggs to ovulate in greater quantity and at a more predictable time and to retrieve them vaginally, with a needle that pokes through to the ovaries. The 1990s were—unexpectedly—the decade of the man. Male-factor infertility—slow or misshapen sperm or low sperm count—is a common reason couples may be unable to conceive. For a long time the only “cure” for male-factor infertility was sperm donation. Then, in 1992, scientists in Belgium announced the first live birth after using ICSI—intracytoplasmic sperm injection—in which a single sperm is injected into the egg. ICSI was a disruptive technology that cured male-factor infertility, for couples who can afford it.\n\nFor more than half a century it has been almost ridiculously easy to freeze sperm, which are stripped-down DNA missiles. The first reported human birth from frozen sperm occurred back in 1953. Not so for the egg, which is among the largest cells in the body and difficult to freeze well. Eggs are mostly water, meaning ice crystals can form, with sharp edges that damage organelles and other delicate structures. For years freezing an egg entailed dehydrating it to the fullest extent possible, then introducing tiny amounts of cryoprotectant, a kind of antifreeze that aims to prevent crystals from forming. Everything was done very slowly. “It would be this painful process that would take about two to three hours,” says Amy Sparks, an embryologist at the University of Iowa, who remembers the agony of ratcheting down the temperature bit by bit. This technology enabled the first human birth from a frozen embryo in 1984; the first birth from a frozen oocyte was reported two years later, in 1986. But for eggs, freezing remained both difficult and damaging: the upshot often was like what happens when you thaw ice cream and refreeze it: icy granulation. “When it thaws, all of a sudden the water from those crystals has nowhere to go and causes damage to the cell,” Sparks says.\n\nThen, about 10 years ago, came the most important recent scientific breakthrough in assisted reproductive technology. Vitrification—from vitrum, Latin for “glass”—is the ability to freeze eggs (and embryos) breathtakingly fast. The procedure involves larger quantities of cryoprotectant than earlier methods and a direct plunge into liquid nitrogen, which triggers “ultrarapid cooling,” minimizes the formation of ice crystals and almost instantly transforms the egg into a glasslike state. “In the past 10 years the impact of vitrification ... has really transformed the field in ways that we could not have foreseen,” says Serena Chen, director of the clinic at Saint Barnabas Medical Center in New Jersey.\n\n\n\nInstead of growing embryos in incubators in the lab, the INVOcell device can be inserted into a patient's vagina to incubate them there. Credit: Jamie Chung\n\n\n\nVitrification is akin to pushing the “pause” button, Chen says; when the time comes, the laboratory pushes “play” and commences rapid thawing. The results are so show-stopping that in 2018, the ethics committee of the American Society for Reproductive Medicine (ASRM)—which up to that point had declined to recommend social use of the technology—issued a paper saying egg freezing “for women attempting to safeguard their reproductive potential for the future” could now be considered “ethically permissible.” In short: egg freezing has gone mainstream. Clinics disagree over whether frozen eggs are as viable as fresh, but most experts, including Paulson and Sparks, say they are very, very close. And there is no question that eggs frozen when a woman is 32 are better than fresh eggs retrieved from the same woman at 42.\n\nBut even great eggs, just like sex, do not always make a baby. Cedars explains to patients that they should not wait to use frozen eggs until their early 40s, because if they do not work, the old-fashioned method might not either. Yet here lies a quandary—if women cannot wait until their fresh eggs have declined, what is the point of freezing in the first place?\n\nIVF strides\n\nVitrification is not the only advance helping to buoy the promise of egg freezing. Other elements of IVF have seen major improvements, such as the new standard of growing an embryo for five days in the lab before transferring it back to a woman. A decade ago embryos were often transferred at the three-day stage, when they consisted of just eight cells. Human embryos now arrive in the uterus as “blastocysts,” with roughly 100 cells, which are more mature and robust and have a much greater chance of success. According to CDC data from 2016, for women younger than 35, nearly 50 percent of fresh embryos transferred at day five resulted in a live birth as compared with 34.4 percent of embryos transferred at day three. For women between 35 and 37, the percentages were 42.1 for day five versus 28.6 for day three.\n\nSuccess rates are also getting better because labs can now closely replicate the chemical environment of the fallopian tube, where embryos spend their first five or so days when pregnancy happens naturally. Labs have gotten much better at regulating the amounts and concentrations of nitrogen, oxygen and carbon dioxide. Current incubators also feature more solid-state technology that requires less opening and closing of doors so that embryos can rest undisturbed.\n\nThe ability to develop embryos to the blastocyst stage means embryologists can more easily recognize the best of the batch before deciding which to try to implant. These judgment calls are also improved by a process called preimplantation genetic selection. Back in the three-day-embryo era, if scientists wanted to gauge the genetic health of an embryo, they had to pry one cell from an eight-cell mass, a lab procedure so harrowing that Sparks still has “nightmares” about it. Now it is much easier to use lasers to grab a couple of cells from the part of the blastocyst that will create the placenta—the less vital section than the one that is destined for the fetus.\n\nAll in all, embryologists’ improved ability to freeze and test embryos amounts to “a huge change,” Penzias says. About 10 years ago, frozen embryos had a 10 percent lower success rate than fresh. “Now we’re talking about parity,” he says. The improved odds mean, in theory, that whether women are using embryos created from eggs retrieved the same month or from those frozen years before, clinics can transfer just one embryo at a time rather than the two or three that used to be the norm. For 14 years it has been the University of Iowa’s policy that if a woman is younger than 38, has no prior failed transfers at the clinic and has at least a single good-looking blastocyst (a five-day-old embryo), then one is “all they get,” Sparks says. These trends have reduced the prevalence of twins, and especially of triplets and higher-order multiples, which are much riskier pregnancies than carrying singletons, for both babies and moms. At the University of Iowa, the rate of twin birth used to be 40 percent in 2001; now it is under 5 percent. Industrywide, according to the CDC, the portion of transfers involving a single embryo has more than tripled, from 12 percent in 2007 to 40 percent in 2016. Equally important: the percentage of fresh single-embryo transfers resulting in a live birth increased from 21 percent in 2007 to 37 percent in 2016.\n\nThese innovations are just the beginning. A new invention allows a woman to incubate embryos inside a device inserted in her vagina rather than an incubator in the lab. And even more radical technologies are on the horizon: Mitochondrial replacement therapy, for instance, is a controversial procedure that can eliminate the risk of genetic mitochondrial disease by injecting the nucleus of a mother’s egg into an egg from a woman without the disease whose nucleus has been removed but whose mitochondria remain. The procedure is banned in the U.S., out of concerns about mixing the DNA of two women, but is being developed in England. The day is also coming, Paulson says, when it will be possible to use stem cell technology to manufacture sperm and eggs from normal body cells, such as skin cells. Although it sounds like science fiction, the procedure would involve no changes to a cell’s DNA, so that part, at least, is less worrisome than mitochondrial transfer. With this technology, women would no longer need to bank eggs. “At 45, you can still have an egg made out of your skin cells,” Paulson says. It sounds wild, but so did IVF 40 years ago. “It’s going to happen.”\n\nTicking clocks\n\nIt is a fact that a woman is born with all the oocytes she will have; over time her ovarian reserve diminishes, as does the quality of her eggs.\n\nTalking about this subject has always been fraught. Back in 2001, when the ASRM launched an ad campaign partly about age-related infertility, the National Organization for Women attacked it as coercive and antifeminist. Chen says this reaction does women a major disservice; older eggs are more likely to be chromosomally abnormal, with a higher risk for miscarriage and the grief that follows. She adds that egg freezing is often depicted as elective and narcissistic, “kind of like plastic surgery or getting a cute Mini Cooper.” But women face many pressures, particularly in their mid-30s, when each year of delayed childbearing means an increase in earning power. “It’s not about women just being selfish and trying to work on their careers,” Chen says. “The truth is, a lot of people just haven’t found the right partner.”\n\nStill, Chen shares concerns about the commercialization of a technology that originally aimed to help cancer patients preserve fertility during treatment. Jake Anderson-Bialis, co-founder of the consumer education Web site FertilityIQ, worries that women do not realize taking hormones and then undergoing retrieval is not a minor lunch-hour-type procedure. And there is still no guarantee the eggs will result in a live birth. The backlash could be huge if many of the women now freezing their eggs later attempt to use them, only to find out their investment failed. The dirty secret of the fertility industry, up to now, has been multiple births; going forward, Anderson-Bialis says, “if there’s going to be a black eye, it’s egg freezing.” By this, he means the danger that the eggs, once thawed, will not be viable—a potentially devastating outcome to women sold on the promise of egg freezing. Cedars agrees that some women are too bullish on what technology can accomplish. “We have to repeatedly say to patients, ‘There’s not a baby in the freezer,’” she says. “‘There is the potential for a baby.’”","title":"Pausing Fertility: What Will Happen When the Eggs Thaw?","origin":"Medical & Biotech","image":"https://static.scientificamerican.com/sciam/cache/file/6B5508D9-2E75-43D6-A5348FDC2E9834C6_source.jpg?w=590&h=800&CB34AD6B-2151-4288-834BC982BFD191E6","link":"https://www.scientificamerican.com/article/pausing-fertility-what-will-happen-when-the-eggs-thaw/"},{"authors":"Karen Weintraub","pub_date":"May 9, 2019","abstract":"As of this month, there have been more than 750 cases of measles in the U.S. this year across 23 states—the most since 1994, according to the Centers for Disease Control and Prevention. Measles was considered “eliminated” in the U.S. in 2000, although there have been small, sporadic outbreaks since then. A new study looks at how countries have pulled themselves out of past outbreaks of the disease—strategies that may need to be adapted in light of current vaccine hesitancy.\n\nAccording to the study, published Thursday in Science, a country’s control of measles passes along a continuum with three different categories: a large number of cases every year, fewer cases overall but lots of year-to-year variability, and finally, consistently few or no cases. Knowing where a country lies in this continuum–referred to as a “canonical path”—could help it plan its response to the next outbreak, says senior author Justin Lessler, an epidemiologist and associate professor at the Johns Hopkins Bloomberg School of Public Health.\n\n“This was really driven by the laws that govern measles transmission and measles epidemic dynamics,” Lessler says. In the past, “as you had increases in vaccination rates and decreases in birth rates it would really drive countries along this expected path.”\n\n\n\nHow different countries have progressed along the consistent and predictable path for measles outbreaks, 1990-2017. Credit: Matthew Graham, Amy K. Winter, Matthew Ferrari, Bryan Grenfell, William J. Moss, Andrew S. Azman, C. Jessica E. Metcalf, Justin Lessler\n\n\n\nLessler and his colleagues conducted a statistical analysis of measles outbreaks in countries worldwide between 1980 and 2017. By looking at weighted averages of measles cases and year-to-year variability, the researchers placed countries and regions at different points on the continuum. For example, Africa in 2008 was at almost exactly the same stage the Americas were in 1995, according to the research.\n\nThe study should also help a country direct its vaccination efforts, rather than fighting an outbreak based on the patterns of previous ones, Lessler says. If a prior outbreak was particularly severe among small children, many countries will be inclined to focus vaccination efforts on this age bracket, he says. But that is probably not the right approach. If childhood vaccination rates are high and birth rates low, the new analysis suggests that older children and teens may now be the most vulnerable, he says. “The path [the outbreak takes is] dictated by the size of the population you have that’s susceptible to measles,” Lessler says. “You could use the position along the path to understand the age distribution of susceptibility, which could help target vaccination efforts.”\n\nShweta Bansal, an associate professor of biology at Georgetown University in Washington, D.C., says the study allows countries to use a minimal amount of data to identify where they might be on that path. “As a public health communication tool, I think it’s quite powerful,” says Bansal, who was not involved in the research.\n\nBut as the current U.S. outbreaks demonstrate, even countries that had been almost completely measles-free for years are suddenly vulnerable again because people are declining to get vaccinated.\n\nJohn Brownstein, an epidemiologist at Harvard Medical School who was not involved in the new study, says social media has changed the dynamics around measles and other vaccine-preventable diseases—and it is unclear what the repercussions will be. Brownstein says that when he was featured in a recent Facebook video encouraging measles vaccination, the post was flooded with comments opposing vaccines and spreading inaccurate information about both the disease and the vaccine. “It was pretty unbelievable,” says Brownstein, who is also Chief Innovation Officer at Boston Children’s Hospital. “I started trying to comment back to clarify, and the wave [of responses] just was too big for me to be able to handle.”\n\nIt is not clear, Brownstein says, whether historic trends of controlling diseases with vaccines can continue when so many people are passionately opposed to them. Vaccine hesitancy is not new or U.S. specific, he says: “Every location on earth has vaccine confidence issues.” But the internet makes it easier for people who oppose vaccines to find each other and share their opinions.\n\n“There’s a combination of mistrust around government and pharmaceutical companies that is probably different” than with other public concerns, Brownstein says. “There’s also a component of the invasiveness of the needle that’s also at play in our psychology.”\n\nBefore vaccination, measles infected more than 95 percent of all children and was responsible for more than four million deaths worldwide each year. After the introduction of the measles vaccine in the 1960s, childhood deaths from not just measles but a wide range of infectious diseases dropped substantially. Measles seems to erase immune protections that the child has from other infectious diseases. According to a 2015 study in Science that examined historical data, measles outbreaks predict deaths from other childhood diseases two to three years later, suggesting that a measles infection made these children more vulnerable to diseases such as pneumonia and diarrhea.\n\nMany people see measles infections as benign, particularly in young children, but teens and young adults suffer terribly, says Jeffrey Griffiths, a professor in the Department of Public Health and Community Medicine at Tufts University School of Medicine. “It’s a vicious, bad disease and it’s not like getting a cold,” he says. Malnourished children and those with vitamin A deficiencies are particularly vulnerable, with a death rate as high as 50 percent in parts of Africa, Griffiths adds.\n\nThe World Health Organization had hoped to eliminate measles worldwide by 2020. Lessler says that date is not realistic, but he and Bansal say they still believe it will someday be possible to eradicate measles. “Doing this kind of work requires strong optimism,” Bansal says. She adds that measles “represents an ideal case for eradication” because the pathogen is well understood, an effective vaccine exists—the recommended two doses seem to provide long-lasting immunity—and past U.S. experience shows it is possible to limit transmission of the disease for an extended period. “We have a much better chance of [eradicating measles] than other infections, but the challenge of vaccine hesitancy is certainly giving us all cause for concern,” she says.","title":"Measles Outbreaks Follow a Predictable Path—Provided People Get Vaccinated","origin":"Public Health","image":"https://static.scientificamerican.com/sciam/cache/file/4680AE5B-6551-4B75-905E462D9349172B_source.jpg?w=590&h=800&6265D5D4-AFB0-4214-985C31634FEAF4F9","link":"https://www.scientificamerican.com/article/measles-outbreaks-follow-a-predictable-path-provided-people-get-vaccinated/"},{"authors":"Amanda Baker","pub_date":"May 2, 2019","abstract":"How many words does it take to teach a meaningful lesson in critical thinking? 5000? 1000? 500? And how young could your audience be and still get something out of it? Ten? Eight? Three? Imagine you have been challenged to teach a three-year-old child something about metacognition in fewer than 300 words. It may sound impossible, but picture books do it every day.\n\nObviously, we aren’t asking toddlers to parse the Monty Hall problem or navigate the prisoner’s dilemma. But figuring out how to make decisions – and assessing the strength of both that process and the decisions themselves – provides the foundation for any bigger questions you might want to pose. And because toddlers are still figuring out this whole decision thing from scratch, they engage with this process without hesitation. Most people are familiar with the characteristic “why” stage, with curious young minds asking about everything from how toasters work to why people have hair. But spending time with a toddler makes it clear that children this age are probably also asked “why” more than any other humans on the planet. “Why didn’t you tell me you had to use the potty?” “Why do you think the lamp is going to bite you?” “Why did you stuff your napkin into a full glass of milk?” All of these fall within the realm of an average morning. And the answers are often delivered with a blank-faced sincerity unparalleled in adults: “I wasn’t done with my book,” “The lamp can see me,” or “It was wet.”\n\nParsing the logic of seemingly id-driven actions takes work on both sides – grown-ups trying to follow staggering non sequiturs and toddlers trying to articulate their logic with a limited vocabulary and foggy grasp of pronouns. One common arena for these kinds of conversations is the reading of picture books. Try as I might to explain the decision-making process, I can’t imagine I will ever approach the clarity and impact of Mo Willems’ Should I Share My Ice Cream? Spoiler alert for those have not followed this particular adventure, the elephant gets some ice cream and has to decide whether to share it with his best friend, Piggie. Elephant takes so long making the decision that his ice cream ultimately melts, and Piggie shows up just in time to console her friend by sharing an ice cream cone of her own. This synopsis contains neither the humor nor the melodrama of the original story. But my ~894 readings have taught me that young readers can not only follow the logic of deciding whether to share, but also be driven to such sympathy to need to hug the book on pages when the characters look sad.\n\nPart of the magic comes not just from the ultimate decisions, but the steps the characters take in making them. Each step is laid out and illustrated for the reader. The initial excitement, the realization that he has a chance to share, the question of whether he should share, the question of whether he wants to share, the discovery of an excuse to keep the ice cream to himself, and the logical breakdown of that excuse. On one page, the elephant gleefully determines that the chance that Piggie might not like the flavor absolves him of any reasonable obligation to share. He looks at the ice cream with almost manic anticipation. But flip the page, and you witness the honest admission that Piggie would, in fact, like that flavor. I can’t decide if it sounds simple or complicated, but there is power in the page turn. It even drives some critical analysis of my own behavior. Am I overthinking this story as a defense mechanism against the hundreds of times I will likely be asked to re-read it? Probably. Do I care? No.\n\nAnd limited text and few powerful illustrations can take on concepts more nuanced than sharing. On its surface, Galia Bernstein’s I Am a Cat follows a small house cat on the journey of convincing its larger peers – lions and tigers – that it too is a cat. In the process, the characters engage their assumptions, personal bias, in-group/out-group dynamics, combating misconceptions with logical arguments, and changing their minds when faced with convincing evidence. There is even a reasonable primer in taxonomic practices thrown in for good measure. Both kids and grown-ups can appreciate a small, stripey role model standing its ground when laughed at, and responding with calm, careful evidence rather than visceral frustration. Even when the argument is about tails, pointy ears, and claws, it is a welcome change to see evidence-based arguments result in changed minds and a collective kitty romp rather than finger pointing and assertions of us versus them.\n\nFor those who will spend the foreseeable future in the land of picture books, there is comfort in recognizing opportunities to challenge assumptions (Last Stop on Market Street) or giggle at terrible logic (the final lines of the classic Madeline). But there are also lessons for those tasked with conveying complex ideas to unexpected audiences. There is a source of hope. Not only can we start conversations about critical thinking before they can be fully considered conversations, but we can remember the power of a clear narrative in opening conversational doors that might otherwise be closed to us. If picture book authors can use their prodigious skills to engage toddlers in logic, trade-offs, and critical decision making with 500 words and an ice cream cone, the rest of us can take the time to get to know our audiences, find the right narrative, and open the door to conversations with a shared story.","title":"Learning about Critical Thinking from Kitty Claws and Ice Cream Cones","origin":"Budding Scientist","image":"https://static.scientificamerican.com/blogs/cache/file/1D1A6D8D-0696-439B-80FD014775607F57_source.jpg?w=590&h=800&D18AB65D-4EDF-4A8C-8E1649212E5B3347","link":"https://blogs.scientificamerican.com/budding-scientist/learning-about-critical-thinking-from-kitty-claws-and-ice-cream-cones/"},{"authors":"Andrea Thompson","pub_date":"May 10, 2019","abstract":"A rapidly growing body of research shows plastic pollution accumulating around the planet at an alarming rate. Tiny bits known as microplastic result from the breakdown of larger items and have proven especially pervasive, turning up everywhere from oceans to rivers to soil, even hanging in the air we breathe.\n\nAs public awareness grows and concerns mount, cities, states and countries have been looking for ways to curb the release of plastic into the environment and to slow production of the material. Policies have ranged from bans on “single-use” plastics, such as grocery bags or straws, to rules requiring producers help pay for collecting and recycling their products.\n\nThe issue is also gaining traction at the international level. María Fernanda Espinosa Garcés, president of the 73rd session of the United Nations General Assembly, singled it out as a key environmental concern she wants the body to address during her tenure, which began in September. She worked with several countries on launching a campaign in December to raise awareness and encourage phasing out single-use plastics, and has initiated a phase-out of such products at U.N. headquarters. Espinosa spoke with Scientific American in her office about the growing awareness of plastic pollution and the role she sees the U.N. playing in tackling it.\n\n[An edited transcript of the interview follows.]\n\nYou identified protecting the environment as one of the key priorities of your presidency, calling out plastic pollution particularly—why did you single out that issue? \n\nI think that the issue of single-use plastics is perhaps one of the defining factors of the current ocean pollution, but also, it's very much connected to human health and our food security. It is an issue that really is affecting now and today—not only the health of consumers, but also the livelihoods of the hundreds of thousands of people living from coastal resources.\n\nIs plastic pollution a growing concern among member states?\n\nYes, definitely. When I launched the campaign, I teamed up with Norway, Antigua and Barbuda. Then I saw that more and more member states are paying attention to that, at different levels. At the international policy level (during the last U.N. Environment Assembly in Nairobi, Kenya, there were two resolutions that were passed: to fight plastic pollution, and to really address the use of single-use plastics), but there are also efforts at the national level. Today we have 127 countries that have passed legislation in the use of single-use plastic bags. So, I think that we are seeing a very strong response from the international community.\n\nThis is a collective action where you need to bring together civil society, academia, science and the private sector. At the same time, we want to really have the younger generations be very plastic-conscious when they have to take consumer decisions. We wanted to make sure that this wasn't seen as a technical scientific issue, but as a personal issue—as a personal choice. And also, we have teamed up with the private sector. The U.N. has launched an agreement [with plastics producers] to say, “Yes, we are going to make profound changes in the way we produce.” That agreement accounted for about 20 percent of the companies that produce single-use plastics.\n\nSo, there is a world movement, I would call it. But this world movement—I hope it bears fruit very soon. Otherwise we will be in deep trouble.\n\nA number of scientists who study plastic pollution say curbing single-use plastics is a great place to start, but they’re concerned action will end there. Are there things the U.N. can do to help create more systemic change around plastic pollution?\n\nWe know that we are singling out one issue and creating awareness; this is not going to solve the entire ocean crisis, as we call it. It's a huge thing, but we have to start somewhere. We understand that this is one problem, and that it is interconnected to a broader production and consumption pattern. It has to also do with the efforts that the U.N. is doing, and the member states are doing, to combat poverty and inequality—because this has to be part of the equation as well. So, this is not an isolated environmental issue. After 25 years of experience in negotiations in the international arena, I can tell you that the only way to build a safer world—a sustainable world for the future—is about understanding holistically what the situation is. But one of the biggest challenges that we face here at the U.N. is to connect the science and the knowledge with the policy and the action.\n\nThere are still many gaps in our knowledge of the impacts of plastic pollution and the best ways to tackle it. Is there a role for the U.N. to play in terms of gathering the research that has been done, to show where gaps are and where research priorities need to be to focus the world’s efforts?\n\nWhat I think honestly, and without being a scientist in the field, is that we need to put together all the evidence that we have already. And this should be perhaps a task of U.N. Environment: to team up perhaps with a body of authority on this issue—for example, the IUCN [the International Union for the Conservation of Nature]—to bring all the evidence together and come up with very concrete policy recommendations.\n\nLast month, the Nordic countries called for a global agreement to tackle plastic pollution. Do you think there is appetite for that among member nations? And given that coordinated global action on climate change has been slow to materialize, are there ways to learn from that process to inform action on plastic? \n\nOn the plastics front, I think that there is very encouraging news. There are the two resolutions [passed by] the U.N. Environment Assembly, so this is an intergovernmental effort already. There are countries that are really thinking about an international legally binding instrument on plastic pollution, and I see that perhaps there is momentum for progress on that front. I know there are countries that are pushing for that, and as president of the General Assembly, I will be more than supportive. And perhaps this is going to be quicker than the climate negotiations.\n\nI think it's not an easy issue, but it is something where we see that it can be done. And we have so many success stories, starting with the Caribbean initiatives to ban not only single-use plastics but Styrofoam, for example. And if they can do it, the European countries can do it, the other Latin American countries can do it. India is also undertaking a very, very ambitious plan to de-plastify their economy and their society. And when India does something, it has a global effect. So, I think that the commitment is there, the drive is there, and I think the momentum also is there to advancing something perhaps more concrete, more universal, more ambitious.\n\nYou’ve also been working to reduce the use of plastic in U.N. facilities. What changes have been made on that front?\n\nYes, I am personally pushing our own community to really have a U.N. single-use-plastic–free venue—and we really need to walk the talk. It is about going to a progressive process to de-plastify the U.N. I hope that when I leave my role as president of the General Assembly, we will see fundamental changes. We have had, in only seven months of my presidency, already, some very important gains: no more plastic straws at the U.N., and we are progressively getting rid of the single-use plastic bottles. We are having very rapid responses, and we are really changing our own culture. If the U.N. cannot be a single-use-plastic-free organization, then we are in deep trouble. And so, I'm pushing hard.","title":"U.N. General Assembly President Sets Her Sights on Plastic Pollution","origin":"Policy & Ethics","image":"https://static.scientificamerican.com/sciam/cache/file/6DB0BE82-4CCC-4FAE-A1F74A028F922D36_source.jpg?w=590&h=800&2A5ED05D-2E0C-466F-B43A661CBE7B04EA","link":"https://www.scientificamerican.com/article/u-n-general-assembly-president-sets-her-sights-on-plastic-pollution/"},{"authors":"Nola Taylor Redd","pub_date":"May 9, 2019","abstract":"The mysterious source of Earth’s water has intrigued generations of scientists. Learning how this liquid—the cornerstone of life as we know it—made its way to our planet has sweeping implications, for the possibility of alien biospheres not only elsewhere in the solar system but also on worlds orbiting other stars. But understanding how water arrived on Earth has proven surprisingly difficult.\n\nAfter the sun formed from a cloud of dust and gas, the remaining protoplanetary disk of material was probably rich in water’s raw ingredients, hydrogen and oxygen. But conventional wisdom holds that the newborn star’s radiance boiled away much of those volatile gases from the inner solar system, leaving mostly dry material from which to build Earth and the other rocky planets. The majority of Earth’s moisture must have arrived later, by some other means.\n\nFor decades, scientists considered icy comets of the outer solar system as the most likely suspects, until observations revealed that most comets’ compositions did not quite match that of Earth’s oceans. And so consensus shifted toward asteroids as the source of Earth’s seas, since these rocky bodies also contain nontrivial amounts of water and are conveniently located close by, where they could have easily rained down on the young Earth. Now, however, an investigation of comet 46P/Wirtanen suggests that the bulk of Earth’s water may have come from comets after all, even though asteroids likely still played an important role.\n\nUsing NASA’s Stratospheric Observatory for Infrared Astronomy (SOFIA), an airplane-mounted telescope that can fly above much of Earth’s atmosphere, a team of researchers measured the proportion of heavy water, or deuterium, to normal water in comet 46P. Whereas the hydrogen nucleus of regular water contains a solitary neutron, deuterium’s nucleus contains both a proton and neutron, making it twice as heavy—and, more importantly, making it evaporate more slowly than normal water. This means the deuterium-to-hydrogen ratio (D/H) of any given object would be expected to vary depending on the distance at which it formed and lingered around the young sun, allowing the ratio to serve as a fingerprint for tracing water’s origins. Find a comet or asteroid with a D/H ratio identical to Earthly seawater, and you have perhaps found a chunk of undelivered ocean; obtaining D/H ratios for multiple objects may yield patterns that reveal the migration of water around the early solar system. Out of a handful of comets whose D/H ratio have been studied, comet 46P is the third known to have a D/H ratio similar to Earth’s.\n\n“It’s fantastic that they’ve got another D/H ratio,” says cometary scientist Karen Meech, of the University of Hawaii’s Institute for Astronomy. Meech was not part of the new research. “It’s very important for trying to understand what’s going on.”\n\nD/H may trace water through the young planetary disk, but it turns out to be a tricky process. Some models suggest the abundance of deuterium grows linearly moving away from the sun; others suggest the abundance shrinks under those same circumstances. Several that seek to replicate the chaotic, turbulent mixing of material in the early solar system predict deuterium abundances varying wildly at different points for no discernible reason. And observations have shown indeed that comets—even those apparently born in close proximity to each other—can have dramatically different D/H ratios. “Until now, we had a dozen measurements that looked kind of random,” says team leader Dariusz Lis, an astrophysicist at the California Institute of Technology. But 46P revealed a surprising new relationship that makes at least some of the measurements appear a little less random. Along with 46P, the other two comets known to have D/H ratios similar to Earth’s oceans, comets 103P/Hartley and 45P/Honda-Mrkos-Pajdušáková, are “hyperactive” objects, meaning they spew off more water than would be predicted based on their surface area alone. “Now, for the first time, we see a correlation between the D/H ratio … and the active fraction,” Lis says.\n\nThe results may have implications for all comets. The excess activity in hyperactive comets comes from water brought up from their interior. If, as Lis and his co-authors suggest, water from hyperactive comets’ nuclei has a more Earth-like D/H fingerprint, this may mean Earth-like water could be hidden deep inside other, nonhyperactive comets as well, putting the spotlight back on comets as an early water source.\n\nSoon to be published in the journal Astronomy & Astrophysics, the result could not only bolster the case for comets as deliverers of Earth’s water, but also tweak the initial conditions that led to life’s origins. “If you knew comets were raining down on Earth during the early stages of formation, that would have profound implications for what material was available for the very beginning stages of life,” says Maria Womack, a comet researcher at the University of South Florida who was not part of the new study.\n\nHyperactive Comets\n\nWhen comets draw close to the sun, their icy surface warms, jumping from solid to gas through a process called sublimation. Hyperactive comets such as comet 46P, however, do something more, somehow spewing off large chunks of ice into their coma, the nebulous cloud that surrounds the cometary nucleus. The tumbling ice chunks remain solid, sublimating in the coma rather than on the surface and providing the “hyper” in hyperactivity.\n\nThose solid chunks could explain the near-Earthly D/H ratio in comets like 46P. Lis and his colleagues suggest that, even if a comet’s surface material is heated and altered by the sun, its inner nucleus could remain relatively pristine for eons. On the surface, solar heat and radiation could evaporate some of the regular water, changing the ratio of normal and heavy water. Deep inside, however, those ratios may remain unchanged from their initial fingerprint (one that could match Earth’s oceans) set billions of years ago during the solar system’s formation. Heat-induced pressures in the comet trigger the release of volatile gases such as carbon dioxide or carbon monoxide, which are buried deep down in the nucleus. As the heated volatiles rise, they may push material from the nucleus to the surface, where it is blasted off to sublimate in the coma, revealing a fingerprint strikingly similar to Earth’s. If that is the case, the researchers suggest that all comets may carry water in their nucleus with a D/H ratio more like our planet’s.\n\nMeech is not yet convinced. In 2005, NASA’s Deep Impact mission blasted a crater in comet Tempel 1. Meech, who was part of that mission, says it showed that fresh material was only a few centimeters beneath the surface rather than hidden deep inside the nucleus. Thus, material blown from the heart of a comet should be similar to what is sublimating from the near-surface. Other missions to comets seem to support that finding. “Based on what was seen with the Deep Impact, EPOXI and Rosetta missions, I, don’t see any reason why the stuff [a hyperactive comet is] ejecting would be any more or less primitive than any other comet,” she says.\n\nOthers, such as comet researcher David Jewitt at the University of California, Los Angeles, are more concerned with simply getting that water to Earth. In addition to D/H ratios, celestial mechanics make a solid argument for asteroids as a dominant source of Earth’s water. Asteroids from the asteroid belt can crash into Earth much more readily than even the closest comets in the outer solar system, and research has revealed that many asteroids contain water with Earth-like fingerprints locked up inside of minerals. And, given the relative ease with which asteroids can pummel the inner planets, it is straightforward to envision them bombarding Earth in necessary numbers to fill the oceans—something that cannot be readily said for comets. According to Jewitt, all of the water in Earth’s oceans would make a single ball about 600 kilometers across or about a billion one-kilometer sized comets roughly the size of 46P. (The average comet is less than 10 kilometers across.)\n\nThe idea that all comets carry Earth-like water in their nucleus remains “a very provocative idea,” says Sean Raymond, a researcher at the Laboratoire d’Astrophysique de Bordeaux in France who models early solar system evolution. “It’s definitely one worth testing.” More in-depth laboratory tests could help reveal whether a comet hiding Earth-like water could be giving off a different D/H ratio, Jewitt says, and that could provide insights into water in the early solar system. But alone, it’s not enough.\n\nRight now, with only three hyperactive comets and a handful of regular comets having measured D/H ratios, the connection between the two remains nebulous. Fundamentally, the most important way to test whether all comets harbor Earth-like water in their nuclei is to find and study many more. “We’ve got to go out and get more of these and see if that prediction holds true,” says Edwin Bergin, a researcher at the University of Michigan who hunts for water in the protoplanetary disks around other stars. Bergin was not part of the new research.\n\nImproving technology should continue to make it easier to measure the D/H ratio of more comets from the ground, while future missions could make even more detailed observations from space. “We need more measurements,” Lis says. “We have gathered a little more than a dozen measurements in the past 25 years. That’s not enough to make a statistical study.”","title":"Hyperactive Comets Hint at Origins of Earth’s Oceans","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/5FAB160C-5BC5-4932-B2FFBBCF17EC0912_source.jpg?w=590&h=800&46059617-9BD4-45A9-BCCFA66F9F48930B","link":"https://www.scientificamerican.com/article/hyperactive-comets-hint-at-origins-of-earths-oceans/"},{"authors":"Nutrition Diva Monica Reinagel","pub_date":"May 9, 2019","abstract":"Perhaps you saw the headlines last week about a new analysis finding that people who consumed a lot of fiber are significantly less likely to die from heart disease, stroke, Type 2 diabetes, and colon cancer.\n\nHow could such a frumpy nutrient make such a big difference in our health? After all, fiber is, by definition, indigestible by humans. It provides no vitamins, minerals, or energy. And yet, fiber intake is consistently linked with lower disease risk.\n\nThere are a number of possible explanations.\n\nHow Fiber Keeps Us Healthier\n\nFirst, fiber has the charming habit of taking out the trash. Insoluble fiber acts as a sort of broom, sweeping waste material out of the large intestine and lowering the risk of colon cancer. Soluble fiber acts more like a sponge, sopping up cholesterol, thereby lowering the risk of heart disease.\n\n\n\n»Continue reading “Can Fiber Undo the Damage of a High Fat Meal?” on QuickAndDirtyTips.com","title":"Can Fiber Cancel Out Calories?","origin":"Wellness","image":"https://static.scientificamerican.com/sciam/cache/file/5C4EFA72-4A75-4CE0-B61140436ABFB52A_source.jpg?w=590&h=800&CF796776-D8D1-4DCD-8D7E0DE6F5A66445","link":"https://www.scientificamerican.com/article/can-fiber-cancel-out-calories/"},{"authors":"Get-Fit Guy Brock Armstrong","pub_date":"May 11, 2019","abstract":"I’ve been trying out various brain training regimens for a few years now. But lately, I’ve been really digging into a series of games that you play on your computer or mobile device for just a few minutes a day, every day, to boost your cognitive function. Or so it promises.\n\nLumos Labs conducted a randomized study of the Lumosity brain training system, and after ten weeks of training, the users improved their working memory, short term memory, processing speed, and overall cognitive function.\n\nCognitive Function and Fitness\n\nPersonally, aside from it being fun to feel like I’m taking a multivitamin for my brain by playing videos games every day, Lumosity (and other brain training systems available) have been showing some promising advantages in the field of exercise and sport.\n\nIn a recent paper published in the Frontiers in Psychology, scientists investigated the role of cognition and neuroscience in understanding, predicting, and potentially improving elite sports performance. Although that particular paper stated “we caution around investing too heavily in such methods at this point in time” I feel like it is a no-lose situation. Even if it doesn’t help me bust out a faster time in my next triathlon, I am still doing something better for my brain than staring at reruns of The Simpsons.\n\n\n\n»Continue reading “How Your Brain Keeps Your Body Fit” on QuickAndDirtyTips.com","title":"How Your Brain Keeps Your Body Fit","origin":"Wellness","image":"https://static.scientificamerican.com/sciam/cache/file/BF996B25-0903-465A-BAC35ADC7B8B96DF_source.jpg?w=590&h=800&7387BC65-2B70-4F35-8A0E1B51FB3314C3","link":"https://www.scientificamerican.com/article/how-your-brain-keeps-your-body-fit/"},{"authors":"Saad B Omer, Robb Butler","pub_date":"May 9, 2019","abstract":"At the beginning of this year, the World Health Organization (WHO) issued a list of top 10 threats to Global Health. These threats ranged from climate change and non-communicable diseases, to antimicrobial resistance and vaccine hesitancy. The list also included HIV, dengue, weak primary care, fragile and vulnerable settings (e.g. regions with drought and conflict), Ebola, and threat of a global influenza pandemic.\n\nOne underlying theme is the relevance of human behavior to many, if not all, of these threats. For some global health threats, the connection is obvious: non-communicable diseases and their associated behavioral risk factors (i.e. smoking or poor diet), or the reluctance of some parents to vaccinate their children and over-prescription and over-demand of antibiotics—a reason for emergence of antibiotic resistance—have clear behavioral connotations. For many others, the link is less obvious but equally important. For example, human behavior is largely at the center of global climate change and will be at the core of any substantial response to it. Similarly, HIV prevention, avoiding dengue carrying mosquitos, shoring up primary care delivery, and responding to Ebola and influenza outbreaks require modifying or working with human behavior.   \n\nAnd yet, the global health response to these threats lacks a coherent focus on behavioral insights. In recent years, fields such as economics and poverty alleviation have embraced behavioral insights as central to understanding and responding to major challenges in these fields. The 2002 and 2017 Nobel prizes in economics were awarded for research on behavioral economics. While behavioral tools have been used for health promotion for several decades, they are inconsistently included in global health policy-making.\n\nFortunately, there are a few models for incorporating insights from behavioral research into large-scale policy initiatives. One approach, used by many governments and some multi-lateral institutions, is establishing so called “nudge units.” These units use lessons from behavioral economics and psychology to inform public policy.\n\nThe first such unit, officially called the Behavioral Insights Team, was established in the United Kingdom in 2010 and was initially based within the UK Cabinet Office. It now exists as a company co-owned by the Cabinet Office. The Obama administration established a U.S. nudge unit, initially known as the White House Social and Behavioral Sciences Team. This unit has evolved into the Office of Evaluation Science within the General Services Administration. Other countries such as Australia and Singapore have established similar entities. In fact, the concept of promoting behavioral insights-based policy-making has also been adopted by multi-lateral organizations such as the World Bank and the Organization for Economic Co-operation and Development.\n\nWhile not every program initiated by a nudge unit has been equally successful, there are plenty of examples of policy interventions that establish the utility of these units. For example, the UK nudge unit demonstrated that behavioral insights can be used to reduce medication errors, increase commitment to organ donations, and ensure that people show up for their doctor’s appointments.\n\nDr. Tedros Adhanom Ghebreyesus, the WHO Director General who soon after his election to this position promised “a transformed WHO,” has encouraged countries and the WHO’s partners to deliver people-centered care.  Last month, Dr. Tedros (as he prefers to be called) announced a major restructuring of the WHO. He also indicated that “the process of fully implementing the new operating model will take more time.” This period of transition is precisely the right time for establishing a nudge unit at WHO.\n\nWhile there are templates of effective nudge units from various countries and organizations, WHO’s behavioral insights unit will have to reflect its own unique role: First, a WHO nudge unit should support ministries of health of WHO Member States in addition to working with WHO’s core programs—including the newly established health emergencies program.  Second, global health problems are multi-faceted and, therefore, require interdisciplinary solutions. A WHO nudge unit must be staffed by individuals with diverse backgrounds, not just those from the social sciences or medical humanities but also epidemiologists and public health practitioners with behavioral sciences training. Lastly, all initiatives of this unit must be evidence-based and all new interventions must be rigorously evaluated—a tradition upheld by effective nudge units.\n\nAs heath ministers and global health leaders prepare to convene at the World Health Assembly in Geneva this month, the WHO would be well-advised to reflect. The WHO was established to advance human health—and human behavior is a core determinant of human health and well-being. Now is the time for this fact to fully accommodated in its structure and programs.","title":"The World Health Organization Needs to Put Human Behavior at the Center of Its Initiatives","origin":"Behavior & Society","image":"https://static.scientificamerican.com/sciam/cache/file/335E727C-96C0-482B-9650EDE41486F929_source.jpg?w=590&h=800&91F3CB27-E15A-437B-B30046818A09AF5A","link":"https://www.scientificamerican.com/article/the-world-health-organization-needs-to-put-human-behavior-at-the-center-of-its-initiatives/"},{"authors":"Chelsea Harvey, E&E News","pub_date":"May 9, 2019","abstract":"With spring in full bloom, winter’s last stores of snow are beginning to melt. As they do, they’ll release much-needed fresh water into streams or the surrounding soil, fueling plant growth and replenishing drinking resources for communities.\n\nIt’s one of nature’s most important annual rituals.\n\nBut how soon the snow starts to liquefy, and how quickly it disappears, may depend on more than just the outside temperature. Scientists are finding that wildfires in the western United States may alter the landscape in ways that lead to earlier, faster snowmelt.\n\nThat’s a big concern for Western water resources. If the snowpack melts and runs off too quickly, it could cause regional freshwater resources to dry up before the cooler fall temperatures set in, increasing the probability of drought.\n\nBut there’s another concern, as well. Many researchers believe a faster snowmelt and a drier summer landscape may also worsen the fire season in some areas, leading to bigger, hotter blazes.\n\nThe whole process offers the possibility of a climate feedback cycle, said researcher Kelly Gleason of the Desert Research Institute in Nevada. Wildfires lead to faster melting, and faster melting in turn leads to more wildfires.\n\n“Earlier snowmelt is already linked to big fires in the mountains,” she said. “And that those fires could be feeding back and accelerating that snowmelt further—there’s this kind of vicious cycle that’s occurring, or we think is occurring.”\n\nGleason, along with other colleagues from the Desert Research Institute and the University of Nevada, has just published a new study that demonstrates the side effects of wildfires on snow, using a combination of satellite observations from across the West and snow samples from sites in Colorado, Wyoming and Utah.\n\nThe research finds that snow starts to melt about five days earlier in the season after a fire has occurred on the landscape. And based on satellite data from the 1980s onward, it suggests that earlier melting may persist for at least a decade after a fire has occurred.\n\nThis happens for several reasons, according to Gleason.\n\nWildfires tend to clear out the forest canopy, leaving more space for sunlight to get through the trees and warm up the snow. They also leave behind burned leaves and branches, which drop bits of ash and char onto the snow below. These burned bits darken the bright white surface of the snow, causing it to absorb more solar energy.\n\nBetween 1999 and 2018, the researchers found that there’s been about a fourfold increase in the amount of solar energy being absorbed by the Western snowpack after the occurrence of wildfires. They also note that Western forests in the seasonal “snow zone”—that is, forests that also see winter snow cover—are experiencing more wildfires, with the total burned area increasing by about 9% every year.\n\nAltogether, the researchers estimate that about 11% of all Western forests in the snow zone are absorbing more solar energy and melting earlier as a result of wildfires.\n\nThe new study only demonstrates the effects of wildfires on snow—not the other way around. But other research has pointed to potential links between earlier snowmelt and the Western fire season.\n\nAt the annual meeting of the American Geophysical Union in December, University of Maryland doctoral candidate Donal O’Leary presented new research on the timing of snowmelt and the severity of fire seasons in the Western states. He found that the effects are not the same on every kind of landscape. But in most forested areas, early snowmelt is associated with a greater amount of burned area during the fire season.\n\nSuch findings would seem to suggest that, in some Western forests, the effects of wildfire on snowmelt and snowmelt on wildfire may be able to mutually fuel each other.\n\n“I want to say that this is a really important, groundbreaking paper, because it shows us for the first time snowpack feeding back to fire regimes in a very direct, mechanistic way,” said wildfire expert Donald Falk of the University of Arizona, who commented on the new research for E&E News. “They highlight this as a much more highly interactive system than we’ve understood previously.”\n\nIn future research, it may be useful to collect snow samples from a wider variety of landscapes across the Western states, to be sure the same effects hold true throughout the region, Falk noted. But generally, he said, the study “absolutely suggests a kind of local landscape-level feedback, which we really haven’t understood as well.”\n\nAt the same time, the researchers suggest, climate change is likely making the entire process more sensitive.\n\nNumerous studies suggest that rising temperatures are causing the total snowpack area to shrink in the Western states, while snow is also accumulating later in the fall and melting earlier in the spring (Climatewire, Dec. 13, 2018). Models project that this effect will worsen as the climate continues to warm.\n\nCombined with the effects of climate change, the influence of wildfires just makes an already vulnerable snowpack even more sensitive to the sun, Gleason noted.\n\n“Climate change is already melting snowpack and increasing forest fires,” she said. “But then there’s this feedback, which could amplify that impact earlier.”\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"In “Vicious Cycle,” Snowmelt Fuels Wildfires and Wildfires Melt Snow","origin":"EARTH","image":"https://static.scientificamerican.com/sciam/cache/file/A1A872A3-4640-4A85-8DBB031AF8765DC2_source.jpg?w=590&h=800&1C0C50FA-655A-4002-B79B44E9FFAA6252","link":"https://www.scientificamerican.com/article/in-vicious-cycle-snowmelt-fuels-wildfires-and-wildfires-melt-snow/"},{"authors":"THE EDITORS","pub_date":"September 1, 2017","abstract":"Editor’s Note (5/8/19): This article is being republished because Georgia’s governor signed a bill into law Tuesday that bans abortions as soon as a fetal heartbeat can be detected, as early as six weeks into a pregnancy.\n\nThere's something rotten in the state of women's health. As this article is being written in July, Republicans in Congress are engaged in a frenzied effort to repeal and replace the Affordable Care Act (ACA) put in place by the Obama administration. At least 22 million Americans would lose medical insurance by 2026 under the latest version of this plan—which includes large cuts to Medicaid—and lack of insurance means more sickness and death for thousands, data show. These cuts threaten to affect women more than men—whether by removing basic health coverage, cutting maternity care or sharply limiting reproductive rights.\n\nIt's time to take a stand against this war on women's health.\n\nCurrent events are just the latest insult in a long history of male-centric medicine, often driven not by politicians but by scientists and physicians. Before the National Institutes of Health Revitalization Act of 1993, which required the inclusion of women and minorities in final-stage medication and therapy trials, women were actively excluded from such tests because scientists worried that female hormonal cycles would interfere with the results. The omission meant women did not know how drugs would affect them. They respond differently to illness and medication than men do, and even today those differences are inadequately understood. Women report more intense pain than men in almost every category of disease, and we do not know why. Heart disease is the number-one killer of women in the U. S., yet only a third of clinical trial subjects in cardiovascular research are female—and fewer than a third of trials that include women report results by sex.\n\nThe Republican assault on health care will just make things worse. The proposed legislation includes provisions that would let states eliminate services known as “essential health benefits,” which include maternity care. Before the ACA made coverage mandatory, eight out of 10 insurance plans for individuals and small businesses did not cover such care. The proposed cuts would have little effect on reducing insurance premiums, and the cost would be shifted to women and their families—who would have to take out private insurance or go on Medicaid (which the proposed bill greatly limits)—or to hospitals, which are required by law to provide maternity care to uninsured mothers.\n\nThe bill, in its current form, would also effectively block funding for Planned Parenthood, which provides reproductive health services to 2.4 million women and men. The clinics are already banned from using federal funding for abortions except in cases of rape or incest or when the mother's life is in danger, in accordance with the federal Hyde Amendment. So the Planned Parenthood cuts would primarily affect routine health services such as gynecological exams, cancer screenings, STD testing and contraception—and these clinics are sometimes the only source for such care. Regardless of which side you are on in the pro-life/pro-choice debate, these attempts to remove access to such basic services should alarm us all.\n\nThe Trump administration also has been chipping away at the ACA's birth-control mandate. A proposed regulation leaked in May suggested the White House was working to create an exemption to allow almost any employer to opt out of covering contraception on religious or moral grounds. Nationwide, women are increasingly turning to highly effective long-acting reversible contraceptives (LARCs) such as intrauterine devices (IUDs). The percentage of women aged 15 to 44 using LARCs increased nearly fivefold from 2002 to 2013. Decreased coverage for contraceptives translates to less widespread use and will likely mean more unintended pregnancies and abortions.\n\nAnd abortions will become harder to obtain. After Roe v. Wade, many states tried to put in place laws to hamstring abortion clinics. These efforts have only ramped up in recent years, as many states have enacted so-called TRAP laws (short for targeted regulation of abortion providers), unnecessarily burdensome regulations that make it very difficult for these clinics to operate. Recognizing this fact, the Supreme Court struck down some of these laws in Texas in 2016, but many are still in place in other states. Rather than making women safer, as proponents claim, these restrictions interfere with their Supreme Court–affirmed right to safely terminate a pregnancy.\n\nWhether or not the repeal-and-replace legislation passes this year, these attacks are part of a larger war on women's health that is not likely to abate anytime soon. We must resist this assault. Never mind “America First”—it's time to put women first.","title":"It’s Time to End the War on Women’s Health","origin":"Public Health","image":"https://static.scientificamerican.com/sciam/cache/file/C1DEB68A-DD7C-40C9-A715C0BD5C2DFED1_source.jpg?w=590&h=800&D8646F89-7E8B-4150-8212D9ACA4602802","link":"https://www.scientificamerican.com/article/it-rsquo-s-time-to-end-the-war-on-women-rsquo-s-health/"},{"authors":"Jennifer Frazer","pub_date":"May 2, 2019","abstract":"The fire chaser beetle, as its name implies, spends its life trying to find a forest fire.\n\nWhy a creature would choose to enter a situation from which all other forest creatures are enthusiastically attempting to exit is a compelling question of natural history. But it turns out the beetle has a very good reason. Freshly burnt trees are fire chaser beetle baby food. Their only baby food.\n\nFire chaser beetles are thus so hell bent on that objective that they have been known to bite firefighters, mistaking them, perhaps, for unusually squishy and unpleasant-smelling trees.\n\nThey have descended on at least one UC Berkeley football game at California Memorial Stadium -- rather unfortunately situated in the midst of some recently burnt pine hills -- at which an estimated 20,000 cigarettes were being smoked. The beetles’ disappointment on discovering the source of the “fire” was probably only matched by the irritation of the smokers swatting confused beetles attempting to bite their necks and hands.\n\nThey have shown up on hot pipes and other equipment at lumber yards and sugar mills, tar plants, cement kilns, smelters, and on one occasion, a colossal 1925 oil tank explosion in Coalinga, California. In that last case, the flames reached hundreds of feet into the air and were visible for over 30 miles … but the nearest plausible beetle-bearing forest was 80 miles away.\n\nThat last detail implies something amazing about fire chaser beetles: they can sense fires from distances over which car stereos are hard pressed to pick up FM radio.\n\nIn fact, because the infrared emission of a burning oil tank of known volume (in this case, 750,000 barrels) can be calculated with reasonable certainty, scientists that studied the Coalinga oil tank explosion have inferred the beetles can detect infrared radiation intensities so low that they are buried in the thermal noise around them. But … how?\n\nInfrared radiation, a proxy for heat, is a reliable source of information about fire because it propagates outward in a clear gradient, dampened only by humidity. It gives a very accurate indication of distance and direction from the source. A highly sensitive infrared sensor can detect a surface fire from space.\n\nA flying fire chaser beetle appears to be trying to give itself up to the authorities. Its second set of legs reach for the sky at what appears to be an awkward and uncomfortable angle.\n\n\n\tFire chaser beetle flying posture (top), heat eye (middle), and cross section of an individual sensillum in the array (bottom). Credit: Schmitz and Bleckmann 1998\n\n\nBut the beetle has a good reason. It’s getting its legs out of the way of its heat eyes, pits filled with infrared sensors tucked just behind its legs.\n\nThe heat eyes on the sides of fire chaser beetles are filled with about 70 infrared sensilla. Inside each sensillum is a hair-like sensor (called a dendritic tip in the diagram above) that physically deforms when the sensillum expands in response to heat, triggering a neural response.\n\nSuch arthropod hair sensors are incredibly sensitive. Spiders possess versions called trichobothria that detect air movement – such as that caused by movement of web or prey – with such sensitivity that they are tripped by levels not much higher than the random movement of air molecules (Brownian motion), or, as the authors of recent paper on the oil-tank-fire-beetle-sensitivity-question put it, “at the limit of the physically possible”.\n\nIn addition to containing similar hypersensitive mechanoreceptors, the sensilla in fire chaser beetle heat eyes are found in arrays of 70-90. A signal picked up by more than one of them can be summed up and amplified by the neurons that wire the array. As a result, the heat eye can detect softer signals than a single sensor could.\n\nFinally, it is also possible the beetles are better able to detect a signal buried in noise due to a spooky (to me) phenomenon called “stochastic resonance”. In this scenario, added thermal noise counterintuitively helps a sensor pick up a signal.\n\nA signal below the threshold for triggering a sensor – but still close to it – will resonate by chance with a portion of thermal noise that is the same frequency. When there is more noise, there is more signal at that resonant frequency. Together, noise plus signal adds up to an impulse sufficient enough to trip the sensor when signal alone or signal with less noise would not. Incredibly, the measurement gets more precise in the presence of noise than without.\n\nThough deeply counterintuitive, stochastic resonance has been demonstrated over and over in biological systems, including several times in humans. For example, humans can detect a touch stimulus that would normally be undetectable when they are exposed to a mechanical vibration at the same time. The portion of the vibration that “resonates” with the touch sums to trigger mechanoreceptors in skin. Crazy but true.\n\nThus, though the fire chaser beetle’s ability to detect fire may seem supernatural, it may operate on physical principles that are also at our very own fingertips.\n\nReferences\n\nSchmitz, H., and H. Bleckmann. \"The photomechanic infrared receptor for the detection of forest fires in the beetle Melanophila acuminata (Coleoptera: Buprestidae).\" Journal of Comparative Physiology A 182, no. 5 (1998): 647-657.\n\nSchmitz, H., and H. Bousack. \"Modelling a historic oil-tank fire allows an estimation of the sensitivity of the infrared receptors in pyrophilous Melanophila beetles.\" PLoS One 7, no. 5 (2012): e37627.","title":"How a Half-Inch Beetle Finds Fires 80 Miles Away","origin":"The Artful Amoeba","image":"https://static.scientificamerican.com/blogs/cache/file/1EE77E5A-293D-428E-AE545E111D202764_source.jpg?w=590&h=800&CE1F9762-3583-4233-A82C7BD12B2E176C","link":"https://blogs.scientificamerican.com/artful-amoeba/how-a-half-inch-beetle-finds-fires-80-miles-away/"},{"authors":"Christopher Intagliata","pub_date":"May 8, 2019","abstract":"By dampening the energy of waves, coral reefs protect coastal cities from flooding damage and other economic losses. Christopher Intagliata reports.","title":"U.S. Coral Reefs Do $1.8 Billion of Work Per Year","origin":"Natural Disasters 60-Second ScienceSubscribe:Apple iTunesRSS","image":"https://static.scientificamerican.com/sciam/cache/file/C92D4CA4-EAF1-41B8-8081202A6FC06A48_source.jpg?w=590&h=800&393C1B23-444C-4660-907929A65CB17EFC","link":"https://www.scientificamerican.com/podcast/episode/u-s-coral-reefs-do-1-8-billion-of-work-per-year/"},{"authors":"Kelly Reidy","pub_date":"May 10, 2019","abstract":"Dragons are not new. Game of Thrones tells us that they date back to some arguably medieval time, which may or may not predate the adventures of Smaug, the dragon from The Hobbit. In the nonfiction world, Christian legend tells of St. George slaying a dragon, and that tale probably derives from pre-Christian stories. Dragons show up in Chinese mythology as well—and in Bhutan, the Druk, or thunder dragon, is emblazoned on the national flag. And in fact, anthropologists have found dragons in art spanning thousands of years and independently created by people from all over the world.\n\nThe ubiquity of dragons across time and space may be related to fears inherited from some of humans’ most adorable ancestors: vervet monkeys. In his book An Instinct for Dragons, David E. Jones cites a study showing that these primates have an innate fear of lions, snakes and eagles. That’s a recipe for a dragon if I’ve ever heard one! Thus, humans may be evolutionarily predisposed to fear these animals.\n\nBut this only leads to more questions: What about the fire-breathing capabilities of European dragons, or the rain-bringing skills of Asian dragons, or the people-eating habits of Maori dragons? And why do some dragons fly while others slither?\n\nThe appearance, behavior and general level of horror of dragons vary wildly across cultures. These differences can tell us something about the natural history of their creators; this is where both local fears and local fauna play a role.\n\nIn northern China, around 300 B.C., workers digging a canal came across a fossilized animal skeleton. Remember that the theory of evolution wasn’t a thing yet, so people assumed this was the skeleton of an existing creature rather than the extinct nonavian dinosaur that it probably was. It went on record as a dragon skeleton—more fuel for the long-existing fire of Chinese dragon mythology.\n\nDragons appear in Chinese art from at least as far back as 1100 B.C. These dragons are relatively tame-looking and typically serpentine, with multiple sets of legs and a vaguely lion-like head. They don’t have wings, but they can fly. Two ancient Chinese rulers declared themselves to be direct descendent of dragons, and so dragons in many Chinese cultures became symbols of power. Contrary to the gut feeling you might be having right now, these dragons are generally seen as wise and benevolent—heroic, even—bringing rain to dry crops and pretty much saving entire civilizations.\n\nIn Europe, on the other hand, dragons are usually the bad guys. European dragon myths feature dragons as vicious monsters whose raison d’être involves getting slain by saints who need hero credibility. St. George, known primarily as a dragon-slayer, is now the patron saint of England and even has his own holiday on April 23.\n\nAppearance-wise, these European dragons are a little wackier than their Asian cousins. They look more like snake/eagle/lion combinations straight out of your worst fever dreams. Usually they have legs and wings and a snake tongue, sometimes fur, sometimes scales, sometimes both. For good measure, they can also breathe fire—the fire-breathing animals in Hieronymus Bosch’s delightful Renaissance-era paintings of hell may have been an inspiration for this feature. The very real and very prehistoric-looking Nile crocodile might also have been an influence, as it regularly swam up to European shores from Egypt and traipsed around on land.\n\nFurther south, in New Zealand, the taniwha are dragon-like creatures from Maori mythology. In this case, take the basic snake/eagle/lion innate-fear combo and add something more local: the great white shark. In fact, the Maori word for great white shark is mangō-taniwha. But don’t worry too much, as these creatures can be benevolent protectors—sometimes. At other times, they can be totally horrifying people-eaters. As a cherry on top of that nightmare cake, note also that in some stories, taniwha have shape-shifting abilities.\n\nAfter thousands of years of international dragon mythology, you’d be forgiven for thinking that their moment has passed.\n\nBut dragons continue to spark our curiosity and captivate our imaginations; today, they make appearances in pop culture via The Lord of the Rings, Dungeons & Dragons (and by extension, Stranger Things), Game of Thrones and even in band names like Imagine Dragons and DragonForce.\n\nThese pop dragons are mostly European-style in appearance, but their roles are more complex than the traditional Western “set ‘em up, knock ‘em down” scheme. They run the gamut from the occasionally disagreeable allies in Game of Thrones to the well-spoken monster in The Hobbit.\n\nEither way, stay vigilant, dear reader, because if Game of Thrones has taught us anything, it’s that “the night is dark and full of terror.”","title":"Here Be Dragons","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/40605986-E95F-4666-AA679D0D6D54725C_source.jpg?w=590&h=800&13F244E9-0C39-47D0-9EDA5DE9BA857B00","link":"https://blogs.scientificamerican.com/observations/here-be-dragons/"},{"authors":"Sandro Galea","pub_date":"May 9, 2019","abstract":"This month, the world saw the first-ever image of a black hole. The picture was captured by the Event Horizon Telescope, a network of radio telescopes operated by a global team of scientists. The black hole is 53.49 million light-years away, at the center of the Messier 87 galaxy. Taking a picture of such a distant object was an immense feat of science and engineering. The roots of this achievement stretch from Einstein’s first theorizing about the existence of black holes, all the way to the creation of cutting-edge technology that allowed us to finally see one.\n\nSuch stories are reminders of why it sometimes feels like science can do anything, from exploring the cosmos, to peering into the distant past, to blurring the boundary between life and death. And that feeling often extends to the science that informs our health. On that front, the 20th century brought a host of major discoveries, from penicillin to the double helix. As the Digital Age ushers in new advances, it is as easy as it has ever been to imagine that science really can solve all our health problems one day.\n\nOur behavior suggests we may even hope that, through the power of science, we can one day innovate our way out of the human condition—the inevitability of age and death. Consider: the United States spends far more on health care than any other country in the world. The vast majority of this spending goes to the drugs and treatments that are the fruits of scientific discovery. With this sky-high spending have come sky-high expectations.\n\nWe eagerly await the drugs that will cure dreaded diseases like cancer and AIDS. We are fascinated by the evolution of precision medicine, with its possibility of tailoring treatment to an individual’s specific lifestyle and genetic code. And we thrill at the notion that technology might extend life indefinitely, that we can someday “hack” mortality, if we can only get the science right.\n\nThese hopes inform a spirit of exploration, one that we should nurture. Yet unbounded confidence in science can also distract us from the core forces that underlie our lives and health—forces far larger than any theorem, technology or cure.\n\nEach day, we are deeply influenced by the social, economic and environmental conditions that surround us. These conditions are at the heart of how our lives unfold, deciding whether we are sick or well. We must have the humility to acknowledge the influence of these forces. When we do not, we open the door to hubris, and risk undermining the very goals we accumulate knowledge to pursue.\n\nThere are ample examples of how we have neglected the foundational forces that shape health, even as we have poured resources into developing new treatments. Take asthma. If a child has asthma, science can indeed provide her with medicine for her illness. But why does she have asthma to begin with? Could it be because she is a child of color, a demographic with a higher asthma risk? Or because she grew up in an economically disadvantaged neighborhood, located near a pollution center like a major roadway, as such neighborhoods often are?\n\nOr could it even be because of political decisions to build the neighborhood in such an inopportune location? We are less likely to ask these questions when we think that the only action we need take to address an illness like asthma is to design ever-better treatments for it. While we often do not think of health in this way, we are effectively letting six million children live with a preventable disease like asthma because we are distracted by the flashy potential of high-tech science, at the expense of solutions that are at hand. \n\nWhat about the continued existence of HIV, a disease for which we have excellent treatments, but which nevertheless persists in some countries due to the forces of poverty, stigma and political negligence? In such cases, our medical advances are simply not enough. We need the humility to recognize that we cannot end these diseases without tackling forces that exist outside the realm of scientific innovation, whose influence can only be checked by collective effort and the application of political will.     \n\nThere is nothing wrong with making better medicines. A cure for asthma or HIV would indeed be welcome. But would it not be better to live in a world where these diseases no longer exist? To get this world, we must have the humility to see that there is more to health than our capacity to cure disease and extend life. Health emerges from our shared context—from the air we breathe, the water we drink, our economy, politics, schools, workplace safety laws, corporate practices and other large-scale influences.\n\nI discuss these influences in my new book, Well: What We Need to Talk About When We Talk About Health. Engaging with them, to improve health, means first recognizing their scope, how they are bigger than any one person, and that they can only be properly addressed when we work together, with humility.\n\nTake another look at the black hole image. It is a ring of light against vast darkness. This sliver of light, framed by the dark of space, is a useful metaphor for the relative smallness of what we know compared to the tremendous scope of what we do not. Our health, like our universe, is shaped by forces that dwarf even our most brilliant advances and discoveries. It is only by having the humility to recognize this that we can begin to move, collectively, towards a healthier future.","title":"Humility Is the First Step toward a Healthier World","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/FA118E13-9551-4DA8-B0F44BC85E8AC486_source.jpg?w=590&h=800&05000FA2-0B63-4D16-829C5FFC5B804862","link":"https://blogs.scientificamerican.com/observations/humility-is-the-first-step-toward-a-healthier-world/"},{"authors":"Steve Mirsky","pub_date":"May 13, 2019","abstract":"In the first chapter of the new book Upheaval: Turning Points for Nations in Crisis, author Jared Diamond describes a crisis of his own. He was 21 and had always excelled academically—until he entered a doctoral program in physiology at the University of Cambridge.\n\nDiamond was charged with measuring the movement of sodium and potassium ions across the electricity-generating membranes of eels. But he had never been good with his hands and was utterly unable to design and build the equipment he needed to perform that task.\n\nSo Diamond switched to a technically easier assignment, which required simply weighing a fish gallbladder to determine its fluid content, then measuring a voltage. But even this simple method to analyze sodium and water transport gave him fits, as no voltages appeared. He seriously considered quitting and finding another career, but decided to give it one more semester.\n\nTwo young faculty researchers helped Diamond solve his technical issues, and he started to get results. He went on to finish his PhD and reinvent himself as an ornithologist and historian. More than 50 years later he is an internationally recognized scientist and writer, having won the U.S. National Medal of Science, a MacArthur Foundation fellowship (commonly called the “genius grant”) and a Pulitzer Prize for his book Guns, Germs and Steel: The Fates of Human Societies. His youthful failure was in fact a springboard.\n\nI have not achieved Jared Diamond’s level of success, but I strongly relate to his story. As Digital Science is running a social media campaign about acknowledging and learning from failure (you can share your own failures with #failtales), I thought I’d tell my story.\n\nI too had a history of academic achievement. I finished an undergraduate degree in chemistry and was accepted at Cornell University for graduate school. The chairman of the chem department was Roald Hoffmann, who had recently won the Nobel Prize and who was my advisor during my first semester. I later chose an advisor with whom I planned to do research for a doctoral thesis.\n\nGraduate school was a shock to my system. For the first time in my life, I hit a wall in my ability to understand information I was expected to digest. I found it increasingly difficult to concentrate on my work and became depressed.\n\nSo I played hooky. And where was the perfect place to not work while looking like one was working? Why, the library. My own science was going nowhere, but I still loved science. So I started reading science magazines. Stephen Jay Gould was writing his monthly columns in Natural History, and I became fascinated with evolutionary theory. I could hardly wait for the next issue of the New Yorker that featured another installment of a five-part series by E.J. Kahn about staple foods—which 35 years later I still remember were corn, wheat, potatoes, soy and rice. And from Scientific American I read articles about everything.\n\n(A few years ago I saw the Kahn staple-food series described as one of the most tedious pieces of magazine journalism every published. I laughed, because for me they were as thrilling as reading Dumas: corn was The Count of Monte Cristo, wheat was The Three Musketeers.)\n\nOne day at the beginning of the second semester of my second year of grad school, I was browsing through an issue of Science when I saw an advertisement for a Mass Media Science and Engineering Fellowship from the American Association for the Advancement of Science. Graduate students in the sciences who received the fellowship would spend the summer at a newspaper, magazine, radio outlet or television outlet as science reporters. I remember reading the ad and thinking, “Weird.” But the next day I looked at the ad again and thought, “Wait. This is what you should be doing.” I applied for and got the fellowship, along with about another 15 grad students around the country.\n\nI announced that I would be leaving Cornell at the end of the semester to do the fellowship and then pursue a career in science journalism. I could take oral exams for a “terminal” Master’s Degree. I studied my butt off and fortunately closely reviewed some material that I was actually asked about during the three-hour ordeal. I got the degree, which I often think of as the “lovely parting gift” that unsuccessful contestants received on game shows. Hoffmann asked me to reconsider leaving the program, but I was sure I was doing the right thing, for me. I left a couple of days later for my fellowship site, WSVN-TV in Miami. After two winters in upstate New York, I would spend the summer of 1985 in south Florida. (I can’t recommend either.)\n\nI took to science journalism—it fulfilled my terms of gratification. The journalist David Epstein exactly captured my feelings in his new book Range: “I worked in labs during and after college and realized that I was not the type of person who wanted to spend my entire life learning one or two things new to the world, but rather the type who wanted constantly to learn things new to me and share them.” Bingo!\n\nWhile in Miami I saw another ad, this one in Broadcasting magazine, advertising an on-air position opening at a small radio station back in upstate New York. I had always loved radio—as a kid I listened to Jean Shepherd, Barry Farber and Big Wilson, names that may ring a bell to a certain demographic—and I parlayed my summer TV gig into a year as a radio morning man. I got a job offer at a 50,000-watt station in Albany, but turned it down to go home to New York City and try writing for print.\n\nI eventually applied for a job at Scientific American—which I did not get. But a few years later I started freelancing for SciAm and then was hired as a writer and editor. I have been writing a monthly column in the magazine for more than 23 years. (Gould did his at Natural History for 25 years, a mark I hope to equal.)\n\nThe radio experience came in handy when, in 2005, Scientific American decided to start podcasts and asked me to head up that effort. We have now produced more than 4,000 episodes of our short podcasts, primarily 60-Second Science, and almost 500 of the in-depth Science Talk.\n\nI kept in touch with Roald Hoffmann over the years. At one point I ran into him at an event in New York City where an acquaintance of mine attempted to introduce us. Roald stopped my friend and said, “Oh, I know Steve. He’s one of our most successful failures.”","title":"If At First You Don't Succeed","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/64434CF6-863F-4716-B814445485156197_source.jpg?w=590&h=800&FF2AC74D-512E-4EC4-A9E7DF7C284DA72A","link":"https://blogs.scientificamerican.com/observations/if-at-first-you-dont-succeed/"},{"authors":"Meredith Bashaw, Stephanie Allard","pub_date":"May 10, 2019","abstract":"I yawn and stretch, then climb to the top of the moss pile to soak up some warmth. Next I’ll check out that spot by the water where I found those yummy bugs yesterday. It’s shaping up to be another good day.\n\nThe critter above is a Houston toad (Anaxyrus houstonensis), an endangered species of amphibian. He lives at the Houston Zoo and is part of a zoo-based breeding program called the Houston Toad Recovery Project.\n\nThere sometimes exists a public perception that zoo animals live in sterile cages and suffer unrelenting boredom or even fear. Historically, zoos were created primarily for entertainment purposes and simply prioritized keeping animals visible and habitats clean. While this does help visitors see animals and animals stay healthy, it isn’t sufficient for allowing animals to lead rich and fulfilling lives. Fortunately for both human and nonhuman animals, modern accredited zoos and aquariums like the Houston Zoo hold themselves to higher standards.\n\nAccredited zoos agree to undergo voluntary review by a panel of industry experts to ensure that everything from their financial security to their animal care is state of the art. These zoos and their accrediting organizations have become focused on animal well-being, recognizing that animals in their care need to thrive rather than just survive.\n\nThey also increasingly include conservation in their mission statements and contribute expertise, time and funding to supporting that effort. Accredited zoos have transformed their operations to benefit animals in their care and in the wild, while still providing the public a fun, awe-inspiring experience.\n\nHow do they achieve such lofty goals? Increasingly, they use science. Between 1993 and 2013, zoos and aquariums accredited by the Association of Zoos and Aquariums (AZA) published 5,175 peer-reviewed scientific manuscripts on a wide array of topics, including animal care and conservation.\n\nZoos and partner organizations conduct animal welfare research to evaluate how animals in their care see (or hear or smell) the world and what behaviors motivate them. Keepers then find innovative ways to enrich animals’ lives by creating opportunities for these skills and behaviors. For ectothermic animals like reptiles and amphibians, thermoregulation and foraging are highly-motivated behaviors, so creating opportunities for these behaviors improves well-being.\n\nThe Houston toad above, for instance, isn’t simply hand-fed a diet of bugs. Instead, the zoo simulates the same processes the toad would need to perfect in order to find food in the wild, placing bugs inside crevices and other hiding spots.\n\nFood puzzles use that concept to give carnivores mental and physical exercise, as well as the thrill of the hunt. Zoos recognize that while achieving a goal—like getting food—is valuable to animals, so is the process of using their skills to reach that goal. As a result, zoos increasingly design environments to empower animals to make meaningful choices about what to do, when, and with whom and to enable them to exert some control over their surroundings.\n\nWhile animals are already reaping the benefits of advances in research and zoo design, there’s still much we don’t know about how animals of different species perceive their environments and what they value. As research improves our understanding of animals’ perspectives, zoos will need to stay nimble and continually improve so that every animal in their care can thrive.\n\nZoos also conserve wildlife and wild places around the world. Zoos accredited by the AZA spent more than $200 million on field conservation initiatives in 2017, and zoos belonging to other regional accrediting organizations are also active in conservation. AZA zoos’ efforts benefitted 863 species in 128 countries, including the Houston toad.\n\nThe Houston Zoo first started breeding Houston toads to supplement the wild population in 1978. The zoo reestablished an “assurance population” in 2007; the captive colony maintained by the institution ensures that prolonged drought, wildfires, highways and development won’t result in these toads’ extinction. Today, the Houston Zoo partners with the U.S. Fish and Wildlife Service, the Texas Parks and Wildlife Department, Texas State University and the Fort Worth Zoo to breed Houston toads and restock local ponds; in 2017 alone, the Houston Zoo released 930,000 captive-bred eggs into the Houston toad’s native habitat.\n\nThese types of programs are critical to safeguarding species in the wild. Biodiversity is threatened around the globe, with amphibians in particularly acute crisis. It is imperative that zoos continue to strengthen their conservation efforts. Captive toads in the Houston Zoo’s breeding program won’t necessarily make their way back into the wild, but their kids will.","title":"Modern Zoos Aren’t Just for Entertainment","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/458BEFED-D86E-48F7-86D3DF5BF530BA9E_source.jpg?w=590&h=800&0C1E1DC7-610C-4AE7-97C6EA033BDA38D2","link":"https://blogs.scientificamerican.com/observations/modern-zoos-arent-just-for-entertainment/"},{"authors":"Saad B Omer, Robb Butler","pub_date":"May 9, 2019","abstract":"At the beginning of this year, the World Health Organization (WHO) issued a list of top 10 threats to Global Health. These threats ranged from climate change and non-communicable diseases, to antimicrobial resistance and vaccine hesitancy. The list also included HIV, dengue, weak primary care, fragile and vulnerable settings (e.g. regions with drought and conflict), Ebola, and threat of a global influenza pandemic.\n\nOne underlying theme is the relevance of human behavior to many, if not all, of these threats. For some global health threats, the connection is obvious: non-communicable diseases and their associated behavioral risk factors (i.e. smoking or poor diet), or the reluctance of some parents to vaccinate their children and over-prescription and over-demand of antibiotics—a reason for emergence of antibiotic resistance—have clear behavioral connotations. For many others, the link is less obvious but equally important. For example, human behavior is largely at the center of global climate change and will be at the core of any substantial response to it. Similarly, HIV prevention, avoiding dengue carrying mosquitos, shoring up primary care delivery, and responding to Ebola and influenza outbreaks require modifying or working with human behavior.   \n\nAnd yet, the global health response to these threats lacks a coherent focus on behavioral insights. In recent years, fields such as economics and poverty alleviation have embraced behavioral insights as central to understanding and responding to major challenges in these fields. The 2002 and 2017 Nobel prizes in economics were awarded for research on behavioral economics. While behavioral tools have been used for health promotion for several decades, they are inconsistently included in global health policy-making.\n\nFortunately, there are a few models for incorporating insights from behavioral research into large-scale policy initiatives. One approach, used by many governments and some multi-lateral institutions, is establishing so called “nudge units.” These units use lessons from behavioral economics and psychology to inform public policy.\n\nThe first such unit, officially called the Behavioral Insights Team, was established in the United Kingdom in 2010 and was initially based within the UK Cabinet Office. It now exists as a company co-owned by the Cabinet Office. The Obama administration established a U.S. nudge unit, initially known as the White House Social and Behavioral Sciences Team. This unit has evolved into the Office of Evaluation Science within the General Services Administration. Other countries such as Australia and Singapore have established similar entities. In fact, the concept of promoting behavioral insights-based policy-making has also been adopted by multi-lateral organizations such as the World Bank and the Organization for Economic Co-operation and Development.\n\nWhile not every program initiated by a nudge unit has been equally successful, there are plenty of examples of policy interventions that establish the utility of these units. For example, the UK nudge unit demonstrated that behavioral insights can be used to reduce medication errors, increase commitment to organ donations, and ensure that people show up for their doctor’s appointments.\n\nDr. Tedros Adhanom Ghebreyesus, the WHO Director General who soon after his election to this position promised “a transformed WHO,” has encouraged countries and the WHO’s partners to deliver people-centered care.  Last month, Dr. Tedros (as he prefers to be called) announced a major restructuring of the WHO. He also indicated that “the process of fully implementing the new operating model will take more time.” This period of transition is precisely the right time for establishing a nudge unit at WHO.\n\nWhile there are templates of effective nudge units from various countries and organizations, WHO’s behavioral insights unit will have to reflect its own unique role: First, a WHO nudge unit should support ministries of health of WHO Member States in addition to working with WHO’s core programs—including the newly established health emergencies program.  Second, global health problems are multi-faceted and, therefore, require interdisciplinary solutions. A WHO nudge unit must be staffed by individuals with diverse backgrounds, not just those from the social sciences or medical humanities but also epidemiologists and public health practitioners with behavioral sciences training. Lastly, all initiatives of this unit must be evidence-based and all new interventions must be rigorously evaluated—a tradition upheld by effective nudge units.\n\nAs heath ministers and global health leaders prepare to convene at the World Health Assembly in Geneva this month, the WHO would be well-advised to reflect. The WHO was established to advance human health—and human behavior is a core determinant of human health and well-being. Now is the time for this fact to fully accommodated in its structure and programs.","title":"The World Health Organization Needs to Put Human Behavior at the Center of Its Initiatives","origin":"Behavior & Society","image":"https://static.scientificamerican.com/sciam/cache/file/335E727C-96C0-482B-9650EDE41486F929_source.jpg?w=590&h=800&91F3CB27-E15A-437B-B30046818A09AF5A","link":"https://www.scientificamerican.com/article/the-world-health-organization-needs-to-put-human-behavior-at-the-center-of-its-initiatives/"},{"authors":"Andrea Thompson","pub_date":"May 10, 2019","abstract":"A rapidly growing body of research shows plastic pollution accumulating around the planet at an alarming rate. Tiny bits known as microplastic result from the breakdown of larger items and have proven especially pervasive, turning up everywhere from oceans to rivers to soil, even hanging in the air we breathe.\n\nAs public awareness grows and concerns mount, cities, states and countries have been looking for ways to curb the release of plastic into the environment and to slow production of the material. Policies have ranged from bans on “single-use” plastics, such as grocery bags or straws, to rules requiring producers help pay for collecting and recycling their products.\n\nThe issue is also gaining traction at the international level. María Fernanda Espinosa Garcés, president of the 73rd session of the United Nations General Assembly, singled it out as a key environmental concern she wants the body to address during her tenure, which began in September. She worked with several countries on launching a campaign in December to raise awareness and encourage phasing out single-use plastics, and has initiated a phase-out of such products at U.N. headquarters. Espinosa spoke with Scientific American in her office about the growing awareness of plastic pollution and the role she sees the U.N. playing in tackling it.\n\n[An edited transcript of the interview follows.]\n\nYou identified protecting the environment as one of the key priorities of your presidency, calling out plastic pollution particularly—why did you single out that issue? \n\nI think that the issue of single-use plastics is perhaps one of the defining factors of the current ocean pollution, but also, it's very much connected to human health and our food security. It is an issue that really is affecting now and today—not only the health of consumers, but also the livelihoods of the hundreds of thousands of people living from coastal resources.\n\nIs plastic pollution a growing concern among member states?\n\nYes, definitely. When I launched the campaign, I teamed up with Norway, Antigua and Barbuda. Then I saw that more and more member states are paying attention to that, at different levels. At the international policy level (during the last U.N. Environment Assembly in Nairobi, Kenya, there were two resolutions that were passed: to fight plastic pollution, and to really address the use of single-use plastics), but there are also efforts at the national level. Today we have 127 countries that have passed legislation in the use of single-use plastic bags. So, I think that we are seeing a very strong response from the international community.\n\nThis is a collective action where you need to bring together civil society, academia, science and the private sector. At the same time, we want to really have the younger generations be very plastic-conscious when they have to take consumer decisions. We wanted to make sure that this wasn't seen as a technical scientific issue, but as a personal issue—as a personal choice. And also, we have teamed up with the private sector. The U.N. has launched an agreement [with plastics producers] to say, “Yes, we are going to make profound changes in the way we produce.” That agreement accounted for about 20 percent of the companies that produce single-use plastics.\n\nSo, there is a world movement, I would call it. But this world movement—I hope it bears fruit very soon. Otherwise we will be in deep trouble.\n\nA number of scientists who study plastic pollution say curbing single-use plastics is a great place to start, but they’re concerned action will end there. Are there things the U.N. can do to help create more systemic change around plastic pollution?\n\nWe know that we are singling out one issue and creating awareness; this is not going to solve the entire ocean crisis, as we call it. It's a huge thing, but we have to start somewhere. We understand that this is one problem, and that it is interconnected to a broader production and consumption pattern. It has to also do with the efforts that the U.N. is doing, and the member states are doing, to combat poverty and inequality—because this has to be part of the equation as well. So, this is not an isolated environmental issue. After 25 years of experience in negotiations in the international arena, I can tell you that the only way to build a safer world—a sustainable world for the future—is about understanding holistically what the situation is. But one of the biggest challenges that we face here at the U.N. is to connect the science and the knowledge with the policy and the action.\n\nThere are still many gaps in our knowledge of the impacts of plastic pollution and the best ways to tackle it. Is there a role for the U.N. to play in terms of gathering the research that has been done, to show where gaps are and where research priorities need to be to focus the world’s efforts?\n\nWhat I think honestly, and without being a scientist in the field, is that we need to put together all the evidence that we have already. And this should be perhaps a task of U.N. Environment: to team up perhaps with a body of authority on this issue—for example, the IUCN [the International Union for the Conservation of Nature]—to bring all the evidence together and come up with very concrete policy recommendations.\n\nLast month, the Nordic countries called for a global agreement to tackle plastic pollution. Do you think there is appetite for that among member nations? And given that coordinated global action on climate change has been slow to materialize, are there ways to learn from that process to inform action on plastic? \n\nOn the plastics front, I think that there is very encouraging news. There are the two resolutions [passed by] the U.N. Environment Assembly, so this is an intergovernmental effort already. There are countries that are really thinking about an international legally binding instrument on plastic pollution, and I see that perhaps there is momentum for progress on that front. I know there are countries that are pushing for that, and as president of the General Assembly, I will be more than supportive. And perhaps this is going to be quicker than the climate negotiations.\n\nI think it's not an easy issue, but it is something where we see that it can be done. And we have so many success stories, starting with the Caribbean initiatives to ban not only single-use plastics but Styrofoam, for example. And if they can do it, the European countries can do it, the other Latin American countries can do it. India is also undertaking a very, very ambitious plan to de-plastify their economy and their society. And when India does something, it has a global effect. So, I think that the commitment is there, the drive is there, and I think the momentum also is there to advancing something perhaps more concrete, more universal, more ambitious.\n\nYou’ve also been working to reduce the use of plastic in U.N. facilities. What changes have been made on that front?\n\nYes, I am personally pushing our own community to really have a U.N. single-use-plastic–free venue—and we really need to walk the talk. It is about going to a progressive process to de-plastify the U.N. I hope that when I leave my role as president of the General Assembly, we will see fundamental changes. We have had, in only seven months of my presidency, already, some very important gains: no more plastic straws at the U.N., and we are progressively getting rid of the single-use plastic bottles. We are having very rapid responses, and we are really changing our own culture. If the U.N. cannot be a single-use-plastic-free organization, then we are in deep trouble. And so, I'm pushing hard.","title":"U.N. General Assembly President Sets Her Sights on Plastic Pollution","origin":"Policy & Ethics","image":"https://static.scientificamerican.com/sciam/cache/file/6DB0BE82-4CCC-4FAE-A1F74A028F922D36_source.jpg?w=590&h=800&2A5ED05D-2E0C-466F-B43A661CBE7B04EA","link":"https://www.scientificamerican.com/article/u-n-general-assembly-president-sets-her-sights-on-plastic-pollution/"},{"authors":"Colleen Chierici","pub_date":"May 9, 2019","abstract":"It’s been four years since I donated my kidney in a so-called “paired exchange,” allowing my friend Tinh to receive the kidney she needed.\n\nI met Tinh during nursing school in September of 2012. We quickly became friends, spending grueling hours in our university’s library, preparing ourselves for our future nursing careers.\n\nHer kidney disease developed from a strep throat infection she caught in 2006. Post-streptococcal glomerulonephritis is a rare condition that affects the kidneys because of the body’s immune response against the strep infection.\n\nI made my decision to donate my kidney to her shortly after the birth of my daughter in September of 2013. Tinh had received a kidney from her mother 2010, but the transplant failed, leading her to restart dialysis.\n\nI imagined the pain her mother and loved ones must have felt to watch her go through such an ordeal. I would want someone to step up for my daughter if I could not give her what she needed to survive. Once I made my decision, however, and passed all the medical, social and psychological screening at Northwestern Memorial Hospital, we got the news that I wasn’t an exact match.\n\nSo the transplant center gave me the option to do a paired exchange, meaning that Tinh would receive a kidney from someone else, and my kidney would go to another person who was a match for me.\n\nFor the laparoscopic transplant surgery in January 2015, I stayed in the hospital overnight and went home the next day. I was back at work three weeks after my kidney was removed. My health is the same as it was before, and my life continues on as normal. That’s how it can be for anyone on the transplant list, but that isn’t always the case.\n\nCurrent numbers show there are 113,000 men, women and children on the national transplant waiting list. In 2018, only 36,528 transplants were performed. These statistics make it clear thousands of people who will never receive the organ they desperately need. Twenty people die each day waiting for a transplant. Many wait knowing that death is a possible outcome.\n\nLuckily, Tinh received her kidney and she is flourishing: she went back to school, she travels and she has a successful career. But surgery is not the end of treatment for her or for any organ recipients. She needs lifelong follow-up and medication to survive. The medication is expensive and many cannot or do not know how to pay for the medications.\n\nSome insurers do not coverage for the anti-rejection medications essential to an organ recipient’s survival. If a patient does not take these medications as prescribed, the body’s immune system will destroy the new organ.\n\nChronic rejection is the leading cause of transplant failure. If a transplanted kidney fails, a patient has the option to go back on dialysis. If a heart, lung, or liver transplant fails, the patient will be put back on a waiting list for another transplant. Many will die before getting one.\n\nMedicare offers kidney recipients some respite, as anyone under the age of 65, with end-stage renal disease will receive coverage for dialysis and kidney transplantation. Depending on what part of Medicare they had while receiving a kidney transplant, some recipients will receive coverage for anti-rejection meds for the rest of their lives.\n\nOther recipients will receive coverage for 36 months after a successful transplantation. For those who don’t receive life-long coverage, anti-rejection medications can cost $10,000 to $14,000 per year.\n\nOther organ recipients such as liver, lung and heart transplant recipients do not receive the same financial offset as kidney recipients, because failure of these organs are not covered the same way under Medicare.\n\nSome individuals waiting for life-saving transplants are turned away due to inability to pay for anti-rejection medications post-transplant, and turn to crowdfunding sources such as GoFundMe.\n\nFor instance, social media recently joined in the cause for patient Hedda Elizabeth Martin, who was reportedly not considered a candidate for a heart transplant, because of concerns on how she would pay for anti-rejection medication.\n\nLast year, there was much press surrounding 11-year-old Sofia Sanchez, who had two wishes granted: dancing with the musical artist Drake, and receiving a heart transplant at Lurie Children’s Hospital. A happy ending to a transplant story is what everyone wants to hear. That is not always the case.\n\nAs a registered nurse, I can possibly understand why an organ would not be allocated to an individual who cannot afford anti-rejection medication; it would be perhaps seen as not the best use of a viable organ. Perhaps the rationale is that organs are scarce and they need to go to patients who have the best chance of survival. However, a patient’s chance of survival based on their economic ability to afford the medication is unconscionable. It is not only the wealthy who deserve organ transplants.  \n\nNo legal protections for organ recipients exist in the form of federal regulations that mandate insurers to provide lifelong coverage for anti-rejection medications.\n\nSome organizations have joined a coalition named Honor the Gift, which seeks to extend Medicare coverage of anti-rejection medication beyond 36 months for kidney transplant recipients, but this does not include recipients of other organ transplants.\n\nLast April, during Donate Life Month, I celebrated as part of the largest gathering of living donors in Chicago, breaking a Guinness World Record with 410 kidney and liver donors coming together to raise awareness.\n\nAwareness of organ donation is more important than ever: the United Network for Organ Sharing has decided to broaden the geographic regions where livers are shared to decrease wait times for livers nationally.\n\nBut this new system will increase organ transplant disparity, because patients in wealthier areas, who are more likely to receive an organ because they can afford the care associated with it, will have access to the organs that were previously being transplanted in poorer areas. The best way to combat the scarcity of organs and ensure everyone has a fair chance of receiving one is by increasing organ donation, live and deceased.\n\nI count myself lucky to have been able to help my friend with an organ donation she needed. She is fortunate to have excellent insurance and so is able to afford her anti-rejection medications.\n\nEvery person in need of an organ donation in this country deserves the right to a healthy future, regardless of economic circumstances. This month and all year, it is essential that healthcare advocates, insurers and healthcare providers all do the right thing for every patient.","title":"We Need to Make Organ Transplantation Easier","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/5F76BF1E-9042-4013-A5C2D17D334754B0_source.jpg?w=590&h=800&3B9BA15C-27C1-4288-8ECCD26EB1F6D35C","link":"https://blogs.scientificamerican.com/observations/we-need-to-make-organ-transplantation-easier/"},{"authors":"Kate Marvel","pub_date":"May 12, 2019","abstract":"Imagine spending your whole career working on a question to which you don’t want to know the answer. We know that greenhouse gas emissions can and do warm the planet, but we don’t know one very basic thing: how hot, exactly, is it going to get? The main reason for this, of course, is that human behavior is so hard to predict. How will the people of the late twenty-first century get their energy? Will they need as much as we do, or will they have reconciled themselves to fundamentally different lives?\n\nPerhaps that decision will have been made for them by war or societal collapse. None of this is knowable. But even if we could remove all the uncertainty associated with politics, economics, technology, and demography, we still wouldn’t be sure. There are many things we don’t understand about our rapidly-warming planet.\n\nTo some extent, we know why we don’t know. I have been sternly informed by communication experts that “global warming” is a better term for what’s happening than “climate change.” I have also been told the opposite. But the two are inseparable: they feed back upon each other. Rising temperatures change the planet, and these changes can speed up or, if we are very lucky, slow down the warming we’ve caused.\n\nWe are not very lucky. Most of these changes will make things worse. The polar ice that we are currently melting is a good example. Right now, it reflects sunlight back to space, cooling the planet like a sunshield on a car windscreen. When it goes, it will leave behind dark land or ocean to absorb rather than reflects the sun. A little bit of warming can become much more.\n\nTo study the effects of these changes, we use something artificial but useful: the concept of climate “sensitivity.” In our climate models, we abruptly double atmospheric carbon dioxide from its preindustrial value of 280 parts per million, let the model Earth evolve for a few hundred years, and then measure the increase in its temperature. In the first generation of climate models, this varied from about a degree and a half Celsius to about four and a half degrees. The best guess was about three degrees C. The next time we did this, having improved the models substantially, the best guess was three degrees C, and the range was between 1.5 and 4.5 degrees. Decades of new science and advances in computing power later, and nothing about these estimates or their uncertainty has substantially changed.\n\nWe don’t know everything, but we don’t know nothing. All climate models simulate a changing planet in response to a changing temperature. And, increasingly, we know why they disagree on that final warming. In the climate models that warm more, low, thick clouds appear to be changing in ways that reduce their sun-blocking power. In the models that warm less, these changes are smaller.\n\nSo scientists have devoted their time to measuring clouds, understanding them, and figuring out how to represent them in climate models. This work has paid off: the range of uncertainty is now changing. Unfortunately, it’s increased. Climate models that use more modern techniques to simulate clouds are now projecting more warming: five or six degrees Celsius in response to a doubling of carbon dioxide. To put those numbers in context, four and a half degrees is the difference between now and the last Ice Age.\n\nI find these high numbers hard to believe, but as a scientist it’s my job to find things hard to believe. My skepticism is rooted in clues from the planet’s past. At the height of the last Ice Age, temperatures were cooler and carbon dioxide levels lower. It’s hard to reconcile these measurements with extremely high climate sensitivities. But it’s almost impossible to reconcile them with extremely low ones.\n\nClues from the more recent past might seem to paint a more reassuring picture. We have, after all, emitted carbon dioxide, and the planet has warmed in response. Our Earth is about a degree Celsius warmer than it was before the Industrial Revolution. This is dangerous, but not yet catastrophic, and some have suggested it might be indicative of a planet relatively insensitive to carbon dioxide. But the past is not the future, and we have good reason to believe that there are no analogues for the future into which we are hurtling. Right now, heat is being mixed into the deep ocean, which is cold and vast but not infinite. It will warm up in time, over hundreds or thousands of years, and the changes it will trigger may be different than any we have ever observed. Clouds may dissipate, ice will melt, and the warming will get worse.\n\nThese uncertainties matter in the real world. If the climate is very sensitive to carbon dioxide- if the changes provoked by warming themselves create much more warming- then our time frame for action is reduced. If the climate is relatively insensitive, then perhaps we’ll have a little more breathing room. But we’ve ruled out a climate sensitivity of zero. Warming is real, it’s happening, and it’s likely to get worse. Uncertainty is no excuse for inaction. Even in the improbable event that climate sensitivity is very low, “business as usual” still warms the planet and leads to unpleasant consequences. In the event that climate sensitivity is high, “business as usual” means disaster.\n\nClimate models, like all models, are imperfect representations of the real world. They tell us something useful about the planet we’re changing, but not how much, exactly, we’ll change it. The only way to be sure is to actually double atmospheric carbon dioxide and wait until the planet approaches a new equilibrium, measuring the changes along the way. This is an uncontrolled experiment I hope we will never do. But I’m afraid we’re well on our way to finding out.","title":"Global Warming: How Hot, Exactly, Is it Going to Get?","origin":"Hot Planet","image":"https://static.scientificamerican.com/blogs/cache/file/80C4493E-6185-4B03-8BB3D50C6EFE5DB1_source.gif?w=590&h=800&F16593DB-37EB-46A1-ADBFDD2EC7B05A93","link":"https://blogs.scientificamerican.com/hot-planet/global-warming-how-hot-exactly-is-it-going-to-get/"},{"authors":"Susana Martinez-Conde and Stephen L. Macknik","pub_date":"May 7, 2019","abstract":"The man and the woman sat down, facing each other in the dimly illuminated room. This was the first time the two young people had met, though they were about to become intensely familiar with each other—in an unusual sort of way. The researcher informed them that the purpose of the study was to understand “the perception of the face of another person.” The two participants were to gaze at each other’s eyes for 10 minutes straight, while maintaining a neutral facial expression, and pay attention to their partner’s face. After giving these instructions, the researcher stepped back and sat on one side of the room, away from the participants’ lines of sight. The two volunteers settled in their seats and locked eyes—feeling a little awkward at first, but suppressing uncomfortable smiles to comply with the scientist’s directions. Ten minutes had seemed like a long stretch to look deeply into the eyes of a stranger, but time started to lose its meaning after a while. Sometimes, the young couple felt as if they were looking at things from outside their own bodies. Other times, it seemed as if each moment contained a lifetime. Throughout their close encounter, each member of the duo experienced their partner’s face as everchanging. Human features became animal traits, transmogrifying into grotesqueries. There were eyeless faces, and faces with too many eyes. The semblances of dead relatives materialized. Monstrosities abounded.\n\nThe bizarre perceptual phenomena that the pair witnessed were manifestations of the “strange face illusion,” first described by the psychologist Giovanni Caputo of the University of Urbino, Italy. Urbino’s original study, published in 2010, reported a new type of illusion, experienced by people looking at themselves in the mirror in low light conditions.\n\nAs we noted in an ensuing Scientific American Mind article,\n\n“Caputo asked 50 subjects to gaze at their reflected faces in a mirror for a 10-minute session. After less than a minute, most observers began to perceive the “strange-face illusion.” The participants’ descriptions included huge deformations of their own faces; seeing the faces of alive or deceased parents; archetypal faces such as an old woman, child or the portrait of an ancestor; animal faces such as a cat, pig or lion; and even fantastical and monstrous beings. All 50 participants reported feelings of “otherness” when confronted with a face that seemed suddenly unfamiliar. Some felt powerful emotions.”\n\nIn his subsequent research, Caputo observed that the strange face phenomenon was not limited to one’s face reflected in the mirror, but it extended to other people’s faces, in situations where pairs of experimental participants gazed at each other for sustained periods of time in a dimly lit room. \n\n\n\tExperimental setup. Credit: Drawing by Alberto Conti\n\n\n\n\nMost recently, in a study published last month in the Journal of Trauma and Dissociation, Caputo sought to test a large sample of participants, which comprised 90 healthy young adults. Notably, the participant population included 15 portrait artists, who were able to produce artistic depictions of their perceptual experiences at the end of the experiment. Four of such portraits are included below: a stranger with eyewear, a monkey-woman, an alien face, and a cartoonish human-rabbit face.  \n\n\n\tFour examples of strange-face illusions sketched by portrait artists: (a) Stranger with eyewear, (b) Monstrous monkey-woman, (c) Alien face, (d) Cartoon-like human-rabbit face. Credit: Giovanni Caputo\n\n\nThe mechanisms underlying the strange face illusion remain somewhat obscure. The perceptual vanishing of objects and scenes during prolonged gazing, known as Troxler fading, could be part of the explanation. When we stare at an unchanging face for a long time (our own face in the mirror, or the face of the person sitting in front of us), our visual neurons decrease their activity, making facial features fade and disappear (and then reappear when we blink or move our eyes). In the absence of such visual information, our brain is bound to “fill in” the gaps according to our neural wiring, expectations, and experiences—sometimes with fantastical results. \n\nFuture research may offer a more complete picture of why the strange face illusion arises. In the meantime, you may want to avoid candle-lit romantic dinners—or looking too long into the eyes of your beloved.","title":"Locking Eyes with a Monster","origin":"Illusion Chasers","image":"https://static.scientificamerican.com/blogs/cache/file/8920FEFD-183D-4CF9-84230C2D69E1B285_source.jpg?w=590&h=800&11360235-E9E8-4B5A-8FB3EE0168C8F33C","link":"https://blogs.scientificamerican.com/illusion-chasers/locking-eyes-with-a-monster/"},{"authors":"Jonathan O'Callaghan","pub_date":"May 13, 2019","abstract":"This Wednesday SpaceX will launch its first batch of Starlink satellites—a “mega constellation” of thousands of spacecraft to provide high-speed Internet access to billions of people at any location on the planet. Starlink is only the first of many such projects; there are at least eight more mega constellations in the works from other companies. Although they promise to revolutionize global telecommunications, these efforts are not free of peril: as the number of satellites inexorably grows, so, too, does the risk of creating dangerous debris that could threaten the continued safe use of Earth orbit. “This is something we need to pay attention to,” says Glenn Peterson, a senior engineering specialist at the Aerospace Corporation, headquartered in El Segundo, Calif. “We have to be proactive.”\n\nToday Earth orbit is a busy place. Almost 2,000 active satellites whiz around our planet, along with nearly 3,000 dead satellites and 34,000 pieces of “space junk” larger than 10 centimeters in size. Whenever debris or a defunct spacecraft gets too close for comfort to an active satellite—typically when a collision risk rises to one part in several thousand—the satellite’s operator must perform a collision-avoidance maneuver. The International Space Station, for example, is moved when the chance of a collision isgreater than one in 10,000.\n\nThese close encounters already occur thousands of times each year, but the sheer vastness of mega constellations such as Starlink will change the game, resulting in an estimated 67,000 annual collision-avoidance maneuvers if all of them are launched. As Earth orbit becomes jam-packed with satellites, the risk increases. A worst-case scenario would be the Kessler syndrome, a positive feedback loop in which debris-generating collisions create more and more collisions, which in turn create more and more debris, rendering parts of Earth orbit essentially unusable.\n\nNine companies total—including SpaceX, Amazon, Telesat and LeoSat—have been licensed by the U.S. Federal Communications Commission to launch such constellations. SpaceX alone plans to launch nearly 12,000 satellites by the mid-2020s, which will operate either at an altitude about 500 kilometers in low-Earth orbit (LEO) or a higher altitude of roughly 1,200 kilometers in nongeostationary orbit (NGSO). It is the first company of the nine to launch any fully functional satellites of its constellation. OneWeb, the next front-runner, has plans for a 650-strong constellation in NGSO. Six of its test satellites were launched this past February, and its first proper launch of three dozen or so satellites are planned for later this year. Monthly launches of 30 to 36 satellites will follow, with the service coming online in 2021. Every other company has similar plans for incrementally launching hundreds to thousands of satellites of its own.\n\nRisk versus Reward\n\nThe benefits of mega constellations would be manifold. Blanketing the entire planet with high-bandwidth, low-latency, always-on Internet access means ships out at sea, high-flying planes and people in remote, undeveloped areas (even Antarctica!) will suddenly be connected as never before. “Connectivity is just not [currently] available to everybody,” says Mike Lindsay, a space mission designer at OneWeb. “Half the world lacks an affordable access point to broadband Internet.”\n\nQuestions remain, however, on how to safely operate so many satellites in orbit. If the satellites fail, they could easily add to the growing problem  of space junk. At altitudes of 500 kilometers, failed satellites will not be a huge problem: within several years, atmospheric drag will naturally pull them back toward Earth to burn up on reentry. Indeed, to combat space junk, SpaceX recently modified its license with the FCC to lower the planned altitudes of more than 1,500 of its satellites by half. But at an altitude of 1,200 kilometers, where satellites remain aloft for longer, the dilemma becomes clear: “It’ll be thousands of years at those altitudes,” says Hugh Lewis, a professor of engineering and physical sciences at the University of Southampton in England, who developed a model called DAMAGE to track and monitor space debris.\n\nThere are no binding rules currently in place for how long a satellite can safely linger in orbit. The United Nations recommends that satellites be deorbited no more than 25 years after the end of their missions, but these guidelines lack strict penalties for noncompliance. “They are voluntary guidelines,” says Brian Weeden, director of program planning at the Secure World Foundation. The longer a satellite is in orbit, the greater the odds of it colliding with another one are. And such collisions are not unprecedented—in 2009 the American Iridium 33 satellite slammed into the defunct Russian Kosmos 2251 satellite, producing thousands of new pieces of debris.\n\nSome companies are being proactive in how to approach this problem. OneWeb, for example, will attach a handle to each of its satellites, offering an easy way for future orbital scrappers to haul them back down for disposal. No company has yet proved such technology, but progress is being made by entities such as the Japan-based Astroscale. “It is expected that a very small percentage of satellites will fail in such a way that the satellite operator is unable to deorbit them,” says Harriet Brettle, a business analyst at Astroscale. But “Astroscale and other emerging companies are looking to provide a backup service that will remove such failed satellites and maintain a sustainable space environment.”\n\nOther companies licensed by the FCC, however, plan to solely use the onboard propulsion of each of their satellites to ensure a safe deorbit. In principle, doing so seems fine, but in practice, satellite failure rates are not negligible. Even a 99 percent reliability rate for mega constellations would still result in hundreds of dead satellites adrift in orbit. As these numbers stack up, the chance of catastrophe would only grow.\n\n“The real problem is that we don’t have a great track record of getting [satellites] back out of orbit,” says Stijn Lemmens, a space debris analyst at the European Space Agency. “Long-term environment simulations indicate that we would need to reduce the orbital lifetime of about 90 percent of all objects that are launched into orbit. And in reality, we see this is happening successfully for about 5 to 15 percent. So we’re way off the target goal.”\n\nNoisy Skies\n\nAnother issue is the radio-based communications of the satellites themselves. Each satellite constellation will be awarded a chunk of the electromagnetic spectrum in which to communicate, but picking out a satellite amids the noise of so many can be tricky. With thousands more satellites set to enter orbit, actually communicating with a single one among those flying  overhead could be difficult. “The radio frequency interference is a big thing that is overshadowed by the potential collision risk,” Weeden says.\n\nThese mega constellations could cause problems for astronomy, too. Already, astronomers using optical telescopes have to contend with satellites occasionally crossing their view. Such interference could increase by a factor of several times with the emergence of mega constellations, says Mark Hammergren, a planetary scientist at the Adler Planetarium in Chicago. And for radio astronomers, things could become even more vexing. “Any time a satellite would pass through the observing beam of a radio telescope, there’s a chance that its transmission might be received and interpreted as a celestial signal,” Hammergren says.\n\nWednesday’s Starlink launch will be rightly lauded as a means to bring the Internet to the masses, but the greater plan of more than doubling the number of active satellites in orbit unavoidably comes with huge complications and seemingly scant room for contingencies. Even if launches and operations unfold smoothly for every mega constellation operator, just one of them experiencing financial difficulties could make the risk of space junk suddenly skyrocket. “The worst case is: you launch all your satellites, you go bankrupt, and they all stay there,” Lemmens says. “Then you have thousands of new satellites without a plan of getting them out of there. And you would have a Kessler-type of syndrome.”","title":"SpaceX's Starlink Could Cause Cascades of Space Junk","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/B6F541A6-4D9A-465B-9D5052911235B36E_source.jpg?w=590&h=800&8181615B-3C69-48AF-A8A0B0A8A2EF8E5B","link":"https://www.scientificamerican.com/article/spacexs-starlink-could-cause-cascades-of-space-junk/"},{"authors":"Amanda Baker","pub_date":"May 2, 2019","abstract":"How many words does it take to teach a meaningful lesson in critical thinking? 5000? 1000? 500? And how young could your audience be and still get something out of it? Ten? Eight? Three? Imagine you have been challenged to teach a three-year-old child something about metacognition in fewer than 300 words. It may sound impossible, but picture books do it every day.\n\nObviously, we aren’t asking toddlers to parse the Monty Hall problem or navigate the prisoner’s dilemma. But figuring out how to make decisions – and assessing the strength of both that process and the decisions themselves – provides the foundation for any bigger questions you might want to pose. And because toddlers are still figuring out this whole decision thing from scratch, they engage with this process without hesitation. Most people are familiar with the characteristic “why” stage, with curious young minds asking about everything from how toasters work to why people have hair. But spending time with a toddler makes it clear that children this age are probably also asked “why” more than any other humans on the planet. “Why didn’t you tell me you had to use the potty?” “Why do you think the lamp is going to bite you?” “Why did you stuff your napkin into a full glass of milk?” All of these fall within the realm of an average morning. And the answers are often delivered with a blank-faced sincerity unparalleled in adults: “I wasn’t done with my book,” “The lamp can see me,” or “It was wet.”\n\nParsing the logic of seemingly id-driven actions takes work on both sides – grown-ups trying to follow staggering non sequiturs and toddlers trying to articulate their logic with a limited vocabulary and foggy grasp of pronouns. One common arena for these kinds of conversations is the reading of picture books. Try as I might to explain the decision-making process, I can’t imagine I will ever approach the clarity and impact of Mo Willems’ Should I Share My Ice Cream? Spoiler alert for those have not followed this particular adventure, the elephant gets some ice cream and has to decide whether to share it with his best friend, Piggie. Elephant takes so long making the decision that his ice cream ultimately melts, and Piggie shows up just in time to console her friend by sharing an ice cream cone of her own. This synopsis contains neither the humor nor the melodrama of the original story. But my ~894 readings have taught me that young readers can not only follow the logic of deciding whether to share, but also be driven to such sympathy to need to hug the book on pages when the characters look sad.\n\nPart of the magic comes not just from the ultimate decisions, but the steps the characters take in making them. Each step is laid out and illustrated for the reader. The initial excitement, the realization that he has a chance to share, the question of whether he should share, the question of whether he wants to share, the discovery of an excuse to keep the ice cream to himself, and the logical breakdown of that excuse. On one page, the elephant gleefully determines that the chance that Piggie might not like the flavor absolves him of any reasonable obligation to share. He looks at the ice cream with almost manic anticipation. But flip the page, and you witness the honest admission that Piggie would, in fact, like that flavor. I can’t decide if it sounds simple or complicated, but there is power in the page turn. It even drives some critical analysis of my own behavior. Am I overthinking this story as a defense mechanism against the hundreds of times I will likely be asked to re-read it? Probably. Do I care? No.\n\nAnd limited text and few powerful illustrations can take on concepts more nuanced than sharing. On its surface, Galia Bernstein’s I Am a Cat follows a small house cat on the journey of convincing its larger peers – lions and tigers – that it too is a cat. In the process, the characters engage their assumptions, personal bias, in-group/out-group dynamics, combating misconceptions with logical arguments, and changing their minds when faced with convincing evidence. There is even a reasonable primer in taxonomic practices thrown in for good measure. Both kids and grown-ups can appreciate a small, stripey role model standing its ground when laughed at, and responding with calm, careful evidence rather than visceral frustration. Even when the argument is about tails, pointy ears, and claws, it is a welcome change to see evidence-based arguments result in changed minds and a collective kitty romp rather than finger pointing and assertions of us versus them.\n\nFor those who will spend the foreseeable future in the land of picture books, there is comfort in recognizing opportunities to challenge assumptions (Last Stop on Market Street) or giggle at terrible logic (the final lines of the classic Madeline). But there are also lessons for those tasked with conveying complex ideas to unexpected audiences. There is a source of hope. Not only can we start conversations about critical thinking before they can be fully considered conversations, but we can remember the power of a clear narrative in opening conversational doors that might otherwise be closed to us. If picture book authors can use their prodigious skills to engage toddlers in logic, trade-offs, and critical decision making with 500 words and an ice cream cone, the rest of us can take the time to get to know our audiences, find the right narrative, and open the door to conversations with a shared story.","title":"Learning about Critical Thinking from Kitty Claws and Ice Cream Cones","origin":"Budding Scientist","image":"https://static.scientificamerican.com/blogs/cache/file/1D1A6D8D-0696-439B-80FD014775607F57_source.jpg?w=590&h=800&D18AB65D-4EDF-4A8C-8E1649212E5B3347","link":"https://blogs.scientificamerican.com/budding-scientist/learning-about-critical-thinking-from-kitty-claws-and-ice-cream-cones/"},{"authors":"Christopher Intagliata","pub_date":"May 8, 2019","abstract":"By dampening the energy of waves, coral reefs protect coastal cities from flooding damage and other economic losses. Christopher Intagliata reports.","title":"U.S. Coral Reefs Do $1.8 Billion of Work Per Year","origin":"Natural Disasters 60-Second ScienceSubscribe:Apple iTunesRSS","image":"https://static.scientificamerican.com/sciam/cache/file/C92D4CA4-EAF1-41B8-8081202A6FC06A48_source.jpg?w=590&h=800&393C1B23-444C-4660-907929A65CB17EFC","link":"https://www.scientificamerican.com/podcast/episode/u-s-coral-reefs-do-1-8-billion-of-work-per-year/"},{"authors":"Chelsea Harvey, E&E News","pub_date":"May 9, 2019","abstract":"With spring in full bloom, winter’s last stores of snow are beginning to melt. As they do, they’ll release much-needed fresh water into streams or the surrounding soil, fueling plant growth and replenishing drinking resources for communities.\n\nIt’s one of nature’s most important annual rituals.\n\nBut how soon the snow starts to liquefy, and how quickly it disappears, may depend on more than just the outside temperature. Scientists are finding that wildfires in the western United States may alter the landscape in ways that lead to earlier, faster snowmelt.\n\nThat’s a big concern for Western water resources. If the snowpack melts and runs off too quickly, it could cause regional freshwater resources to dry up before the cooler fall temperatures set in, increasing the probability of drought.\n\nBut there’s another concern, as well. Many researchers believe a faster snowmelt and a drier summer landscape may also worsen the fire season in some areas, leading to bigger, hotter blazes.\n\nThe whole process offers the possibility of a climate feedback cycle, said researcher Kelly Gleason of the Desert Research Institute in Nevada. Wildfires lead to faster melting, and faster melting in turn leads to more wildfires.\n\n“Earlier snowmelt is already linked to big fires in the mountains,” she said. “And that those fires could be feeding back and accelerating that snowmelt further—there’s this kind of vicious cycle that’s occurring, or we think is occurring.”\n\nGleason, along with other colleagues from the Desert Research Institute and the University of Nevada, has just published a new study that demonstrates the side effects of wildfires on snow, using a combination of satellite observations from across the West and snow samples from sites in Colorado, Wyoming and Utah.\n\nThe research finds that snow starts to melt about five days earlier in the season after a fire has occurred on the landscape. And based on satellite data from the 1980s onward, it suggests that earlier melting may persist for at least a decade after a fire has occurred.\n\nThis happens for several reasons, according to Gleason.\n\nWildfires tend to clear out the forest canopy, leaving more space for sunlight to get through the trees and warm up the snow. They also leave behind burned leaves and branches, which drop bits of ash and char onto the snow below. These burned bits darken the bright white surface of the snow, causing it to absorb more solar energy.\n\nBetween 1999 and 2018, the researchers found that there’s been about a fourfold increase in the amount of solar energy being absorbed by the Western snowpack after the occurrence of wildfires. They also note that Western forests in the seasonal “snow zone”—that is, forests that also see winter snow cover—are experiencing more wildfires, with the total burned area increasing by about 9% every year.\n\nAltogether, the researchers estimate that about 11% of all Western forests in the snow zone are absorbing more solar energy and melting earlier as a result of wildfires.\n\nThe new study only demonstrates the effects of wildfires on snow—not the other way around. But other research has pointed to potential links between earlier snowmelt and the Western fire season.\n\nAt the annual meeting of the American Geophysical Union in December, University of Maryland doctoral candidate Donal O’Leary presented new research on the timing of snowmelt and the severity of fire seasons in the Western states. He found that the effects are not the same on every kind of landscape. But in most forested areas, early snowmelt is associated with a greater amount of burned area during the fire season.\n\nSuch findings would seem to suggest that, in some Western forests, the effects of wildfire on snowmelt and snowmelt on wildfire may be able to mutually fuel each other.\n\n“I want to say that this is a really important, groundbreaking paper, because it shows us for the first time snowpack feeding back to fire regimes in a very direct, mechanistic way,” said wildfire expert Donald Falk of the University of Arizona, who commented on the new research for E&E News. “They highlight this as a much more highly interactive system than we’ve understood previously.”\n\nIn future research, it may be useful to collect snow samples from a wider variety of landscapes across the Western states, to be sure the same effects hold true throughout the region, Falk noted. But generally, he said, the study “absolutely suggests a kind of local landscape-level feedback, which we really haven’t understood as well.”\n\nAt the same time, the researchers suggest, climate change is likely making the entire process more sensitive.\n\nNumerous studies suggest that rising temperatures are causing the total snowpack area to shrink in the Western states, while snow is also accumulating later in the fall and melting earlier in the spring (Climatewire, Dec. 13, 2018). Models project that this effect will worsen as the climate continues to warm.\n\nCombined with the effects of climate change, the influence of wildfires just makes an already vulnerable snowpack even more sensitive to the sun, Gleason noted.\n\n“Climate change is already melting snowpack and increasing forest fires,” she said. “But then there’s this feedback, which could amplify that impact earlier.”\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"In “Vicious Cycle,” Snowmelt Fuels Wildfires and Wildfires Melt Snow","origin":"EARTH","image":"https://static.scientificamerican.com/sciam/cache/file/A1A872A3-4640-4A85-8DBB031AF8765DC2_source.jpg?w=590&h=800&1C0C50FA-655A-4002-B79B44E9FFAA6252","link":"https://www.scientificamerican.com/article/in-vicious-cycle-snowmelt-fuels-wildfires-and-wildfires-melt-snow/"},{"authors":"Jean Chemnick, E&E News","pub_date":"May 10, 2019","abstract":"EPA Administrator Andrew Wheeler used an overseas gathering of environment ministers this week to hint that the United States might overhaul the way it uses climate data and modeling. Five days after his assertion was included in an official document from the Group of Seven meeting in Metz, France, it remains unclear if Wheeler revealed a potential policy to reexamine climate modeling.\n\nIt’s become common for the United States to have its own climate and energy paragraph in multilateral statements, and on Monday, Wheeler broke away from the six other nations on issues like the Paris Agreement, providing support for poor and climate-affected countries, and overseas investments in fossil fuels.\n\nThat much was normal. It’s happened ever since President Trump took office in January 2017.\n\nBut Wheeler added something new that’s raising concern among some environmentalists that the United States might be formally questioning climate science inside federal agencies.\n\n“The United States reaffirms its commitment to re-examine comprehensive modeling that best reflects the actual state of climate science in order to inform its policy-making decisions, including comparing actual monitored climate data against the modeled climate trajectories on an on-going basis,” says the U.S. portion of the communiqué.\n\nGreens who follow the G-7 process were dismayed.\n\nAlden Meyer, director of policy and strategy at the Union of Concerned Scientists, called the language “pretty troubling,” and Luca Bergamaschi of the Britain-based E3G called it “a major step back.”\n\nThey read Wheeler’s language as an attempt to undercut a report last year by the U.N. Intergovernmental Panel on Climate Change. The report drew on thousands of peer-reviewed studies to warn of the importance of holding postindustrial warming to no more than 1.5 degrees Celsius.\n\nWheeler has been critical of the IPCC’s conclusions and of the National Climate Assessment, a U.S. report that issued similar warnings last year. He’s not alone in the Trump administration. In December, U.S. delegates to the U.N. climate talks in Katowice, Poland, joined Russia and Saudi Arabia to block language to “welcome” the IPCC’s findings.\n\nIt’s unclear if Wheeler meant to slight the IPCC on Monday. In fact, he joined his counterparts from France, Canada, the United Kingdom, Italy, Germany and Japan in praising the international body’s work to “strengthen the science-policy interface on the environment including by providing reliable assessments of the state of knowledge in response to the requests of policy makers and build capacity to use science effectively in decision-making at all levels.”\n\nThe statement leaves little to “re-examine” from the IPCC’s work.\n\nSo, was he announcing an alternative climate modeling initiative, either at EPA or another federal agency?\n\n“Currently, there are no specific efforts underway at EPA,” said agency spokesman James Hewitt. He didn’t respond to follow-ups about future plans or initiatives at other agencies.\n\nMeyer and others suggested that Wheeler might be referring to plans within the White House to convene a task force within the National Security Council to undermine the scientific underpinnings of the National Climate Assessment. But that proposal—to be spearheaded by William Happer, a senior director on the National Security Council—has yet to be accepted by Trump. NSC didn’t respond to inquiries (Climatewire, Feb. 21).\n\nMyron Ebell, a senior fellow at the Competitive Enterprise Institute, said a White House meeting last week to brief the president on the Happer proposal “went well.” But he said the concept remains controversial among some senior officials.\n\n“The president is enthusiastic about setting up the Happer commission,” said Ebell, who oversaw the EPA transition team before Trump’s inauguration. But he noted that Wheeler would have been unlikely to reference a program that Trump has yet to bless at an international forum.\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"Trump Administration Might “Re-Examine” Climate Modeling","origin":"Policy & Ethics","image":"https://static.scientificamerican.com/sciam/cache/file/9B94D236-E595-4388-B447F424BD452366_source.jpg?w=590&h=800&C4DF7DF0-B393-40EE-8EF6903C3A248653","link":"https://www.scientificamerican.com/article/trump-administration-might-re-examine-climate-modeling/"},{"authors":"Ralph Nader","pub_date":"May 9, 2019","abstract":"“Fundamental Canon No. 1” of the American Society of Engineers states that “Engineers shall hold paramount the safety, health, and welfare of the public.” Most engineering societies have this principle in their codes of ethics. This duty frames the decades of struggles by conscientious engineers—whether employees or consultants—who strive to balance professional ethics with occupational survival.\n\nCompared to the technologically stagnant dark days in the auto industry of cruel suppression of technical dissent over safety and toxic emissions, a censorship that carried over to the industry-controlled Society of Automotive Engineers, today’s engineers are working in an improved environment for taking their conscience to work. Yet much more remains to be done to safeguard the ability of engineers to speak truth to the powers-that-be.\n\nFor starters, the word whistle-blower—once popularly meant to describe a snitch or a disgruntled employee—now describes an ethical person willing to put his or her job on the line in order to expose corrupt, illegal, fraudulent and harmful activities. Indeed, in the aftermath of recent Boeing 737 MAX crashes, the media routinely and positively refers to disclosures by “Boeing whistle-blowers.” Congressional investigating committees and federal agencies have called for whistle-blowers to come forward and shed light on corporate misdeeds and governmental agency lapses.\n\nTo put it mildly, this was not always the case. In 1971, I convened the Conference on Professional Responsibility—a sober name for a group of whistle-blowers from corporations, government and unions. They were ragged as “malcontents” or “occupational-suiciders.” In fact, they were courageous, accurate, morally right, and willing to lose everything to expose wrongdoing.\n\nKeynoters at the whistle-blower conference were Senator William Proxmire, who protected government whistle-blowers on military defense issues, and Robert Townsend, author of the best-selling Up the Organization. Townsend drew from his business experience to explain the critical role whistle-blowing could play in giant corporations. Law Professor Arthur Miller reviewed the lack of legal protection and vulnerability of whistle-blowers and presented what the law should provide “in its institutions and principles.” (See Whistle Blowing: The Report of the Conference on Professional Responsibility, by Ralph Nader, Peter Petkas and Kate Blackwell, 1972).\n\nAfter this watershed conference, much began to change. Numerous health and safety statutes now protect government employees who report noncompliance with environmental, worker safety and labor standards. Starting in 1978, a Merit System Protection Board was established and later strengthened under President George Herbert Walker Bush to give federal employees some, but not enough, due process against retaliation. Several states followed with their own whistle-blower protections.\n\nIn 1977 an NGO called the Government Accountability Project (GAP) started offering pro bono representation to many government and corporate whistle-blowers. After the enactment of the 1986 False Claims Act, federal employees exposing fraud against the government were able to secure a sizable portion of any resultant verdict or settlement against those ripping off the taxpayers. This law alone has recovered over $60 billion from the fraudsters. Private law firms and the Justice Department are regularly involved in pursuing these claims.\n\nThe vast world of state and federal procurement/military contracts and infrastructure is known to be rife with “waste, fraud and abuse.” Engineers are most likely to see such violations first. Decades ago, foreshadowing the many challenges in engineering, the Society of Professional Engineers, in its code of ethics, instructed engineers on their obligation to report safety and fraud violations to the appropriate outside authorities, should they find no recourse inside their place of employment.\n\nWith $5 trillion of deferred maintenance for our public works, as measured by the American Society of Civil Engineers, the challenges to the assertion of engineering conscientiousness will be ever larger.\n\nWe need more public interest engineering advocacy groups and initiatives to open up new frontiers of excellence and service as well as to support engineers inside the corporate framework. It was a Caltech professor, Arie Jan Haagen-Smit, not GM engineers or chemists, who proved in the 1950s the connection between motor vehicles and the lethal photochemical smog over the cities and suburbs of California. This led to smog-control regulations and ethical and legal foundations for industrial air pollution controls.\n\nEngineer Ralf Hotchkiss, rendered a paraplegic before college, courageously revolutionized the functional and economical design of superior wheelchairs, including showing natives how to utilize local materials in poor countries. He also helped break the virtual wheelchair monopoly of a British multinational company in the process. We need more engineers who embody the three principles of any profession—independence, scholarly pursuits, and commitment to public service. Those are the vital ethical pillars to helping engineers withstand the great pressures to place commercial priorities over their engineering integrity and limit harm to the public. We see the push to relegate engineers to indentured status in industries such as the chemical, nuclear, weapons systems, mining, auto, aviation, railroad and medical devices industries, as well as the new unregulated areas of biotechnology, nanotechnology and artificial intelligence.\n\nThere has been progress in legal protections for whistle-blowers, more civil litigations and, importantly, higher public expectations and popular support for these unsung protectors. There is, however, much more work to do, especially in educating the engineering school curricula and encouraging the numerous engineering societies to take their codes of ethics seriously. But as Nassim Taleb, author of The Black Swan, has written, “Mental clarity is the child of courage, not the other way around.”\n\nIn 1966, in an address to a chapter of the American Society of Engineering Education (reprinted in the new book Ethics, Politics, and Whistleblowing in Engineering, by Nicholas Sakellariou and Rania Milleron [my niece], CRC Press), I said “the [engineering] profession must assert itself towards its most magnificent aspirations—for so much of our future is in your trust.”\n\nWell, isn’t that a great understatement today!?","title":"When Engineers Become Whistleblowers","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/75FD8177-0CC5-4829-BEBE66F3248FBBB7_source.jpg?w=590&h=800&C9D7CD35-1DEE-4719-9C05247151A6C23F","link":"https://blogs.scientificamerican.com/observations/when-engineers-become-whistleblowers/"},{"authors":"Get-Fit Guy Brock Armstrong","pub_date":"May 11, 2019","abstract":"I’ve been trying out various brain training regimens for a few years now. But lately, I’ve been really digging into a series of games that you play on your computer or mobile device for just a few minutes a day, every day, to boost your cognitive function. Or so it promises.\n\nLumos Labs conducted a randomized study of the Lumosity brain training system, and after ten weeks of training, the users improved their working memory, short term memory, processing speed, and overall cognitive function.\n\nCognitive Function and Fitness\n\nPersonally, aside from it being fun to feel like I’m taking a multivitamin for my brain by playing videos games every day, Lumosity (and other brain training systems available) have been showing some promising advantages in the field of exercise and sport.\n\nIn a recent paper published in the Frontiers in Psychology, scientists investigated the role of cognition and neuroscience in understanding, predicting, and potentially improving elite sports performance. Although that particular paper stated “we caution around investing too heavily in such methods at this point in time” I feel like it is a no-lose situation. Even if it doesn’t help me bust out a faster time in my next triathlon, I am still doing something better for my brain than staring at reruns of The Simpsons.\n\n\n\n»Continue reading “How Your Brain Keeps Your Body Fit” on QuickAndDirtyTips.com","title":"How Your Brain Keeps Your Body Fit","origin":"Wellness","image":"https://static.scientificamerican.com/sciam/cache/file/BF996B25-0903-465A-BAC35ADC7B8B96DF_source.jpg?w=590&h=800&7387BC65-2B70-4F35-8A0E1B51FB3314C3","link":"https://www.scientificamerican.com/article/how-your-brain-keeps-your-body-fit/"},{"authors":"Karen Weintraub","pub_date":"May 9, 2019","abstract":"As of this month, there have been more than 750 cases of measles in the U.S. this year across 23 states—the most since 1994, according to the Centers for Disease Control and Prevention. Measles was considered “eliminated” in the U.S. in 2000, although there have been small, sporadic outbreaks since then. A new study looks at how countries have pulled themselves out of past outbreaks of the disease—strategies that may need to be adapted in light of current vaccine hesitancy.\n\nAccording to the study, published Thursday in Science, a country’s control of measles passes along a continuum with three different categories: a large number of cases every year, fewer cases overall but lots of year-to-year variability, and finally, consistently few or no cases. Knowing where a country lies in this continuum–referred to as a “canonical path”—could help it plan its response to the next outbreak, says senior author Justin Lessler, an epidemiologist and associate professor at the Johns Hopkins Bloomberg School of Public Health.\n\n“This was really driven by the laws that govern measles transmission and measles epidemic dynamics,” Lessler says. In the past, “as you had increases in vaccination rates and decreases in birth rates it would really drive countries along this expected path.”\n\n\n\nHow different countries have progressed along the consistent and predictable path for measles outbreaks, 1990-2017. Credit: Matthew Graham, Amy K. Winter, Matthew Ferrari, Bryan Grenfell, William J. Moss, Andrew S. Azman, C. Jessica E. Metcalf, Justin Lessler\n\n\n\nLessler and his colleagues conducted a statistical analysis of measles outbreaks in countries worldwide between 1980 and 2017. By looking at weighted averages of measles cases and year-to-year variability, the researchers placed countries and regions at different points on the continuum. For example, Africa in 2008 was at almost exactly the same stage the Americas were in 1995, according to the research.\n\nThe study should also help a country direct its vaccination efforts, rather than fighting an outbreak based on the patterns of previous ones, Lessler says. If a prior outbreak was particularly severe among small children, many countries will be inclined to focus vaccination efforts on this age bracket, he says. But that is probably not the right approach. If childhood vaccination rates are high and birth rates low, the new analysis suggests that older children and teens may now be the most vulnerable, he says. “The path [the outbreak takes is] dictated by the size of the population you have that’s susceptible to measles,” Lessler says. “You could use the position along the path to understand the age distribution of susceptibility, which could help target vaccination efforts.”\n\nShweta Bansal, an associate professor of biology at Georgetown University in Washington, D.C., says the study allows countries to use a minimal amount of data to identify where they might be on that path. “As a public health communication tool, I think it’s quite powerful,” says Bansal, who was not involved in the research.\n\nBut as the current U.S. outbreaks demonstrate, even countries that had been almost completely measles-free for years are suddenly vulnerable again because people are declining to get vaccinated.\n\nJohn Brownstein, an epidemiologist at Harvard Medical School who was not involved in the new study, says social media has changed the dynamics around measles and other vaccine-preventable diseases—and it is unclear what the repercussions will be. Brownstein says that when he was featured in a recent Facebook video encouraging measles vaccination, the post was flooded with comments opposing vaccines and spreading inaccurate information about both the disease and the vaccine. “It was pretty unbelievable,” says Brownstein, who is also Chief Innovation Officer at Boston Children’s Hospital. “I started trying to comment back to clarify, and the wave [of responses] just was too big for me to be able to handle.”\n\nIt is not clear, Brownstein says, whether historic trends of controlling diseases with vaccines can continue when so many people are passionately opposed to them. Vaccine hesitancy is not new or U.S. specific, he says: “Every location on earth has vaccine confidence issues.” But the internet makes it easier for people who oppose vaccines to find each other and share their opinions.\n\n“There’s a combination of mistrust around government and pharmaceutical companies that is probably different” than with other public concerns, Brownstein says. “There’s also a component of the invasiveness of the needle that’s also at play in our psychology.”\n\nBefore vaccination, measles infected more than 95 percent of all children and was responsible for more than four million deaths worldwide each year. After the introduction of the measles vaccine in the 1960s, childhood deaths from not just measles but a wide range of infectious diseases dropped substantially. Measles seems to erase immune protections that the child has from other infectious diseases. According to a 2015 study in Science that examined historical data, measles outbreaks predict deaths from other childhood diseases two to three years later, suggesting that a measles infection made these children more vulnerable to diseases such as pneumonia and diarrhea.\n\nMany people see measles infections as benign, particularly in young children, but teens and young adults suffer terribly, says Jeffrey Griffiths, a professor in the Department of Public Health and Community Medicine at Tufts University School of Medicine. “It’s a vicious, bad disease and it’s not like getting a cold,” he says. Malnourished children and those with vitamin A deficiencies are particularly vulnerable, with a death rate as high as 50 percent in parts of Africa, Griffiths adds.\n\nThe World Health Organization had hoped to eliminate measles worldwide by 2020. Lessler says that date is not realistic, but he and Bansal say they still believe it will someday be possible to eradicate measles. “Doing this kind of work requires strong optimism,” Bansal says. She adds that measles “represents an ideal case for eradication” because the pathogen is well understood, an effective vaccine exists—the recommended two doses seem to provide long-lasting immunity—and past U.S. experience shows it is possible to limit transmission of the disease for an extended period. “We have a much better chance of [eradicating measles] than other infections, but the challenge of vaccine hesitancy is certainly giving us all cause for concern,” she says.","title":"Measles Outbreaks Follow a Predictable Path—Provided People Get Vaccinated","origin":"Public Health","image":"https://static.scientificamerican.com/sciam/cache/file/4680AE5B-6551-4B75-905E462D9349172B_source.jpg?w=590&h=800&6265D5D4-AFB0-4214-985C31634FEAF4F9","link":"https://www.scientificamerican.com/article/measles-outbreaks-follow-a-predictable-path-provided-people-get-vaccinated/"},{"authors":"Liza Mundy","pub_date":"Scientific American May 2019 Issue","abstract":"Sprightly yellow seems to be the hue of choice for corporate wellness chains designing a logo to attract health-minded women. There is the cleansing grapefruit of SoulCycle, the happy buttercup of Drybar. And last year vans started materializing at busy pedestrian spots in Manhattan and Los Angeles that sported the shade of sunflowers. These vans are mobile fertility clinics, inviting women to pop in and learn how to safeguard their reproductive germ line by freezing their eggs. “Own your future,” the ads on the side promise. “Your fertility, understood.”\n\nThe vehicles are emissaries of Kindbody, a boutique fertility practice that courts the same clientele that frequents spin classes and blow-dry bars. It is one of a small but growing number of outfits that offer fertility services, including retrieving a woman’s eggs, or oocytes, to be frozen for later use. Because eggs are one of the most important factors in female fertility, and both their quality and quantity declines with age, banking eggs promises to lengthen a woman’s window of fertility and postpone the decision of whether to have kids. As a rival service, Extend Fertility, puts it, “Women have more options today than ever before. And we’re giving you one more—the option to start your family when you’re ready.”\n\nThe appearance of boutique egg-freezing outfits is one of the most high-profile—but not the only—recent developments in assisted reproductive technology, which is the science (and commerce) of helping people have the babies they want. These stand-alone clinics exist thanks to a convergence of female financial empowerment, venture capital backing and real medical progress. And it is not just mobile clinics behind the push. Egg freezing is on the rise at gold-standard fertility clinics, such as the one at the University of Southern California. There, according to clinic director Richard Paulson, it accounts for almost 40 percent of egg-retrieval cycles—in which women inject themselves with hormones to stimulate their ovaries to release multiple eggs, and doctors then collect those eggs while the women are under anesthesia. (The other 60 percent of cycles at the clinic involve women undergoing infertility treatment who intend to use the eggs soon.)\n\nUltimately these providers are making the case that egg freezing has come far enough to justify the $10,000-plus bet women place by investing in the procedure and medications not covered by insurance (that price tag does not include the storage fees women must pay yearly to keep the eggs on ice). This confidence stems from significant breakthroughs in the science of fertility and conception made over the past decade, notably a process that allows doctors to flash-freeze eggs. Physicians have also come a long way in the science of in vitro fertilization (IVF)—the process that comes after egg freezing—which unites a thawed egg (or a fresh one) with a sperm for conception in a petri dish and then grows the resulting embryo to the point where it can be put back inside a woman’s uterus to implant.\n\nAll this amounts to a sea change in the science of making babies, one that suggests, in theory, that women are not bound by the traditional notion of the ticking biological clock. Yet in practice, the reality is more complicated. Women must consider other factors besides their eggs, such as their overall health and the health of the sperm they plan to use, in deciding when to get pregnant. And just how good of a bet these new technologies truly are remains to be determined: the vast majority of frozen eggs at clinics have yet to be thawed. The question remains: Will they all be viable? Can science really safeguard fertility for later?\n\nThe freezing boom\n\nIn some places, such as the San Francisco Bay Area, the rise in egg freezing is linked in part to nearby tech companies such as Facebook and Google, which now (and with some fanfare) cover the procedure for employees. In Silicon Valley, egg freezing has become part of the benefits package a prudent career woman may consider availing herself of, a kind of 401(k) for future family formation. The boom also stems from other converging trends. One is the millennial generation’s comfort with social media; boutique clinics have strong presences on Instagram and Twitter, as do a growing number of traditional clinics. Even online dating—which has sold the hope that much messiness of the human heart can be solved by downloading an app—has an impact. “Women have said to me, instead of looking at every date as ‘Is this someone I could marry?’ they can set that aside,” says Marcelle Cedars, director of the University of California, San Francisco’s Center for Reproductive Health.\n\nThe rise in freezing also bespeaks a public inured to paying a monthly fee for products. What egg freezing is—among other things—is one more paid-subscription service, like Netflix or Zipcar. Oocytes, once frozen, must be kept frozen until used. After a woman goes through the not easy or cheap process of having eggs retrieved, she will be powerfully motivated to continue paying the storage fee, which can be as much as $500 or $1,000 a year. Every batch of eggs in liquid nitrogen represents an income stream for years, for the clinic and its investors.\n\n\n\nVitrification devices such as the S-Cryolock (shown) help to freeze eggs and embryos almost instantly to prevent damage. Credit: Jamie Chung\n\n\n\nBut the freezing trend is also the outcome of science. Asked to reflect on stages of progress in the field, Paulson casts his mind back to when in vitro was in its infancy. The first IVF baby was Louise Brown, born in 1978, now a mother herself. The technology for the scheme was nonexistent to the point where doctors had to fashion their own utensils to retrieve eggs and incubate embryos; when the late gynecologist Patrick Steptoe and the late physiologist Robert Edwards were performing the experiments that would result in Brown’s birth, they kept embryos warm in a pouch created in the skin of a living rabbit.\n\nInto the 1980s IVF patients could expect, at best, a 10 to 15 percent delivery rate. “We were able to help a handful of people,” says Alan Penzias, an associate professor at Harvard Medical School and a doctor at Boston IVF. “But not the majority. Most people failed.”\n\nThe retrieval of eggs—the well-protected female germ line—has always been hard. The 1980s saw basic techniques developed and refined; at first, doctors had to perform laparoscopic surgery to extract a single egg the instant it was ovulated. They learned to administer hormones that could cause eggs to ovulate in greater quantity and at a more predictable time and to retrieve them vaginally, with a needle that pokes through to the ovaries. The 1990s were—unexpectedly—the decade of the man. Male-factor infertility—slow or misshapen sperm or low sperm count—is a common reason couples may be unable to conceive. For a long time the only “cure” for male-factor infertility was sperm donation. Then, in 1992, scientists in Belgium announced the first live birth after using ICSI—intracytoplasmic sperm injection—in which a single sperm is injected into the egg. ICSI was a disruptive technology that cured male-factor infertility, for couples who can afford it.\n\nFor more than half a century it has been almost ridiculously easy to freeze sperm, which are stripped-down DNA missiles. The first reported human birth from frozen sperm occurred back in 1953. Not so for the egg, which is among the largest cells in the body and difficult to freeze well. Eggs are mostly water, meaning ice crystals can form, with sharp edges that damage organelles and other delicate structures. For years freezing an egg entailed dehydrating it to the fullest extent possible, then introducing tiny amounts of cryoprotectant, a kind of antifreeze that aims to prevent crystals from forming. Everything was done very slowly. “It would be this painful process that would take about two to three hours,” says Amy Sparks, an embryologist at the University of Iowa, who remembers the agony of ratcheting down the temperature bit by bit. This technology enabled the first human birth from a frozen embryo in 1984; the first birth from a frozen oocyte was reported two years later, in 1986. But for eggs, freezing remained both difficult and damaging: the upshot often was like what happens when you thaw ice cream and refreeze it: icy granulation. “When it thaws, all of a sudden the water from those crystals has nowhere to go and causes damage to the cell,” Sparks says.\n\nThen, about 10 years ago, came the most important recent scientific breakthrough in assisted reproductive technology. Vitrification—from vitrum, Latin for “glass”—is the ability to freeze eggs (and embryos) breathtakingly fast. The procedure involves larger quantities of cryoprotectant than earlier methods and a direct plunge into liquid nitrogen, which triggers “ultrarapid cooling,” minimizes the formation of ice crystals and almost instantly transforms the egg into a glasslike state. “In the past 10 years the impact of vitrification ... has really transformed the field in ways that we could not have foreseen,” says Serena Chen, director of the clinic at Saint Barnabas Medical Center in New Jersey.\n\n\n\nInstead of growing embryos in incubators in the lab, the INVOcell device can be inserted into a patient's vagina to incubate them there. Credit: Jamie Chung\n\n\n\nVitrification is akin to pushing the “pause” button, Chen says; when the time comes, the laboratory pushes “play” and commences rapid thawing. The results are so show-stopping that in 2018, the ethics committee of the American Society for Reproductive Medicine (ASRM)—which up to that point had declined to recommend social use of the technology—issued a paper saying egg freezing “for women attempting to safeguard their reproductive potential for the future” could now be considered “ethically permissible.” In short: egg freezing has gone mainstream. Clinics disagree over whether frozen eggs are as viable as fresh, but most experts, including Paulson and Sparks, say they are very, very close. And there is no question that eggs frozen when a woman is 32 are better than fresh eggs retrieved from the same woman at 42.\n\nBut even great eggs, just like sex, do not always make a baby. Cedars explains to patients that they should not wait to use frozen eggs until their early 40s, because if they do not work, the old-fashioned method might not either. Yet here lies a quandary—if women cannot wait until their fresh eggs have declined, what is the point of freezing in the first place?\n\nIVF strides\n\nVitrification is not the only advance helping to buoy the promise of egg freezing. Other elements of IVF have seen major improvements, such as the new standard of growing an embryo for five days in the lab before transferring it back to a woman. A decade ago embryos were often transferred at the three-day stage, when they consisted of just eight cells. Human embryos now arrive in the uterus as “blastocysts,” with roughly 100 cells, which are more mature and robust and have a much greater chance of success. According to CDC data from 2016, for women younger than 35, nearly 50 percent of fresh embryos transferred at day five resulted in a live birth as compared with 34.4 percent of embryos transferred at day three. For women between 35 and 37, the percentages were 42.1 for day five versus 28.6 for day three.\n\nSuccess rates are also getting better because labs can now closely replicate the chemical environment of the fallopian tube, where embryos spend their first five or so days when pregnancy happens naturally. Labs have gotten much better at regulating the amounts and concentrations of nitrogen, oxygen and carbon dioxide. Current incubators also feature more solid-state technology that requires less opening and closing of doors so that embryos can rest undisturbed.\n\nThe ability to develop embryos to the blastocyst stage means embryologists can more easily recognize the best of the batch before deciding which to try to implant. These judgment calls are also improved by a process called preimplantation genetic selection. Back in the three-day-embryo era, if scientists wanted to gauge the genetic health of an embryo, they had to pry one cell from an eight-cell mass, a lab procedure so harrowing that Sparks still has “nightmares” about it. Now it is much easier to use lasers to grab a couple of cells from the part of the blastocyst that will create the placenta—the less vital section than the one that is destined for the fetus.\n\nAll in all, embryologists’ improved ability to freeze and test embryos amounts to “a huge change,” Penzias says. About 10 years ago, frozen embryos had a 10 percent lower success rate than fresh. “Now we’re talking about parity,” he says. The improved odds mean, in theory, that whether women are using embryos created from eggs retrieved the same month or from those frozen years before, clinics can transfer just one embryo at a time rather than the two or three that used to be the norm. For 14 years it has been the University of Iowa’s policy that if a woman is younger than 38, has no prior failed transfers at the clinic and has at least a single good-looking blastocyst (a five-day-old embryo), then one is “all they get,” Sparks says. These trends have reduced the prevalence of twins, and especially of triplets and higher-order multiples, which are much riskier pregnancies than carrying singletons, for both babies and moms. At the University of Iowa, the rate of twin birth used to be 40 percent in 2001; now it is under 5 percent. Industrywide, according to the CDC, the portion of transfers involving a single embryo has more than tripled, from 12 percent in 2007 to 40 percent in 2016. Equally important: the percentage of fresh single-embryo transfers resulting in a live birth increased from 21 percent in 2007 to 37 percent in 2016.\n\nThese innovations are just the beginning. A new invention allows a woman to incubate embryos inside a device inserted in her vagina rather than an incubator in the lab. And even more radical technologies are on the horizon: Mitochondrial replacement therapy, for instance, is a controversial procedure that can eliminate the risk of genetic mitochondrial disease by injecting the nucleus of a mother’s egg into an egg from a woman without the disease whose nucleus has been removed but whose mitochondria remain. The procedure is banned in the U.S., out of concerns about mixing the DNA of two women, but is being developed in England. The day is also coming, Paulson says, when it will be possible to use stem cell technology to manufacture sperm and eggs from normal body cells, such as skin cells. Although it sounds like science fiction, the procedure would involve no changes to a cell’s DNA, so that part, at least, is less worrisome than mitochondrial transfer. With this technology, women would no longer need to bank eggs. “At 45, you can still have an egg made out of your skin cells,” Paulson says. It sounds wild, but so did IVF 40 years ago. “It’s going to happen.”\n\nTicking clocks\n\nIt is a fact that a woman is born with all the oocytes she will have; over time her ovarian reserve diminishes, as does the quality of her eggs.\n\nTalking about this subject has always been fraught. Back in 2001, when the ASRM launched an ad campaign partly about age-related infertility, the National Organization for Women attacked it as coercive and antifeminist. Chen says this reaction does women a major disservice; older eggs are more likely to be chromosomally abnormal, with a higher risk for miscarriage and the grief that follows. She adds that egg freezing is often depicted as elective and narcissistic, “kind of like plastic surgery or getting a cute Mini Cooper.” But women face many pressures, particularly in their mid-30s, when each year of delayed childbearing means an increase in earning power. “It’s not about women just being selfish and trying to work on their careers,” Chen says. “The truth is, a lot of people just haven’t found the right partner.”\n\nStill, Chen shares concerns about the commercialization of a technology that originally aimed to help cancer patients preserve fertility during treatment. Jake Anderson-Bialis, co-founder of the consumer education Web site FertilityIQ, worries that women do not realize taking hormones and then undergoing retrieval is not a minor lunch-hour-type procedure. And there is still no guarantee the eggs will result in a live birth. The backlash could be huge if many of the women now freezing their eggs later attempt to use them, only to find out their investment failed. The dirty secret of the fertility industry, up to now, has been multiple births; going forward, Anderson-Bialis says, “if there’s going to be a black eye, it’s egg freezing.” By this, he means the danger that the eggs, once thawed, will not be viable—a potentially devastating outcome to women sold on the promise of egg freezing. Cedars agrees that some women are too bullish on what technology can accomplish. “We have to repeatedly say to patients, ‘There’s not a baby in the freezer,’” she says. “‘There is the potential for a baby.’”","title":"Pausing Fertility: What Will Happen When the Eggs Thaw?","origin":"Medical & Biotech","image":"https://static.scientificamerican.com/sciam/cache/file/6B5508D9-2E75-43D6-A5348FDC2E9834C6_source.jpg?w=590&h=800&CB34AD6B-2151-4288-834BC982BFD191E6","link":"https://www.scientificamerican.com/article/pausing-fertility-what-will-happen-when-the-eggs-thaw/"},{"authors":"THE EDITORS","pub_date":"September 1, 2017","abstract":"Editor’s Note (5/8/19): This article is being republished because Georgia’s governor signed a bill into law Tuesday that bans abortions as soon as a fetal heartbeat can be detected, as early as six weeks into a pregnancy.\n\nThere's something rotten in the state of women's health. As this article is being written in July, Republicans in Congress are engaged in a frenzied effort to repeal and replace the Affordable Care Act (ACA) put in place by the Obama administration. At least 22 million Americans would lose medical insurance by 2026 under the latest version of this plan—which includes large cuts to Medicaid—and lack of insurance means more sickness and death for thousands, data show. These cuts threaten to affect women more than men—whether by removing basic health coverage, cutting maternity care or sharply limiting reproductive rights.\n\nIt's time to take a stand against this war on women's health.\n\nCurrent events are just the latest insult in a long history of male-centric medicine, often driven not by politicians but by scientists and physicians. Before the National Institutes of Health Revitalization Act of 1993, which required the inclusion of women and minorities in final-stage medication and therapy trials, women were actively excluded from such tests because scientists worried that female hormonal cycles would interfere with the results. The omission meant women did not know how drugs would affect them. They respond differently to illness and medication than men do, and even today those differences are inadequately understood. Women report more intense pain than men in almost every category of disease, and we do not know why. Heart disease is the number-one killer of women in the U. S., yet only a third of clinical trial subjects in cardiovascular research are female—and fewer than a third of trials that include women report results by sex.\n\nThe Republican assault on health care will just make things worse. The proposed legislation includes provisions that would let states eliminate services known as “essential health benefits,” which include maternity care. Before the ACA made coverage mandatory, eight out of 10 insurance plans for individuals and small businesses did not cover such care. The proposed cuts would have little effect on reducing insurance premiums, and the cost would be shifted to women and their families—who would have to take out private insurance or go on Medicaid (which the proposed bill greatly limits)—or to hospitals, which are required by law to provide maternity care to uninsured mothers.\n\nThe bill, in its current form, would also effectively block funding for Planned Parenthood, which provides reproductive health services to 2.4 million women and men. The clinics are already banned from using federal funding for abortions except in cases of rape or incest or when the mother's life is in danger, in accordance with the federal Hyde Amendment. So the Planned Parenthood cuts would primarily affect routine health services such as gynecological exams, cancer screenings, STD testing and contraception—and these clinics are sometimes the only source for such care. Regardless of which side you are on in the pro-life/pro-choice debate, these attempts to remove access to such basic services should alarm us all.\n\nThe Trump administration also has been chipping away at the ACA's birth-control mandate. A proposed regulation leaked in May suggested the White House was working to create an exemption to allow almost any employer to opt out of covering contraception on religious or moral grounds. Nationwide, women are increasingly turning to highly effective long-acting reversible contraceptives (LARCs) such as intrauterine devices (IUDs). The percentage of women aged 15 to 44 using LARCs increased nearly fivefold from 2002 to 2013. Decreased coverage for contraceptives translates to less widespread use and will likely mean more unintended pregnancies and abortions.\n\nAnd abortions will become harder to obtain. After Roe v. Wade, many states tried to put in place laws to hamstring abortion clinics. These efforts have only ramped up in recent years, as many states have enacted so-called TRAP laws (short for targeted regulation of abortion providers), unnecessarily burdensome regulations that make it very difficult for these clinics to operate. Recognizing this fact, the Supreme Court struck down some of these laws in Texas in 2016, but many are still in place in other states. Rather than making women safer, as proponents claim, these restrictions interfere with their Supreme Court–affirmed right to safely terminate a pregnancy.\n\nWhether or not the repeal-and-replace legislation passes this year, these attacks are part of a larger war on women's health that is not likely to abate anytime soon. We must resist this assault. Never mind “America First”—it's time to put women first.","title":"It’s Time to End the War on Women’s Health","origin":"Public Health","image":"https://static.scientificamerican.com/sciam/cache/file/C1DEB68A-DD7C-40C9-A715C0BD5C2DFED1_source.jpg?w=590&h=800&D8646F89-7E8B-4150-8212D9ACA4602802","link":"https://www.scientificamerican.com/article/it-rsquo-s-time-to-end-the-war-on-women-rsquo-s-health/"},{"authors":"Caleb A. Scharf","pub_date":"April 25, 2019","abstract":"As scientific fields go, both physics and cosmology arguably get to have the most fun. I don’t mean in terms of day-to-day humdrum research, but in terms of speculation at the frontiers of knowledge.\n\nConsider for example the pleasures of the multiverse. The harder astronomers work to pin down the fundamental parameterizations of the cosmos, from its matter contents to its ordinary energy and dark energy, the more it looks like a reality borne from the physics of inflation. This is a phenomenon that produces exponential expansion of space, resulting in the noise of quantum fluctuations on teeny tiny scales ending up as the seeds of structure on cosmic scales – like galaxies and stars. It also propels a universe towards a spatially flat geometry. And inflation, as we currently think of it, seems to almost inevitably lead to many, many, many universes. \n\nThat’s fun (in the loosest definition of that term) because with enough physical realities maybe there really are repeats of everything that we know – right down to you, your dog, what you had for breakfast, and the text of this article that you’re reading right now.\n\nThen there are more philosophically motivated arguments that perhaps our universe is the result of experimentation or deliberate simulation. Maybe it was born in a super-powerful particle accelerator out of something like an inflating, energetic monopole, or in a hugely advanced quantum computer capable of modeling an entire cosmos of atoms and photons. In either case the line between real and unreal is irrevocably blurred. For example, to simulate a universe that exhibits the mind-boggling complexity that we experience – or think that we experience – requires the construction of a model that is pretty much as mind-bogglingly complex and physical as if it actually existed as a mind-bogglingly complex and physical reality.\n\nThere are even arguments for why it is actually quite likely for us to be ‘inside’ such a simulation (where ‘quite likely’ is philosopher-speak for ‘who knows, but it’s good for the lecture circuit’). Specifically, even if only a very few species (assuming an external physical reality like the one we experience) are sophisticated enough to construct a universe simulation, they might end up running huge numbers of such simulations. Perhaps to explore the lives of their ancestors, or perhaps to show off to the neighbors. \n\nIn all cases, the consequence of there being vast numbers of simulated realities would be that it is far more likely that you are simulated than real – it’s just a numbers game. Indeed, since we are not yet technologically sophisticated enough to build such models the odds may be even greater that we are in fact a simulated ancestor species. \n\nBut whether this is a simulation, or a bona-fide physical reality produced by someone’s laboratory tinkering, an important question is raised.\n\nThat is: why aren’t things a bit better?\n\nI mean, come on. A universe with an accelerating cosmic expansion – as we seem to have - is astonishingly inconvenient. In a few hundred billion years it will become extremely difficult, if not impossible, for a sentient species to make any kind of meaningful sense out of the cosmos – as distant matter becomes effectively unseeable due to the expansion of spacetime. There are other issues too. Already the rate of star formation has dropped to a mediocre level, ensuring a future consisting mostly of dismal little red dwarfs and few new planets. And what about the peculiarities of physics – from quantum mechanics to thermodynamics and all of this ‘emergent phenomena' stuff? Honestly, it does seem a bit patched together.\n\nWhich brings me to a disquieting conclusion and new twist to the idea that we might exist within a manufactured universe. Even for some hyper-advanced intelligent species, building or simulating universes would have to be quite costly in terms of resources. Therefore, it’s not unreasonable to expect that some corners have to be cut, some expenses kept under control. \n\nI’m reminded of the legend of the dry comment often attributed to the astronaut Alan Shepard when asked how he felt sitting atop an enormous rocket about to blast off to space. His response was (with some likely paraphrasing added over the years) “I just kept looking around at all those dozens of instruments in front of me and reminding myself that every one was supplied by the lowest bidder.” \n\nPerhaps this is indeed the ultimate answer to why our universe is a little squirrely. While it is remarkable how well much of it can be understood – albeit with centuries of effort on our part – in other respects it is also highly resistant to being easily decoded. Built by the lowest bidder it would suffer from some corner-cutting, some inconsistencies and illogical quirks. \n\nAnd that leads to the ultimate question, the one that we all seek the answer to. \n\nHow do I get in touch with customer service?","title":"The Lowest Bid Universe","origin":"Life, Unbounded","image":"https://static.scientificamerican.com/blogs/cache/file/AEBD30B0-065B-4003-9107B8672FDED09C_source.jpg?w=590&h=800&F547C62E-DB43-43FA-97F9D4286B14D052","link":"https://blogs.scientificamerican.com/life-unbounded/the-lowest-bid-universe/"},{"authors":"Evelyn Lamb","pub_date":"May 3, 2019","abstract":"Approximation is a recurring theme in mathematics. Sometimes it seems like all of mathematics is saying, “Well, I know how to solve the problem in this domain. Is there a way I can approximate other domains with this domain?” A lot of calculus boils down to approximating arbitrary functions with linear functions. (For our purposes, “linear” means “completely well-behaved.”) Fourier analysis, which forms the backbone of signal processing, is all about approximating complicated periodic functions with sums of simple sine waves. Scores of mathematicians spend their time thinking about what conditions allow us to approximate functions by simpler functions. A mathematical space called Swiss cheese is yet another example of the ubiquity of approximation.\n\nLike the deli counter staple, mathematical Swiss cheeses are full of holes. To make a Swiss cheese, we start with a closed disc or filled-in circle, the set of all points in the plane that are less than or equal to a given distance (the radius) from a central point. \n\n\n\t\n\t\tWhat a lovely, cheesy disc! Credit: Evelyn Lamb\n\t\n\n\nNow we punch it full of holes in a particular way. We want to remove open discs (filled-in discs, but without their boundaries), and we have some rules about the removed discs. If you look up definitions of Swiss cheeses in math, you will see a various definitions, but just like Emmentaler and Gruyére, they are just different particular varieties that all count as Swiss cheese. \n\nThis being theoretical math, we remove an infinite number of discs, but we require that the sum of the areas of the removed discs is less than the area of the original disc (often quite a bit less), that no two removed discs overlap, and that the resulting space has no interior. That is, if we zoom in on any part of the space, no matter how small, there are holes in it. It’s hard to imagine such a space (and impossible to draw it, which didn't stop me), but there are ways to make sure the definition works mathematically.\n\n\n\t\n\t\tAn approximation of a mathematical Swiss cheese. It's very difficult to draw a picture with interesting features at arbitrarily small scales. Credit: Evelyn Lamb\n\t\n\n\nSwiss mathematician Alice Roth, the first person to describe these spaces, was trying to understand the limits of approximations of continuous functions by rational functions in the complex plane. A rational function is the ratio of two polynomials. Polynomials might be familiar to you from algebra classes. They are some of the simplest and easiest to understand functions. They have expressions like z+5 or z3-9z+7. Rational functions have expressions like (z3-9z+7)/(z+5).\n\nIs it always possible to approximate continuous functions by rational functions, or are there some spaces where this fails? Roth and other mathematicians showed that there are continuous functions on Swiss cheeses that cannot be approximated by rational functions.\n\nI am both a mathematician and a lover of cheese, so when I first heard that there were mathematical objects called Swiss cheeses, I was intrigued. The related research paper titles were delightful. Abstract Swiss Cheese Space and the Classicalisation of Swiss Cheeses. Swiss cheeses, rational approximation and universal plane curves. On the volume of the intersection of two Wiener sausages. (That last paper describes Swiss cheese-related calculations on another punny mathematical space called a Wiener sausage. Mathematicians like food.) Everything about this was relevant to my interests. When I learned about the history of the name, it got even better.\n\nWhen she first described them, Alice Roth did not use the term Swiss cheese. As far as I can tell, she didn’t name them anything in particular. She used them as an important example in her doctoral thesis at the Swiss Federal Institute of Technology in Zürich, won an award for that thesis, and graduated with her Ph.D. She had a thirty-year career as a high school teacher, during which she did not publish any mathematical research. After retiring, she jumped back into research, still in the same field she had studied thirty years before, and continued doing important work in her late 60s and early 70s. (Take that, G. H. Hardy and your “math is a young man’s game” nonsense!) Sadly, she died of cancer at age 72, while she was still full of mathematical creativity and enthusiasm.\n\nDuring Roth’s teaching career, while she was absent from the research world, Swiss cheeses were rediscovered independently in the 1950s by Soviet-born Armenian mathematician Sergey Mergelyan, who constructed them for similar reasons, probing the limitations of approximation in various settings. At some point, because of all the holes, someone started referring to them as Mergelyan’s Swiss cheeses. When Roth returned to research, she saw her examples attributed to Mergelyan in publications and corrected the record. The name Swiss cheese turned out to be even more appropriate than the person who coined it could have realized.\n\nFor more on Alice Roth, her Swiss cheese, and her other contributions to approximation theory, check out “Alice in Switzerland: The Life and Mathematics of Alice Roth” by Ulrich Daepp, Paul Gauthier, Pamela Gorkin, and Gerald Schmieder.","title":"The Serendipity of Swiss Cheese","origin":"Roots of Unity","image":"https://static.scientificamerican.com/blogs/cache/file/427AD491-3876-431F-9CA35E53EC6F19A4_source.jpg?w=590&h=800&A8960A06-8DE4-4DC6-A7DAD9E0273D1D5B","link":"https://blogs.scientificamerican.com/roots-of-unity/the-serendipity-of-swiss-cheese/"},{"authors":"Nutrition Diva Monica Reinagel","pub_date":"May 9, 2019","abstract":"Perhaps you saw the headlines last week about a new analysis finding that people who consumed a lot of fiber are significantly less likely to die from heart disease, stroke, Type 2 diabetes, and colon cancer.\n\nHow could such a frumpy nutrient make such a big difference in our health? After all, fiber is, by definition, indigestible by humans. It provides no vitamins, minerals, or energy. And yet, fiber intake is consistently linked with lower disease risk.\n\nThere are a number of possible explanations.\n\nHow Fiber Keeps Us Healthier\n\nFirst, fiber has the charming habit of taking out the trash. Insoluble fiber acts as a sort of broom, sweeping waste material out of the large intestine and lowering the risk of colon cancer. Soluble fiber acts more like a sponge, sopping up cholesterol, thereby lowering the risk of heart disease.\n\n\n\n»Continue reading “Can Fiber Undo the Damage of a High Fat Meal?” on QuickAndDirtyTips.com","title":"Can Fiber Cancel Out Calories?","origin":"Wellness","image":"https://static.scientificamerican.com/sciam/cache/file/5C4EFA72-4A75-4CE0-B61140436ABFB52A_source.jpg?w=590&h=800&CF796776-D8D1-4DCD-8D7E0DE6F5A66445","link":"https://www.scientificamerican.com/article/can-fiber-cancel-out-calories/"},{"authors":"Jennifer Frazer","pub_date":"May 2, 2019","abstract":"The fire chaser beetle, as its name implies, spends its life trying to find a forest fire.\n\nWhy a creature would choose to enter a situation from which all other forest creatures are enthusiastically attempting to exit is a compelling question of natural history. But it turns out the beetle has a very good reason. Freshly burnt trees are fire chaser beetle baby food. Their only baby food.\n\nFire chaser beetles are thus so hell bent on that objective that they have been known to bite firefighters, mistaking them, perhaps, for unusually squishy and unpleasant-smelling trees.\n\nThey have descended on at least one UC Berkeley football game at California Memorial Stadium -- rather unfortunately situated in the midst of some recently burnt pine hills -- at which an estimated 20,000 cigarettes were being smoked. The beetles’ disappointment on discovering the source of the “fire” was probably only matched by the irritation of the smokers swatting confused beetles attempting to bite their necks and hands.\n\nThey have shown up on hot pipes and other equipment at lumber yards and sugar mills, tar plants, cement kilns, smelters, and on one occasion, a colossal 1925 oil tank explosion in Coalinga, California. In that last case, the flames reached hundreds of feet into the air and were visible for over 30 miles … but the nearest plausible beetle-bearing forest was 80 miles away.\n\nThat last detail implies something amazing about fire chaser beetles: they can sense fires from distances over which car stereos are hard pressed to pick up FM radio.\n\nIn fact, because the infrared emission of a burning oil tank of known volume (in this case, 750,000 barrels) can be calculated with reasonable certainty, scientists that studied the Coalinga oil tank explosion have inferred the beetles can detect infrared radiation intensities so low that they are buried in the thermal noise around them. But … how?\n\nInfrared radiation, a proxy for heat, is a reliable source of information about fire because it propagates outward in a clear gradient, dampened only by humidity. It gives a very accurate indication of distance and direction from the source. A highly sensitive infrared sensor can detect a surface fire from space.\n\nA flying fire chaser beetle appears to be trying to give itself up to the authorities. Its second set of legs reach for the sky at what appears to be an awkward and uncomfortable angle.\n\n\n\tFire chaser beetle flying posture (top), heat eye (middle), and cross section of an individual sensillum in the array (bottom). Credit: Schmitz and Bleckmann 1998\n\n\nBut the beetle has a good reason. It’s getting its legs out of the way of its heat eyes, pits filled with infrared sensors tucked just behind its legs.\n\nThe heat eyes on the sides of fire chaser beetles are filled with about 70 infrared sensilla. Inside each sensillum is a hair-like sensor (called a dendritic tip in the diagram above) that physically deforms when the sensillum expands in response to heat, triggering a neural response.\n\nSuch arthropod hair sensors are incredibly sensitive. Spiders possess versions called trichobothria that detect air movement – such as that caused by movement of web or prey – with such sensitivity that they are tripped by levels not much higher than the random movement of air molecules (Brownian motion), or, as the authors of recent paper on the oil-tank-fire-beetle-sensitivity-question put it, “at the limit of the physically possible”.\n\nIn addition to containing similar hypersensitive mechanoreceptors, the sensilla in fire chaser beetle heat eyes are found in arrays of 70-90. A signal picked up by more than one of them can be summed up and amplified by the neurons that wire the array. As a result, the heat eye can detect softer signals than a single sensor could.\n\nFinally, it is also possible the beetles are better able to detect a signal buried in noise due to a spooky (to me) phenomenon called “stochastic resonance”. In this scenario, added thermal noise counterintuitively helps a sensor pick up a signal.\n\nA signal below the threshold for triggering a sensor – but still close to it – will resonate by chance with a portion of thermal noise that is the same frequency. When there is more noise, there is more signal at that resonant frequency. Together, noise plus signal adds up to an impulse sufficient enough to trip the sensor when signal alone or signal with less noise would not. Incredibly, the measurement gets more precise in the presence of noise than without.\n\nThough deeply counterintuitive, stochastic resonance has been demonstrated over and over in biological systems, including several times in humans. For example, humans can detect a touch stimulus that would normally be undetectable when they are exposed to a mechanical vibration at the same time. The portion of the vibration that “resonates” with the touch sums to trigger mechanoreceptors in skin. Crazy but true.\n\nThus, though the fire chaser beetle’s ability to detect fire may seem supernatural, it may operate on physical principles that are also at our very own fingertips.\n\nReferences\n\nSchmitz, H., and H. Bleckmann. \"The photomechanic infrared receptor for the detection of forest fires in the beetle Melanophila acuminata (Coleoptera: Buprestidae).\" Journal of Comparative Physiology A 182, no. 5 (1998): 647-657.\n\nSchmitz, H., and H. Bousack. \"Modelling a historic oil-tank fire allows an estimation of the sensitivity of the infrared receptors in pyrophilous Melanophila beetles.\" PLoS One 7, no. 5 (2012): e37627.","title":"How a Half-Inch Beetle Finds Fires 80 Miles Away","origin":"The Artful Amoeba","image":"https://static.scientificamerican.com/blogs/cache/file/1EE77E5A-293D-428E-AE545E111D202764_source.jpg?w=590&h=800&CE1F9762-3583-4233-A82C7BD12B2E176C","link":"https://blogs.scientificamerican.com/artful-amoeba/how-a-half-inch-beetle-finds-fires-80-miles-away/"},{"authors":"Nola Taylor Redd","pub_date":"May 9, 2019","abstract":"The mysterious source of Earth’s water has intrigued generations of scientists. Learning how this liquid—the cornerstone of life as we know it—made its way to our planet has sweeping implications, for the possibility of alien biospheres not only elsewhere in the solar system but also on worlds orbiting other stars. But understanding how water arrived on Earth has proven surprisingly difficult.\n\nAfter the sun formed from a cloud of dust and gas, the remaining protoplanetary disk of material was probably rich in water’s raw ingredients, hydrogen and oxygen. But conventional wisdom holds that the newborn star’s radiance boiled away much of those volatile gases from the inner solar system, leaving mostly dry material from which to build Earth and the other rocky planets. The majority of Earth’s moisture must have arrived later, by some other means.\n\nFor decades, scientists considered icy comets of the outer solar system as the most likely suspects, until observations revealed that most comets’ compositions did not quite match that of Earth’s oceans. And so consensus shifted toward asteroids as the source of Earth’s seas, since these rocky bodies also contain nontrivial amounts of water and are conveniently located close by, where they could have easily rained down on the young Earth. Now, however, an investigation of comet 46P/Wirtanen suggests that the bulk of Earth’s water may have come from comets after all, even though asteroids likely still played an important role.\n\nUsing NASA’s Stratospheric Observatory for Infrared Astronomy (SOFIA), an airplane-mounted telescope that can fly above much of Earth’s atmosphere, a team of researchers measured the proportion of heavy water, or deuterium, to normal water in comet 46P. Whereas the hydrogen nucleus of regular water contains a solitary neutron, deuterium’s nucleus contains both a proton and neutron, making it twice as heavy—and, more importantly, making it evaporate more slowly than normal water. This means the deuterium-to-hydrogen ratio (D/H) of any given object would be expected to vary depending on the distance at which it formed and lingered around the young sun, allowing the ratio to serve as a fingerprint for tracing water’s origins. Find a comet or asteroid with a D/H ratio identical to Earthly seawater, and you have perhaps found a chunk of undelivered ocean; obtaining D/H ratios for multiple objects may yield patterns that reveal the migration of water around the early solar system. Out of a handful of comets whose D/H ratio have been studied, comet 46P is the third known to have a D/H ratio similar to Earth’s.\n\n“It’s fantastic that they’ve got another D/H ratio,” says cometary scientist Karen Meech, of the University of Hawaii’s Institute for Astronomy. Meech was not part of the new research. “It’s very important for trying to understand what’s going on.”\n\nD/H may trace water through the young planetary disk, but it turns out to be a tricky process. Some models suggest the abundance of deuterium grows linearly moving away from the sun; others suggest the abundance shrinks under those same circumstances. Several that seek to replicate the chaotic, turbulent mixing of material in the early solar system predict deuterium abundances varying wildly at different points for no discernible reason. And observations have shown indeed that comets—even those apparently born in close proximity to each other—can have dramatically different D/H ratios. “Until now, we had a dozen measurements that looked kind of random,” says team leader Dariusz Lis, an astrophysicist at the California Institute of Technology. But 46P revealed a surprising new relationship that makes at least some of the measurements appear a little less random. Along with 46P, the other two comets known to have D/H ratios similar to Earth’s oceans, comets 103P/Hartley and 45P/Honda-Mrkos-Pajdušáková, are “hyperactive” objects, meaning they spew off more water than would be predicted based on their surface area alone. “Now, for the first time, we see a correlation between the D/H ratio … and the active fraction,” Lis says.\n\nThe results may have implications for all comets. The excess activity in hyperactive comets comes from water brought up from their interior. If, as Lis and his co-authors suggest, water from hyperactive comets’ nuclei has a more Earth-like D/H fingerprint, this may mean Earth-like water could be hidden deep inside other, nonhyperactive comets as well, putting the spotlight back on comets as an early water source.\n\nSoon to be published in the journal Astronomy & Astrophysics, the result could not only bolster the case for comets as deliverers of Earth’s water, but also tweak the initial conditions that led to life’s origins. “If you knew comets were raining down on Earth during the early stages of formation, that would have profound implications for what material was available for the very beginning stages of life,” says Maria Womack, a comet researcher at the University of South Florida who was not part of the new study.\n\nHyperactive Comets\n\nWhen comets draw close to the sun, their icy surface warms, jumping from solid to gas through a process called sublimation. Hyperactive comets such as comet 46P, however, do something more, somehow spewing off large chunks of ice into their coma, the nebulous cloud that surrounds the cometary nucleus. The tumbling ice chunks remain solid, sublimating in the coma rather than on the surface and providing the “hyper” in hyperactivity.\n\nThose solid chunks could explain the near-Earthly D/H ratio in comets like 46P. Lis and his colleagues suggest that, even if a comet’s surface material is heated and altered by the sun, its inner nucleus could remain relatively pristine for eons. On the surface, solar heat and radiation could evaporate some of the regular water, changing the ratio of normal and heavy water. Deep inside, however, those ratios may remain unchanged from their initial fingerprint (one that could match Earth’s oceans) set billions of years ago during the solar system’s formation. Heat-induced pressures in the comet trigger the release of volatile gases such as carbon dioxide or carbon monoxide, which are buried deep down in the nucleus. As the heated volatiles rise, they may push material from the nucleus to the surface, where it is blasted off to sublimate in the coma, revealing a fingerprint strikingly similar to Earth’s. If that is the case, the researchers suggest that all comets may carry water in their nucleus with a D/H ratio more like our planet’s.\n\nMeech is not yet convinced. In 2005, NASA’s Deep Impact mission blasted a crater in comet Tempel 1. Meech, who was part of that mission, says it showed that fresh material was only a few centimeters beneath the surface rather than hidden deep inside the nucleus. Thus, material blown from the heart of a comet should be similar to what is sublimating from the near-surface. Other missions to comets seem to support that finding. “Based on what was seen with the Deep Impact, EPOXI and Rosetta missions, I, don’t see any reason why the stuff [a hyperactive comet is] ejecting would be any more or less primitive than any other comet,” she says.\n\nOthers, such as comet researcher David Jewitt at the University of California, Los Angeles, are more concerned with simply getting that water to Earth. In addition to D/H ratios, celestial mechanics make a solid argument for asteroids as a dominant source of Earth’s water. Asteroids from the asteroid belt can crash into Earth much more readily than even the closest comets in the outer solar system, and research has revealed that many asteroids contain water with Earth-like fingerprints locked up inside of minerals. And, given the relative ease with which asteroids can pummel the inner planets, it is straightforward to envision them bombarding Earth in necessary numbers to fill the oceans—something that cannot be readily said for comets. According to Jewitt, all of the water in Earth’s oceans would make a single ball about 600 kilometers across or about a billion one-kilometer sized comets roughly the size of 46P. (The average comet is less than 10 kilometers across.)\n\nThe idea that all comets carry Earth-like water in their nucleus remains “a very provocative idea,” says Sean Raymond, a researcher at the Laboratoire d’Astrophysique de Bordeaux in France who models early solar system evolution. “It’s definitely one worth testing.” More in-depth laboratory tests could help reveal whether a comet hiding Earth-like water could be giving off a different D/H ratio, Jewitt says, and that could provide insights into water in the early solar system. But alone, it’s not enough.\n\nRight now, with only three hyperactive comets and a handful of regular comets having measured D/H ratios, the connection between the two remains nebulous. Fundamentally, the most important way to test whether all comets harbor Earth-like water in their nuclei is to find and study many more. “We’ve got to go out and get more of these and see if that prediction holds true,” says Edwin Bergin, a researcher at the University of Michigan who hunts for water in the protoplanetary disks around other stars. Bergin was not part of the new research.\n\nImproving technology should continue to make it easier to measure the D/H ratio of more comets from the ground, while future missions could make even more detailed observations from space. “We need more measurements,” Lis says. “We have gathered a little more than a dozen measurements in the past 25 years. That’s not enough to make a statistical study.”","title":"Hyperactive Comets Hint at Origins of Earth’s Oceans","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/5FAB160C-5BC5-4932-B2FFBBCF17EC0912_source.jpg?w=590&h=800&46059617-9BD4-45A9-BCCFA66F9F48930B","link":"https://www.scientificamerican.com/article/hyperactive-comets-hint-at-origins-of-earths-oceans/"},{"authors":"Hanneke Weitering, SPACE.com","pub_date":"May 10, 2019","abstract":"Blue Origin is shooting for the moon!\n\nThe private spaceflight company revealed the first life-size mockup of its new lunar lander, named “Blue Moon,” at the Washington Convention Center yesterday (May 9). \n\n“This is an incredible vehicle, and it’s going to the moon,” Blue Origin founder and chief executive Jeff Bezos told a room full of spectators after the curtain dropped to reveal the big, shiny spacecraft. \n\nBlue Moon is designed to carry rovers and other large payloads to the lunar surface, but it could also take astronauts to the moon, said Bezos, who also founded Amazon.com and is the richest person in the world. To modify Blue Moon for a crewed spaceflight, the company would top the spacecraft with an attachable, pressurized ascent vehicle. \n\nBefore launching astronauts to the moon, Blue Origin would first test out the lunar lander with an uncrewed mission, Bezos said. \n\nWhile Bezos did not explicitly state that Blue Origin plans to offer its new vehicle to NASA for the agency’s ambitious push to land American astronauts on the moon in 2024, a newly posted description on the company’s website states that the crew-carrying variant of Blue Moon “has been designed to land an ascent vehicle that will allow us to return Americans to the moon by 2024.” \n\n(Blue Origin representatives had mentioned Blue Moon before, but they hadn’t given us a good look until this week.)\n\nNASA has not yet selected a lander for that historic trip, so Blue Moon may be a contender. Just last month, Lockheed Martin revealed its proposed plans to build a lunar lander. Lockheed’s lander (which has yet to receive a proper name) would be part of the company’s “early Gateway” infrastructure for a sustainable human presence on the moon.\n\nWhether NASA astronauts can really make it to the moon by 2024 is still a subject of debate, but a few things are certain: private companies and other space agencies around the world are gearing up for a new wave of lunar exploration, and Blue Origin has entered the new moon race. \n\nCopyright 2019 Space.com, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.","title":"Blue Origin Unveils “Blue Moon,” Its Big Lunar Lander","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/8B925766-F527-4324-B9A114CE76B766E8_source.jpg?w=590&h=800&55909832-0B53-4FEB-B3C6C74F72D592AA","link":"https://www.scientificamerican.com/article/blue-origin-unveils-blue-moon-its-big-lunar-lander/"},{"authors":"Sandro Galea","pub_date":"May 9, 2019","abstract":"This month, the world saw the first-ever image of a black hole. The picture was captured by the Event Horizon Telescope, a network of radio telescopes operated by a global team of scientists. The black hole is 53.49 million light-years away, at the center of the Messier 87 galaxy. Taking a picture of such a distant object was an immense feat of science and engineering. The roots of this achievement stretch from Einstein’s first theorizing about the existence of black holes, all the way to the creation of cutting-edge technology that allowed us to finally see one.\n\nSuch stories are reminders of why it sometimes feels like science can do anything, from exploring the cosmos, to peering into the distant past, to blurring the boundary between life and death. And that feeling often extends to the science that informs our health. On that front, the 20th century brought a host of major discoveries, from penicillin to the double helix. As the Digital Age ushers in new advances, it is as easy as it has ever been to imagine that science really can solve all our health problems one day.\n\nOur behavior suggests we may even hope that, through the power of science, we can one day innovate our way out of the human condition—the inevitability of age and death. Consider: the United States spends far more on health care than any other country in the world. The vast majority of this spending goes to the drugs and treatments that are the fruits of scientific discovery. With this sky-high spending have come sky-high expectations.\n\nWe eagerly await the drugs that will cure dreaded diseases like cancer and AIDS. We are fascinated by the evolution of precision medicine, with its possibility of tailoring treatment to an individual’s specific lifestyle and genetic code. And we thrill at the notion that technology might extend life indefinitely, that we can someday “hack” mortality, if we can only get the science right.\n\nThese hopes inform a spirit of exploration, one that we should nurture. Yet unbounded confidence in science can also distract us from the core forces that underlie our lives and health—forces far larger than any theorem, technology or cure.\n\nEach day, we are deeply influenced by the social, economic and environmental conditions that surround us. These conditions are at the heart of how our lives unfold, deciding whether we are sick or well. We must have the humility to acknowledge the influence of these forces. When we do not, we open the door to hubris, and risk undermining the very goals we accumulate knowledge to pursue.\n\nThere are ample examples of how we have neglected the foundational forces that shape health, even as we have poured resources into developing new treatments. Take asthma. If a child has asthma, science can indeed provide her with medicine for her illness. But why does she have asthma to begin with? Could it be because she is a child of color, a demographic with a higher asthma risk? Or because she grew up in an economically disadvantaged neighborhood, located near a pollution center like a major roadway, as such neighborhoods often are?\n\nOr could it even be because of political decisions to build the neighborhood in such an inopportune location? We are less likely to ask these questions when we think that the only action we need take to address an illness like asthma is to design ever-better treatments for it. While we often do not think of health in this way, we are effectively letting six million children live with a preventable disease like asthma because we are distracted by the flashy potential of high-tech science, at the expense of solutions that are at hand. \n\nWhat about the continued existence of HIV, a disease for which we have excellent treatments, but which nevertheless persists in some countries due to the forces of poverty, stigma and political negligence? In such cases, our medical advances are simply not enough. We need the humility to recognize that we cannot end these diseases without tackling forces that exist outside the realm of scientific innovation, whose influence can only be checked by collective effort and the application of political will.     \n\nThere is nothing wrong with making better medicines. A cure for asthma or HIV would indeed be welcome. But would it not be better to live in a world where these diseases no longer exist? To get this world, we must have the humility to see that there is more to health than our capacity to cure disease and extend life. Health emerges from our shared context—from the air we breathe, the water we drink, our economy, politics, schools, workplace safety laws, corporate practices and other large-scale influences.\n\nI discuss these influences in my new book, Well: What We Need to Talk About When We Talk About Health. Engaging with them, to improve health, means first recognizing their scope, how they are bigger than any one person, and that they can only be properly addressed when we work together, with humility.\n\nTake another look at the black hole image. It is a ring of light against vast darkness. This sliver of light, framed by the dark of space, is a useful metaphor for the relative smallness of what we know compared to the tremendous scope of what we do not. Our health, like our universe, is shaped by forces that dwarf even our most brilliant advances and discoveries. It is only by having the humility to recognize this that we can begin to move, collectively, towards a healthier future.","title":"Humility Is the First Step toward a Healthier World","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/FA118E13-9551-4DA8-B0F44BC85E8AC486_source.jpg?w=590&h=800&05000FA2-0B63-4D16-829C5FFC5B804862","link":"https://blogs.scientificamerican.com/observations/humility-is-the-first-step-toward-a-healthier-world/"},{"authors":"Susana Martinez-Conde and Stephen L. Macknik","pub_date":"May 7, 2019","abstract":"The man and the woman sat down, facing each other in the dimly illuminated room. This was the first time the two young people had met, though they were about to become intensely familiar with each other—in an unusual sort of way. The researcher informed them that the purpose of the study was to understand “the perception of the face of another person.” The two participants were to gaze at each other’s eyes for 10 minutes straight, while maintaining a neutral facial expression, and pay attention to their partner’s face. After giving these instructions, the researcher stepped back and sat on one side of the room, away from the participants’ lines of sight. The two volunteers settled in their seats and locked eyes—feeling a little awkward at first, but suppressing uncomfortable smiles to comply with the scientist’s directions. Ten minutes had seemed like a long stretch to look deeply into the eyes of a stranger, but time started to lose its meaning after a while. Sometimes, the young couple felt as if they were looking at things from outside their own bodies. Other times, it seemed as if each moment contained a lifetime. Throughout their close encounter, each member of the duo experienced their partner’s face as everchanging. Human features became animal traits, transmogrifying into grotesqueries. There were eyeless faces, and faces with too many eyes. The semblances of dead relatives materialized. Monstrosities abounded.\n\nThe bizarre perceptual phenomena that the pair witnessed were manifestations of the “strange face illusion,” first described by the psychologist Giovanni Caputo of the University of Urbino, Italy. Urbino’s original study, published in 2010, reported a new type of illusion, experienced by people looking at themselves in the mirror in low light conditions.\n\nAs we noted in an ensuing Scientific American Mind article,\n\n“Caputo asked 50 subjects to gaze at their reflected faces in a mirror for a 10-minute session. After less than a minute, most observers began to perceive the “strange-face illusion.” The participants’ descriptions included huge deformations of their own faces; seeing the faces of alive or deceased parents; archetypal faces such as an old woman, child or the portrait of an ancestor; animal faces such as a cat, pig or lion; and even fantastical and monstrous beings. All 50 participants reported feelings of “otherness” when confronted with a face that seemed suddenly unfamiliar. Some felt powerful emotions.”\n\nIn his subsequent research, Caputo observed that the strange face phenomenon was not limited to one’s face reflected in the mirror, but it extended to other people’s faces, in situations where pairs of experimental participants gazed at each other for sustained periods of time in a dimly lit room. \n\n\n\tExperimental setup. Credit: Drawing by Alberto Conti\n\n\n\n\nMost recently, in a study published last month in the Journal of Trauma and Dissociation, Caputo sought to test a large sample of participants, which comprised 90 healthy young adults. Notably, the participant population included 15 portrait artists, who were able to produce artistic depictions of their perceptual experiences at the end of the experiment. Four of such portraits are included below: a stranger with eyewear, a monkey-woman, an alien face, and a cartoonish human-rabbit face.  \n\n\n\tFour examples of strange-face illusions sketched by portrait artists: (a) Stranger with eyewear, (b) Monstrous monkey-woman, (c) Alien face, (d) Cartoon-like human-rabbit face. Credit: Giovanni Caputo\n\n\nThe mechanisms underlying the strange face illusion remain somewhat obscure. The perceptual vanishing of objects and scenes during prolonged gazing, known as Troxler fading, could be part of the explanation. When we stare at an unchanging face for a long time (our own face in the mirror, or the face of the person sitting in front of us), our visual neurons decrease their activity, making facial features fade and disappear (and then reappear when we blink or move our eyes). In the absence of such visual information, our brain is bound to “fill in” the gaps according to our neural wiring, expectations, and experiences—sometimes with fantastical results. \n\nFuture research may offer a more complete picture of why the strange face illusion arises. In the meantime, you may want to avoid candle-lit romantic dinners—or looking too long into the eyes of your beloved.","title":"Locking Eyes with a Monster","origin":"Illusion Chasers","image":"https://static.scientificamerican.com/blogs/cache/file/8920FEFD-183D-4CF9-84230C2D69E1B285_source.jpg?w=590&h=800&11360235-E9E8-4B5A-8FB3EE0168C8F33C","link":"https://blogs.scientificamerican.com/illusion-chasers/locking-eyes-with-a-monster/"},{"authors":"Evelyn Lamb","pub_date":"May 3, 2019","abstract":"Approximation is a recurring theme in mathematics. Sometimes it seems like all of mathematics is saying, “Well, I know how to solve the problem in this domain. Is there a way I can approximate other domains with this domain?” A lot of calculus boils down to approximating arbitrary functions with linear functions. (For our purposes, “linear” means “completely well-behaved.”) Fourier analysis, which forms the backbone of signal processing, is all about approximating complicated periodic functions with sums of simple sine waves. Scores of mathematicians spend their time thinking about what conditions allow us to approximate functions by simpler functions. A mathematical space called Swiss cheese is yet another example of the ubiquity of approximation.\n\nLike the deli counter staple, mathematical Swiss cheeses are full of holes. To make a Swiss cheese, we start with a closed disc or filled-in circle, the set of all points in the plane that are less than or equal to a given distance (the radius) from a central point. \n\n\n\t\n\t\tWhat a lovely, cheesy disc! Credit: Evelyn Lamb\n\t\n\n\nNow we punch it full of holes in a particular way. We want to remove open discs (filled-in discs, but without their boundaries), and we have some rules about the removed discs. If you look up definitions of Swiss cheeses in math, you will see a various definitions, but just like Emmentaler and Gruyére, they are just different particular varieties that all count as Swiss cheese. \n\nThis being theoretical math, we remove an infinite number of discs, but we require that the sum of the areas of the removed discs is less than the area of the original disc (often quite a bit less), that no two removed discs overlap, and that the resulting space has no interior. That is, if we zoom in on any part of the space, no matter how small, there are holes in it. It’s hard to imagine such a space (and impossible to draw it, which didn't stop me), but there are ways to make sure the definition works mathematically.\n\n\n\t\n\t\tAn approximation of a mathematical Swiss cheese. It's very difficult to draw a picture with interesting features at arbitrarily small scales. Credit: Evelyn Lamb\n\t\n\n\nSwiss mathematician Alice Roth, the first person to describe these spaces, was trying to understand the limits of approximations of continuous functions by rational functions in the complex plane. A rational function is the ratio of two polynomials. Polynomials might be familiar to you from algebra classes. They are some of the simplest and easiest to understand functions. They have expressions like z+5 or z3-9z+7. Rational functions have expressions like (z3-9z+7)/(z+5).\n\nIs it always possible to approximate continuous functions by rational functions, or are there some spaces where this fails? Roth and other mathematicians showed that there are continuous functions on Swiss cheeses that cannot be approximated by rational functions.\n\nI am both a mathematician and a lover of cheese, so when I first heard that there were mathematical objects called Swiss cheeses, I was intrigued. The related research paper titles were delightful. Abstract Swiss Cheese Space and the Classicalisation of Swiss Cheeses. Swiss cheeses, rational approximation and universal plane curves. On the volume of the intersection of two Wiener sausages. (That last paper describes Swiss cheese-related calculations on another punny mathematical space called a Wiener sausage. Mathematicians like food.) Everything about this was relevant to my interests. When I learned about the history of the name, it got even better.\n\nWhen she first described them, Alice Roth did not use the term Swiss cheese. As far as I can tell, she didn’t name them anything in particular. She used them as an important example in her doctoral thesis at the Swiss Federal Institute of Technology in Zürich, won an award for that thesis, and graduated with her Ph.D. She had a thirty-year career as a high school teacher, during which she did not publish any mathematical research. After retiring, she jumped back into research, still in the same field she had studied thirty years before, and continued doing important work in her late 60s and early 70s. (Take that, G. H. Hardy and your “math is a young man’s game” nonsense!) Sadly, she died of cancer at age 72, while she was still full of mathematical creativity and enthusiasm.\n\nDuring Roth’s teaching career, while she was absent from the research world, Swiss cheeses were rediscovered independently in the 1950s by Soviet-born Armenian mathematician Sergey Mergelyan, who constructed them for similar reasons, probing the limitations of approximation in various settings. At some point, because of all the holes, someone started referring to them as Mergelyan’s Swiss cheeses. When Roth returned to research, she saw her examples attributed to Mergelyan in publications and corrected the record. The name Swiss cheese turned out to be even more appropriate than the person who coined it could have realized.\n\nFor more on Alice Roth, her Swiss cheese, and her other contributions to approximation theory, check out “Alice in Switzerland: The Life and Mathematics of Alice Roth” by Ulrich Daepp, Paul Gauthier, Pamela Gorkin, and Gerald Schmieder.","title":"The Serendipity of Swiss Cheese","origin":"Roots of Unity","image":"https://static.scientificamerican.com/blogs/cache/file/427AD491-3876-431F-9CA35E53EC6F19A4_source.jpg?w=590&h=800&A8960A06-8DE4-4DC6-A7DAD9E0273D1D5B","link":"https://blogs.scientificamerican.com/roots-of-unity/the-serendipity-of-swiss-cheese/"},{"authors":"Get-Fit Guy Brock Armstrong","pub_date":"May 11, 2019","abstract":"I’ve been trying out various brain training regimens for a few years now. But lately, I’ve been really digging into a series of games that you play on your computer or mobile device for just a few minutes a day, every day, to boost your cognitive function. Or so it promises.\n\nLumos Labs conducted a randomized study of the Lumosity brain training system, and after ten weeks of training, the users improved their working memory, short term memory, processing speed, and overall cognitive function.\n\nCognitive Function and Fitness\n\nPersonally, aside from it being fun to feel like I’m taking a multivitamin for my brain by playing videos games every day, Lumosity (and other brain training systems available) have been showing some promising advantages in the field of exercise and sport.\n\nIn a recent paper published in the Frontiers in Psychology, scientists investigated the role of cognition and neuroscience in understanding, predicting, and potentially improving elite sports performance. Although that particular paper stated “we caution around investing too heavily in such methods at this point in time” I feel like it is a no-lose situation. Even if it doesn’t help me bust out a faster time in my next triathlon, I am still doing something better for my brain than staring at reruns of The Simpsons.\n\n\n\n»Continue reading “How Your Brain Keeps Your Body Fit” on QuickAndDirtyTips.com","title":"How Your Brain Keeps Your Body Fit","origin":"Wellness","image":"https://static.scientificamerican.com/sciam/cache/file/BF996B25-0903-465A-BAC35ADC7B8B96DF_source.jpg?w=590&h=800&7387BC65-2B70-4F35-8A0E1B51FB3314C3","link":"https://www.scientificamerican.com/article/how-your-brain-keeps-your-body-fit/"},{"authors":"Ralph Nader","pub_date":"May 9, 2019","abstract":"“Fundamental Canon No. 1” of the American Society of Engineers states that “Engineers shall hold paramount the safety, health, and welfare of the public.” Most engineering societies have this principle in their codes of ethics. This duty frames the decades of struggles by conscientious engineers—whether employees or consultants—who strive to balance professional ethics with occupational survival.\n\nCompared to the technologically stagnant dark days in the auto industry of cruel suppression of technical dissent over safety and toxic emissions, a censorship that carried over to the industry-controlled Society of Automotive Engineers, today’s engineers are working in an improved environment for taking their conscience to work. Yet much more remains to be done to safeguard the ability of engineers to speak truth to the powers-that-be.\n\nFor starters, the word whistle-blower—once popularly meant to describe a snitch or a disgruntled employee—now describes an ethical person willing to put his or her job on the line in order to expose corrupt, illegal, fraudulent and harmful activities. Indeed, in the aftermath of recent Boeing 737 MAX crashes, the media routinely and positively refers to disclosures by “Boeing whistle-blowers.” Congressional investigating committees and federal agencies have called for whistle-blowers to come forward and shed light on corporate misdeeds and governmental agency lapses.\n\nTo put it mildly, this was not always the case. In 1971, I convened the Conference on Professional Responsibility—a sober name for a group of whistle-blowers from corporations, government and unions. They were ragged as “malcontents” or “occupational-suiciders.” In fact, they were courageous, accurate, morally right, and willing to lose everything to expose wrongdoing.\n\nKeynoters at the whistle-blower conference were Senator William Proxmire, who protected government whistle-blowers on military defense issues, and Robert Townsend, author of the best-selling Up the Organization. Townsend drew from his business experience to explain the critical role whistle-blowing could play in giant corporations. Law Professor Arthur Miller reviewed the lack of legal protection and vulnerability of whistle-blowers and presented what the law should provide “in its institutions and principles.” (See Whistle Blowing: The Report of the Conference on Professional Responsibility, by Ralph Nader, Peter Petkas and Kate Blackwell, 1972).\n\nAfter this watershed conference, much began to change. Numerous health and safety statutes now protect government employees who report noncompliance with environmental, worker safety and labor standards. Starting in 1978, a Merit System Protection Board was established and later strengthened under President George Herbert Walker Bush to give federal employees some, but not enough, due process against retaliation. Several states followed with their own whistle-blower protections.\n\nIn 1977 an NGO called the Government Accountability Project (GAP) started offering pro bono representation to many government and corporate whistle-blowers. After the enactment of the 1986 False Claims Act, federal employees exposing fraud against the government were able to secure a sizable portion of any resultant verdict or settlement against those ripping off the taxpayers. This law alone has recovered over $60 billion from the fraudsters. Private law firms and the Justice Department are regularly involved in pursuing these claims.\n\nThe vast world of state and federal procurement/military contracts and infrastructure is known to be rife with “waste, fraud and abuse.” Engineers are most likely to see such violations first. Decades ago, foreshadowing the many challenges in engineering, the Society of Professional Engineers, in its code of ethics, instructed engineers on their obligation to report safety and fraud violations to the appropriate outside authorities, should they find no recourse inside their place of employment.\n\nWith $5 trillion of deferred maintenance for our public works, as measured by the American Society of Civil Engineers, the challenges to the assertion of engineering conscientiousness will be ever larger.\n\nWe need more public interest engineering advocacy groups and initiatives to open up new frontiers of excellence and service as well as to support engineers inside the corporate framework. It was a Caltech professor, Arie Jan Haagen-Smit, not GM engineers or chemists, who proved in the 1950s the connection between motor vehicles and the lethal photochemical smog over the cities and suburbs of California. This led to smog-control regulations and ethical and legal foundations for industrial air pollution controls.\n\nEngineer Ralf Hotchkiss, rendered a paraplegic before college, courageously revolutionized the functional and economical design of superior wheelchairs, including showing natives how to utilize local materials in poor countries. He also helped break the virtual wheelchair monopoly of a British multinational company in the process. We need more engineers who embody the three principles of any profession—independence, scholarly pursuits, and commitment to public service. Those are the vital ethical pillars to helping engineers withstand the great pressures to place commercial priorities over their engineering integrity and limit harm to the public. We see the push to relegate engineers to indentured status in industries such as the chemical, nuclear, weapons systems, mining, auto, aviation, railroad and medical devices industries, as well as the new unregulated areas of biotechnology, nanotechnology and artificial intelligence.\n\nThere has been progress in legal protections for whistle-blowers, more civil litigations and, importantly, higher public expectations and popular support for these unsung protectors. There is, however, much more work to do, especially in educating the engineering school curricula and encouraging the numerous engineering societies to take their codes of ethics seriously. But as Nassim Taleb, author of The Black Swan, has written, “Mental clarity is the child of courage, not the other way around.”\n\nIn 1966, in an address to a chapter of the American Society of Engineering Education (reprinted in the new book Ethics, Politics, and Whistleblowing in Engineering, by Nicholas Sakellariou and Rania Milleron [my niece], CRC Press), I said “the [engineering] profession must assert itself towards its most magnificent aspirations—for so much of our future is in your trust.”\n\nWell, isn’t that a great understatement today!?","title":"When Engineers Become Whistleblowers","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/75FD8177-0CC5-4829-BEBE66F3248FBBB7_source.jpg?w=590&h=800&C9D7CD35-1DEE-4719-9C05247151A6C23F","link":"https://blogs.scientificamerican.com/observations/when-engineers-become-whistleblowers/"},{"authors":"Kate Marvel","pub_date":"May 12, 2019","abstract":"Imagine spending your whole career working on a question to which you don’t want to know the answer. We know that greenhouse gas emissions can and do warm the planet, but we don’t know one very basic thing: how hot, exactly, is it going to get? The main reason for this, of course, is that human behavior is so hard to predict. How will the people of the late twenty-first century get their energy? Will they need as much as we do, or will they have reconciled themselves to fundamentally different lives?\n\nPerhaps that decision will have been made for them by war or societal collapse. None of this is knowable. But even if we could remove all the uncertainty associated with politics, economics, technology, and demography, we still wouldn’t be sure. There are many things we don’t understand about our rapidly-warming planet.\n\nTo some extent, we know why we don’t know. I have been sternly informed by communication experts that “global warming” is a better term for what’s happening than “climate change.” I have also been told the opposite. But the two are inseparable: they feed back upon each other. Rising temperatures change the planet, and these changes can speed up or, if we are very lucky, slow down the warming we’ve caused.\n\nWe are not very lucky. Most of these changes will make things worse. The polar ice that we are currently melting is a good example. Right now, it reflects sunlight back to space, cooling the planet like a sunshield on a car windscreen. When it goes, it will leave behind dark land or ocean to absorb rather than reflects the sun. A little bit of warming can become much more.\n\nTo study the effects of these changes, we use something artificial but useful: the concept of climate “sensitivity.” In our climate models, we abruptly double atmospheric carbon dioxide from its preindustrial value of 280 parts per million, let the model Earth evolve for a few hundred years, and then measure the increase in its temperature. In the first generation of climate models, this varied from about a degree and a half Celsius to about four and a half degrees. The best guess was about three degrees C. The next time we did this, having improved the models substantially, the best guess was three degrees C, and the range was between 1.5 and 4.5 degrees. Decades of new science and advances in computing power later, and nothing about these estimates or their uncertainty has substantially changed.\n\nWe don’t know everything, but we don’t know nothing. All climate models simulate a changing planet in response to a changing temperature. And, increasingly, we know why they disagree on that final warming. In the climate models that warm more, low, thick clouds appear to be changing in ways that reduce their sun-blocking power. In the models that warm less, these changes are smaller.\n\nSo scientists have devoted their time to measuring clouds, understanding them, and figuring out how to represent them in climate models. This work has paid off: the range of uncertainty is now changing. Unfortunately, it’s increased. Climate models that use more modern techniques to simulate clouds are now projecting more warming: five or six degrees Celsius in response to a doubling of carbon dioxide. To put those numbers in context, four and a half degrees is the difference between now and the last Ice Age.\n\nI find these high numbers hard to believe, but as a scientist it’s my job to find things hard to believe. My skepticism is rooted in clues from the planet’s past. At the height of the last Ice Age, temperatures were cooler and carbon dioxide levels lower. It’s hard to reconcile these measurements with extremely high climate sensitivities. But it’s almost impossible to reconcile them with extremely low ones.\n\nClues from the more recent past might seem to paint a more reassuring picture. We have, after all, emitted carbon dioxide, and the planet has warmed in response. Our Earth is about a degree Celsius warmer than it was before the Industrial Revolution. This is dangerous, but not yet catastrophic, and some have suggested it might be indicative of a planet relatively insensitive to carbon dioxide. But the past is not the future, and we have good reason to believe that there are no analogues for the future into which we are hurtling. Right now, heat is being mixed into the deep ocean, which is cold and vast but not infinite. It will warm up in time, over hundreds or thousands of years, and the changes it will trigger may be different than any we have ever observed. Clouds may dissipate, ice will melt, and the warming will get worse.\n\nThese uncertainties matter in the real world. If the climate is very sensitive to carbon dioxide- if the changes provoked by warming themselves create much more warming- then our time frame for action is reduced. If the climate is relatively insensitive, then perhaps we’ll have a little more breathing room. But we’ve ruled out a climate sensitivity of zero. Warming is real, it’s happening, and it’s likely to get worse. Uncertainty is no excuse for inaction. Even in the improbable event that climate sensitivity is very low, “business as usual” still warms the planet and leads to unpleasant consequences. In the event that climate sensitivity is high, “business as usual” means disaster.\n\nClimate models, like all models, are imperfect representations of the real world. They tell us something useful about the planet we’re changing, but not how much, exactly, we’ll change it. The only way to be sure is to actually double atmospheric carbon dioxide and wait until the planet approaches a new equilibrium, measuring the changes along the way. This is an uncontrolled experiment I hope we will never do. But I’m afraid we’re well on our way to finding out.","title":"Global Warming: How Hot, Exactly, Is it Going to Get?","origin":"Hot Planet","image":"https://static.scientificamerican.com/blogs/cache/file/80C4493E-6185-4B03-8BB3D50C6EFE5DB1_source.gif?w=590&h=800&F16593DB-37EB-46A1-ADBFDD2EC7B05A93","link":"https://blogs.scientificamerican.com/hot-planet/global-warming-how-hot-exactly-is-it-going-to-get/"},{"authors":"Nutrition Diva Monica Reinagel","pub_date":"May 9, 2019","abstract":"Perhaps you saw the headlines last week about a new analysis finding that people who consumed a lot of fiber are significantly less likely to die from heart disease, stroke, Type 2 diabetes, and colon cancer.\n\nHow could such a frumpy nutrient make such a big difference in our health? After all, fiber is, by definition, indigestible by humans. It provides no vitamins, minerals, or energy. And yet, fiber intake is consistently linked with lower disease risk.\n\nThere are a number of possible explanations.\n\nHow Fiber Keeps Us Healthier\n\nFirst, fiber has the charming habit of taking out the trash. Insoluble fiber acts as a sort of broom, sweeping waste material out of the large intestine and lowering the risk of colon cancer. Soluble fiber acts more like a sponge, sopping up cholesterol, thereby lowering the risk of heart disease.\n\n\n\n»Continue reading “Can Fiber Undo the Damage of a High Fat Meal?” on QuickAndDirtyTips.com","title":"Can Fiber Cancel Out Calories?","origin":"Wellness","image":"https://static.scientificamerican.com/sciam/cache/file/5C4EFA72-4A75-4CE0-B61140436ABFB52A_source.jpg?w=590&h=800&CF796776-D8D1-4DCD-8D7E0DE6F5A66445","link":"https://www.scientificamerican.com/article/can-fiber-cancel-out-calories/"},{"authors":"Colleen Chierici","pub_date":"May 9, 2019","abstract":"It’s been four years since I donated my kidney in a so-called “paired exchange,” allowing my friend Tinh to receive the kidney she needed.\n\nI met Tinh during nursing school in September of 2012. We quickly became friends, spending grueling hours in our university’s library, preparing ourselves for our future nursing careers.\n\nHer kidney disease developed from a strep throat infection she caught in 2006. Post-streptococcal glomerulonephritis is a rare condition that affects the kidneys because of the body’s immune response against the strep infection.\n\nI made my decision to donate my kidney to her shortly after the birth of my daughter in September of 2013. Tinh had received a kidney from her mother 2010, but the transplant failed, leading her to restart dialysis.\n\nI imagined the pain her mother and loved ones must have felt to watch her go through such an ordeal. I would want someone to step up for my daughter if I could not give her what she needed to survive. Once I made my decision, however, and passed all the medical, social and psychological screening at Northwestern Memorial Hospital, we got the news that I wasn’t an exact match.\n\nSo the transplant center gave me the option to do a paired exchange, meaning that Tinh would receive a kidney from someone else, and my kidney would go to another person who was a match for me.\n\nFor the laparoscopic transplant surgery in January 2015, I stayed in the hospital overnight and went home the next day. I was back at work three weeks after my kidney was removed. My health is the same as it was before, and my life continues on as normal. That’s how it can be for anyone on the transplant list, but that isn’t always the case.\n\nCurrent numbers show there are 113,000 men, women and children on the national transplant waiting list. In 2018, only 36,528 transplants were performed. These statistics make it clear thousands of people who will never receive the organ they desperately need. Twenty people die each day waiting for a transplant. Many wait knowing that death is a possible outcome.\n\nLuckily, Tinh received her kidney and she is flourishing: she went back to school, she travels and she has a successful career. But surgery is not the end of treatment for her or for any organ recipients. She needs lifelong follow-up and medication to survive. The medication is expensive and many cannot or do not know how to pay for the medications.\n\nSome insurers do not coverage for the anti-rejection medications essential to an organ recipient’s survival. If a patient does not take these medications as prescribed, the body’s immune system will destroy the new organ.\n\nChronic rejection is the leading cause of transplant failure. If a transplanted kidney fails, a patient has the option to go back on dialysis. If a heart, lung, or liver transplant fails, the patient will be put back on a waiting list for another transplant. Many will die before getting one.\n\nMedicare offers kidney recipients some respite, as anyone under the age of 65, with end-stage renal disease will receive coverage for dialysis and kidney transplantation. Depending on what part of Medicare they had while receiving a kidney transplant, some recipients will receive coverage for anti-rejection meds for the rest of their lives.\n\nOther recipients will receive coverage for 36 months after a successful transplantation. For those who don’t receive life-long coverage, anti-rejection medications can cost $10,000 to $14,000 per year.\n\nOther organ recipients such as liver, lung and heart transplant recipients do not receive the same financial offset as kidney recipients, because failure of these organs are not covered the same way under Medicare.\n\nSome individuals waiting for life-saving transplants are turned away due to inability to pay for anti-rejection medications post-transplant, and turn to crowdfunding sources such as GoFundMe.\n\nFor instance, social media recently joined in the cause for patient Hedda Elizabeth Martin, who was reportedly not considered a candidate for a heart transplant, because of concerns on how she would pay for anti-rejection medication.\n\nLast year, there was much press surrounding 11-year-old Sofia Sanchez, who had two wishes granted: dancing with the musical artist Drake, and receiving a heart transplant at Lurie Children’s Hospital. A happy ending to a transplant story is what everyone wants to hear. That is not always the case.\n\nAs a registered nurse, I can possibly understand why an organ would not be allocated to an individual who cannot afford anti-rejection medication; it would be perhaps seen as not the best use of a viable organ. Perhaps the rationale is that organs are scarce and they need to go to patients who have the best chance of survival. However, a patient’s chance of survival based on their economic ability to afford the medication is unconscionable. It is not only the wealthy who deserve organ transplants.  \n\nNo legal protections for organ recipients exist in the form of federal regulations that mandate insurers to provide lifelong coverage for anti-rejection medications.\n\nSome organizations have joined a coalition named Honor the Gift, which seeks to extend Medicare coverage of anti-rejection medication beyond 36 months for kidney transplant recipients, but this does not include recipients of other organ transplants.\n\nLast April, during Donate Life Month, I celebrated as part of the largest gathering of living donors in Chicago, breaking a Guinness World Record with 410 kidney and liver donors coming together to raise awareness.\n\nAwareness of organ donation is more important than ever: the United Network for Organ Sharing has decided to broaden the geographic regions where livers are shared to decrease wait times for livers nationally.\n\nBut this new system will increase organ transplant disparity, because patients in wealthier areas, who are more likely to receive an organ because they can afford the care associated with it, will have access to the organs that were previously being transplanted in poorer areas. The best way to combat the scarcity of organs and ensure everyone has a fair chance of receiving one is by increasing organ donation, live and deceased.\n\nI count myself lucky to have been able to help my friend with an organ donation she needed. She is fortunate to have excellent insurance and so is able to afford her anti-rejection medications.\n\nEvery person in need of an organ donation in this country deserves the right to a healthy future, regardless of economic circumstances. This month and all year, it is essential that healthcare advocates, insurers and healthcare providers all do the right thing for every patient.","title":"We Need to Make Organ Transplantation Easier","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/5F76BF1E-9042-4013-A5C2D17D334754B0_source.jpg?w=590&h=800&3B9BA15C-27C1-4288-8ECCD26EB1F6D35C","link":"https://blogs.scientificamerican.com/observations/we-need-to-make-organ-transplantation-easier/"},{"authors":"Amanda Baker","pub_date":"May 2, 2019","abstract":"How many words does it take to teach a meaningful lesson in critical thinking? 5000? 1000? 500? And how young could your audience be and still get something out of it? Ten? Eight? Three? Imagine you have been challenged to teach a three-year-old child something about metacognition in fewer than 300 words. It may sound impossible, but picture books do it every day.\n\nObviously, we aren’t asking toddlers to parse the Monty Hall problem or navigate the prisoner’s dilemma. But figuring out how to make decisions – and assessing the strength of both that process and the decisions themselves – provides the foundation for any bigger questions you might want to pose. And because toddlers are still figuring out this whole decision thing from scratch, they engage with this process without hesitation. Most people are familiar with the characteristic “why” stage, with curious young minds asking about everything from how toasters work to why people have hair. But spending time with a toddler makes it clear that children this age are probably also asked “why” more than any other humans on the planet. “Why didn’t you tell me you had to use the potty?” “Why do you think the lamp is going to bite you?” “Why did you stuff your napkin into a full glass of milk?” All of these fall within the realm of an average morning. And the answers are often delivered with a blank-faced sincerity unparalleled in adults: “I wasn’t done with my book,” “The lamp can see me,” or “It was wet.”\n\nParsing the logic of seemingly id-driven actions takes work on both sides – grown-ups trying to follow staggering non sequiturs and toddlers trying to articulate their logic with a limited vocabulary and foggy grasp of pronouns. One common arena for these kinds of conversations is the reading of picture books. Try as I might to explain the decision-making process, I can’t imagine I will ever approach the clarity and impact of Mo Willems’ Should I Share My Ice Cream? Spoiler alert for those have not followed this particular adventure, the elephant gets some ice cream and has to decide whether to share it with his best friend, Piggie. Elephant takes so long making the decision that his ice cream ultimately melts, and Piggie shows up just in time to console her friend by sharing an ice cream cone of her own. This synopsis contains neither the humor nor the melodrama of the original story. But my ~894 readings have taught me that young readers can not only follow the logic of deciding whether to share, but also be driven to such sympathy to need to hug the book on pages when the characters look sad.\n\nPart of the magic comes not just from the ultimate decisions, but the steps the characters take in making them. Each step is laid out and illustrated for the reader. The initial excitement, the realization that he has a chance to share, the question of whether he should share, the question of whether he wants to share, the discovery of an excuse to keep the ice cream to himself, and the logical breakdown of that excuse. On one page, the elephant gleefully determines that the chance that Piggie might not like the flavor absolves him of any reasonable obligation to share. He looks at the ice cream with almost manic anticipation. But flip the page, and you witness the honest admission that Piggie would, in fact, like that flavor. I can’t decide if it sounds simple or complicated, but there is power in the page turn. It even drives some critical analysis of my own behavior. Am I overthinking this story as a defense mechanism against the hundreds of times I will likely be asked to re-read it? Probably. Do I care? No.\n\nAnd limited text and few powerful illustrations can take on concepts more nuanced than sharing. On its surface, Galia Bernstein’s I Am a Cat follows a small house cat on the journey of convincing its larger peers – lions and tigers – that it too is a cat. In the process, the characters engage their assumptions, personal bias, in-group/out-group dynamics, combating misconceptions with logical arguments, and changing their minds when faced with convincing evidence. There is even a reasonable primer in taxonomic practices thrown in for good measure. Both kids and grown-ups can appreciate a small, stripey role model standing its ground when laughed at, and responding with calm, careful evidence rather than visceral frustration. Even when the argument is about tails, pointy ears, and claws, it is a welcome change to see evidence-based arguments result in changed minds and a collective kitty romp rather than finger pointing and assertions of us versus them.\n\nFor those who will spend the foreseeable future in the land of picture books, there is comfort in recognizing opportunities to challenge assumptions (Last Stop on Market Street) or giggle at terrible logic (the final lines of the classic Madeline). But there are also lessons for those tasked with conveying complex ideas to unexpected audiences. There is a source of hope. Not only can we start conversations about critical thinking before they can be fully considered conversations, but we can remember the power of a clear narrative in opening conversational doors that might otherwise be closed to us. If picture book authors can use their prodigious skills to engage toddlers in logic, trade-offs, and critical decision making with 500 words and an ice cream cone, the rest of us can take the time to get to know our audiences, find the right narrative, and open the door to conversations with a shared story.","title":"Learning about Critical Thinking from Kitty Claws and Ice Cream Cones","origin":"Budding Scientist","image":"https://static.scientificamerican.com/blogs/cache/file/1D1A6D8D-0696-439B-80FD014775607F57_source.jpg?w=590&h=800&D18AB65D-4EDF-4A8C-8E1649212E5B3347","link":"https://blogs.scientificamerican.com/budding-scientist/learning-about-critical-thinking-from-kitty-claws-and-ice-cream-cones/"},{"authors":"Meredith Bashaw, Stephanie Allard","pub_date":"May 10, 2019","abstract":"I yawn and stretch, then climb to the top of the moss pile to soak up some warmth. Next I’ll check out that spot by the water where I found those yummy bugs yesterday. It’s shaping up to be another good day.\n\nThe critter above is a Houston toad (Anaxyrus houstonensis), an endangered species of amphibian. He lives at the Houston Zoo and is part of a zoo-based breeding program called the Houston Toad Recovery Project.\n\nThere sometimes exists a public perception that zoo animals live in sterile cages and suffer unrelenting boredom or even fear. Historically, zoos were created primarily for entertainment purposes and simply prioritized keeping animals visible and habitats clean. While this does help visitors see animals and animals stay healthy, it isn’t sufficient for allowing animals to lead rich and fulfilling lives. Fortunately for both human and nonhuman animals, modern accredited zoos and aquariums like the Houston Zoo hold themselves to higher standards.\n\nAccredited zoos agree to undergo voluntary review by a panel of industry experts to ensure that everything from their financial security to their animal care is state of the art. These zoos and their accrediting organizations have become focused on animal well-being, recognizing that animals in their care need to thrive rather than just survive.\n\nThey also increasingly include conservation in their mission statements and contribute expertise, time and funding to supporting that effort. Accredited zoos have transformed their operations to benefit animals in their care and in the wild, while still providing the public a fun, awe-inspiring experience.\n\nHow do they achieve such lofty goals? Increasingly, they use science. Between 1993 and 2013, zoos and aquariums accredited by the Association of Zoos and Aquariums (AZA) published 5,175 peer-reviewed scientific manuscripts on a wide array of topics, including animal care and conservation.\n\nZoos and partner organizations conduct animal welfare research to evaluate how animals in their care see (or hear or smell) the world and what behaviors motivate them. Keepers then find innovative ways to enrich animals’ lives by creating opportunities for these skills and behaviors. For ectothermic animals like reptiles and amphibians, thermoregulation and foraging are highly-motivated behaviors, so creating opportunities for these behaviors improves well-being.\n\nThe Houston toad above, for instance, isn’t simply hand-fed a diet of bugs. Instead, the zoo simulates the same processes the toad would need to perfect in order to find food in the wild, placing bugs inside crevices and other hiding spots.\n\nFood puzzles use that concept to give carnivores mental and physical exercise, as well as the thrill of the hunt. Zoos recognize that while achieving a goal—like getting food—is valuable to animals, so is the process of using their skills to reach that goal. As a result, zoos increasingly design environments to empower animals to make meaningful choices about what to do, when, and with whom and to enable them to exert some control over their surroundings.\n\nWhile animals are already reaping the benefits of advances in research and zoo design, there’s still much we don’t know about how animals of different species perceive their environments and what they value. As research improves our understanding of animals’ perspectives, zoos will need to stay nimble and continually improve so that every animal in their care can thrive.\n\nZoos also conserve wildlife and wild places around the world. Zoos accredited by the AZA spent more than $200 million on field conservation initiatives in 2017, and zoos belonging to other regional accrediting organizations are also active in conservation. AZA zoos’ efforts benefitted 863 species in 128 countries, including the Houston toad.\n\nThe Houston Zoo first started breeding Houston toads to supplement the wild population in 1978. The zoo reestablished an “assurance population” in 2007; the captive colony maintained by the institution ensures that prolonged drought, wildfires, highways and development won’t result in these toads’ extinction. Today, the Houston Zoo partners with the U.S. Fish and Wildlife Service, the Texas Parks and Wildlife Department, Texas State University and the Fort Worth Zoo to breed Houston toads and restock local ponds; in 2017 alone, the Houston Zoo released 930,000 captive-bred eggs into the Houston toad’s native habitat.\n\nThese types of programs are critical to safeguarding species in the wild. Biodiversity is threatened around the globe, with amphibians in particularly acute crisis. It is imperative that zoos continue to strengthen their conservation efforts. Captive toads in the Houston Zoo’s breeding program won’t necessarily make their way back into the wild, but their kids will.","title":"Modern Zoos Aren’t Just for Entertainment","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/458BEFED-D86E-48F7-86D3DF5BF530BA9E_source.jpg?w=590&h=800&0C1E1DC7-610C-4AE7-97C6EA033BDA38D2","link":"https://blogs.scientificamerican.com/observations/modern-zoos-arent-just-for-entertainment/"},{"authors":"Steve Mirsky","pub_date":"May 13, 2019","abstract":"In the first chapter of the new book Upheaval: Turning Points for Nations in Crisis, author Jared Diamond describes a crisis of his own. He was 21 and had always excelled academically—until he entered a doctoral program in physiology at the University of Cambridge.\n\nDiamond was charged with measuring the movement of sodium and potassium ions across the electricity-generating membranes of eels. But he had never been good with his hands and was utterly unable to design and build the equipment he needed to perform that task.\n\nSo Diamond switched to a technically easier assignment, which required simply weighing a fish gallbladder to determine its fluid content, then measuring a voltage. But even this simple method to analyze sodium and water transport gave him fits, as no voltages appeared. He seriously considered quitting and finding another career, but decided to give it one more semester.\n\nTwo young faculty researchers helped Diamond solve his technical issues, and he started to get results. He went on to finish his PhD and reinvent himself as an ornithologist and historian. More than 50 years later he is an internationally recognized scientist and writer, having won the U.S. National Medal of Science, a MacArthur Foundation fellowship (commonly called the “genius grant”) and a Pulitzer Prize for his book Guns, Germs and Steel: The Fates of Human Societies. His youthful failure was in fact a springboard.\n\nI have not achieved Jared Diamond’s level of success, but I strongly relate to his story. As Digital Science is running a social media campaign about acknowledging and learning from failure (you can share your own failures with #failtales), I thought I’d tell my story.\n\nI too had a history of academic achievement. I finished an undergraduate degree in chemistry and was accepted at Cornell University for graduate school. The chairman of the chem department was Roald Hoffmann, who had recently won the Nobel Prize and who was my advisor during my first semester. I later chose an advisor with whom I planned to do research for a doctoral thesis.\n\nGraduate school was a shock to my system. For the first time in my life, I hit a wall in my ability to understand information I was expected to digest. I found it increasingly difficult to concentrate on my work and became depressed.\n\nSo I played hooky. And where was the perfect place to not work while looking like one was working? Why, the library. My own science was going nowhere, but I still loved science. So I started reading science magazines. Stephen Jay Gould was writing his monthly columns in Natural History, and I became fascinated with evolutionary theory. I could hardly wait for the next issue of the New Yorker that featured another installment of a five-part series by E.J. Kahn about staple foods—which 35 years later I still remember were corn, wheat, potatoes, soy and rice. And from Scientific American I read articles about everything.\n\n(A few years ago I saw the Kahn staple-food series described as one of the most tedious pieces of magazine journalism every published. I laughed, because for me they were as thrilling as reading Dumas: corn was The Count of Monte Cristo, wheat was The Three Musketeers.)\n\nOne day at the beginning of the second semester of my second year of grad school, I was browsing through an issue of Science when I saw an advertisement for a Mass Media Science and Engineering Fellowship from the American Association for the Advancement of Science. Graduate students in the sciences who received the fellowship would spend the summer at a newspaper, magazine, radio outlet or television outlet as science reporters. I remember reading the ad and thinking, “Weird.” But the next day I looked at the ad again and thought, “Wait. This is what you should be doing.” I applied for and got the fellowship, along with about another 15 grad students around the country.\n\nI announced that I would be leaving Cornell at the end of the semester to do the fellowship and then pursue a career in science journalism. I could take oral exams for a “terminal” Master’s Degree. I studied my butt off and fortunately closely reviewed some material that I was actually asked about during the three-hour ordeal. I got the degree, which I often think of as the “lovely parting gift” that unsuccessful contestants received on game shows. Hoffmann asked me to reconsider leaving the program, but I was sure I was doing the right thing, for me. I left a couple of days later for my fellowship site, WSVN-TV in Miami. After two winters in upstate New York, I would spend the summer of 1985 in south Florida. (I can’t recommend either.)\n\nI took to science journalism—it fulfilled my terms of gratification. The journalist David Epstein exactly captured my feelings in his new book Range: “I worked in labs during and after college and realized that I was not the type of person who wanted to spend my entire life learning one or two things new to the world, but rather the type who wanted constantly to learn things new to me and share them.” Bingo!\n\nWhile in Miami I saw another ad, this one in Broadcasting magazine, advertising an on-air position opening at a small radio station back in upstate New York. I had always loved radio—as a kid I listened to Jean Shepherd, Barry Farber and Big Wilson, names that may ring a bell to a certain demographic—and I parlayed my summer TV gig into a year as a radio morning man. I got a job offer at a 50,000-watt station in Albany, but turned it down to go home to New York City and try writing for print.\n\nI eventually applied for a job at Scientific American—which I did not get. But a few years later I started freelancing for SciAm and then was hired as a writer and editor. I have been writing a monthly column in the magazine for more than 23 years. (Gould did his at Natural History for 25 years, a mark I hope to equal.)\n\nThe radio experience came in handy when, in 2005, Scientific American decided to start podcasts and asked me to head up that effort. We have now produced more than 4,000 episodes of our short podcasts, primarily 60-Second Science, and almost 500 of the in-depth Science Talk.\n\nI kept in touch with Roald Hoffmann over the years. At one point I ran into him at an event in New York City where an acquaintance of mine attempted to introduce us. Roald stopped my friend and said, “Oh, I know Steve. He’s one of our most successful failures.”","title":"If At First You Don't Succeed","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/64434CF6-863F-4716-B814445485156197_source.jpg?w=590&h=800&FF2AC74D-512E-4EC4-A9E7DF7C284DA72A","link":"https://blogs.scientificamerican.com/observations/if-at-first-you-dont-succeed/"},{"authors":"Kelly Reidy","pub_date":"May 10, 2019","abstract":"Dragons are not new. Game of Thrones tells us that they date back to some arguably medieval time, which may or may not predate the adventures of Smaug, the dragon from The Hobbit. In the nonfiction world, Christian legend tells of St. George slaying a dragon, and that tale probably derives from pre-Christian stories. Dragons show up in Chinese mythology as well—and in Bhutan, the Druk, or thunder dragon, is emblazoned on the national flag. And in fact, anthropologists have found dragons in art spanning thousands of years and independently created by people from all over the world.\n\nThe ubiquity of dragons across time and space may be related to fears inherited from some of humans’ most adorable ancestors: vervet monkeys. In his book An Instinct for Dragons, David E. Jones cites a study showing that these primates have an innate fear of lions, snakes and eagles. That’s a recipe for a dragon if I’ve ever heard one! Thus, humans may be evolutionarily predisposed to fear these animals.\n\nBut this only leads to more questions: What about the fire-breathing capabilities of European dragons, or the rain-bringing skills of Asian dragons, or the people-eating habits of Maori dragons? And why do some dragons fly while others slither?\n\nThe appearance, behavior and general level of horror of dragons vary wildly across cultures. These differences can tell us something about the natural history of their creators; this is where both local fears and local fauna play a role.\n\nIn northern China, around 300 B.C., workers digging a canal came across a fossilized animal skeleton. Remember that the theory of evolution wasn’t a thing yet, so people assumed this was the skeleton of an existing creature rather than the extinct nonavian dinosaur that it probably was. It went on record as a dragon skeleton—more fuel for the long-existing fire of Chinese dragon mythology.\n\nDragons appear in Chinese art from at least as far back as 1100 B.C. These dragons are relatively tame-looking and typically serpentine, with multiple sets of legs and a vaguely lion-like head. They don’t have wings, but they can fly. Two ancient Chinese rulers declared themselves to be direct descendent of dragons, and so dragons in many Chinese cultures became symbols of power. Contrary to the gut feeling you might be having right now, these dragons are generally seen as wise and benevolent—heroic, even—bringing rain to dry crops and pretty much saving entire civilizations.\n\nIn Europe, on the other hand, dragons are usually the bad guys. European dragon myths feature dragons as vicious monsters whose raison d’être involves getting slain by saints who need hero credibility. St. George, known primarily as a dragon-slayer, is now the patron saint of England and even has his own holiday on April 23.\n\nAppearance-wise, these European dragons are a little wackier than their Asian cousins. They look more like snake/eagle/lion combinations straight out of your worst fever dreams. Usually they have legs and wings and a snake tongue, sometimes fur, sometimes scales, sometimes both. For good measure, they can also breathe fire—the fire-breathing animals in Hieronymus Bosch’s delightful Renaissance-era paintings of hell may have been an inspiration for this feature. The very real and very prehistoric-looking Nile crocodile might also have been an influence, as it regularly swam up to European shores from Egypt and traipsed around on land.\n\nFurther south, in New Zealand, the taniwha are dragon-like creatures from Maori mythology. In this case, take the basic snake/eagle/lion innate-fear combo and add something more local: the great white shark. In fact, the Maori word for great white shark is mangō-taniwha. But don’t worry too much, as these creatures can be benevolent protectors—sometimes. At other times, they can be totally horrifying people-eaters. As a cherry on top of that nightmare cake, note also that in some stories, taniwha have shape-shifting abilities.\n\nAfter thousands of years of international dragon mythology, you’d be forgiven for thinking that their moment has passed.\n\nBut dragons continue to spark our curiosity and captivate our imaginations; today, they make appearances in pop culture via The Lord of the Rings, Dungeons & Dragons (and by extension, Stranger Things), Game of Thrones and even in band names like Imagine Dragons and DragonForce.\n\nThese pop dragons are mostly European-style in appearance, but their roles are more complex than the traditional Western “set ‘em up, knock ‘em down” scheme. They run the gamut from the occasionally disagreeable allies in Game of Thrones to the well-spoken monster in The Hobbit.\n\nEither way, stay vigilant, dear reader, because if Game of Thrones has taught us anything, it’s that “the night is dark and full of terror.”","title":"Here Be Dragons","origin":"Observations","image":"https://static.scientificamerican.com/blogs/cache/file/40605986-E95F-4666-AA679D0D6D54725C_source.jpg?w=590&h=800&13F244E9-0C39-47D0-9EDA5DE9BA857B00","link":"https://blogs.scientificamerican.com/observations/here-be-dragons/"},{"authors":"Nola Taylor Redd","pub_date":"May 9, 2019","abstract":"The mysterious source of Earth’s water has intrigued generations of scientists. Learning how this liquid—the cornerstone of life as we know it—made its way to our planet has sweeping implications, for the possibility of alien biospheres not only elsewhere in the solar system but also on worlds orbiting other stars. But understanding how water arrived on Earth has proven surprisingly difficult.\n\nAfter the sun formed from a cloud of dust and gas, the remaining protoplanetary disk of material was probably rich in water’s raw ingredients, hydrogen and oxygen. But conventional wisdom holds that the newborn star’s radiance boiled away much of those volatile gases from the inner solar system, leaving mostly dry material from which to build Earth and the other rocky planets. The majority of Earth’s moisture must have arrived later, by some other means.\n\nFor decades, scientists considered icy comets of the outer solar system as the most likely suspects, until observations revealed that most comets’ compositions did not quite match that of Earth’s oceans. And so consensus shifted toward asteroids as the source of Earth’s seas, since these rocky bodies also contain nontrivial amounts of water and are conveniently located close by, where they could have easily rained down on the young Earth. Now, however, an investigation of comet 46P/Wirtanen suggests that the bulk of Earth’s water may have come from comets after all, even though asteroids likely still played an important role.\n\nUsing NASA’s Stratospheric Observatory for Infrared Astronomy (SOFIA), an airplane-mounted telescope that can fly above much of Earth’s atmosphere, a team of researchers measured the proportion of heavy water, or deuterium, to normal water in comet 46P. Whereas the hydrogen nucleus of regular water contains a solitary neutron, deuterium’s nucleus contains both a proton and neutron, making it twice as heavy—and, more importantly, making it evaporate more slowly than normal water. This means the deuterium-to-hydrogen ratio (D/H) of any given object would be expected to vary depending on the distance at which it formed and lingered around the young sun, allowing the ratio to serve as a fingerprint for tracing water’s origins. Find a comet or asteroid with a D/H ratio identical to Earthly seawater, and you have perhaps found a chunk of undelivered ocean; obtaining D/H ratios for multiple objects may yield patterns that reveal the migration of water around the early solar system. Out of a handful of comets whose D/H ratio have been studied, comet 46P is the third known to have a D/H ratio similar to Earth’s.\n\n“It’s fantastic that they’ve got another D/H ratio,” says cometary scientist Karen Meech, of the University of Hawaii’s Institute for Astronomy. Meech was not part of the new research. “It’s very important for trying to understand what’s going on.”\n\nD/H may trace water through the young planetary disk, but it turns out to be a tricky process. Some models suggest the abundance of deuterium grows linearly moving away from the sun; others suggest the abundance shrinks under those same circumstances. Several that seek to replicate the chaotic, turbulent mixing of material in the early solar system predict deuterium abundances varying wildly at different points for no discernible reason. And observations have shown indeed that comets—even those apparently born in close proximity to each other—can have dramatically different D/H ratios. “Until now, we had a dozen measurements that looked kind of random,” says team leader Dariusz Lis, an astrophysicist at the California Institute of Technology. But 46P revealed a surprising new relationship that makes at least some of the measurements appear a little less random. Along with 46P, the other two comets known to have D/H ratios similar to Earth’s oceans, comets 103P/Hartley and 45P/Honda-Mrkos-Pajdušáková, are “hyperactive” objects, meaning they spew off more water than would be predicted based on their surface area alone. “Now, for the first time, we see a correlation between the D/H ratio … and the active fraction,” Lis says.\n\nThe results may have implications for all comets. The excess activity in hyperactive comets comes from water brought up from their interior. If, as Lis and his co-authors suggest, water from hyperactive comets’ nuclei has a more Earth-like D/H fingerprint, this may mean Earth-like water could be hidden deep inside other, nonhyperactive comets as well, putting the spotlight back on comets as an early water source.\n\nSoon to be published in the journal Astronomy & Astrophysics, the result could not only bolster the case for comets as deliverers of Earth’s water, but also tweak the initial conditions that led to life’s origins. “If you knew comets were raining down on Earth during the early stages of formation, that would have profound implications for what material was available for the very beginning stages of life,” says Maria Womack, a comet researcher at the University of South Florida who was not part of the new study.\n\nHyperactive Comets\n\nWhen comets draw close to the sun, their icy surface warms, jumping from solid to gas through a process called sublimation. Hyperactive comets such as comet 46P, however, do something more, somehow spewing off large chunks of ice into their coma, the nebulous cloud that surrounds the cometary nucleus. The tumbling ice chunks remain solid, sublimating in the coma rather than on the surface and providing the “hyper” in hyperactivity.\n\nThose solid chunks could explain the near-Earthly D/H ratio in comets like 46P. Lis and his colleagues suggest that, even if a comet’s surface material is heated and altered by the sun, its inner nucleus could remain relatively pristine for eons. On the surface, solar heat and radiation could evaporate some of the regular water, changing the ratio of normal and heavy water. Deep inside, however, those ratios may remain unchanged from their initial fingerprint (one that could match Earth’s oceans) set billions of years ago during the solar system’s formation. Heat-induced pressures in the comet trigger the release of volatile gases such as carbon dioxide or carbon monoxide, which are buried deep down in the nucleus. As the heated volatiles rise, they may push material from the nucleus to the surface, where it is blasted off to sublimate in the coma, revealing a fingerprint strikingly similar to Earth’s. If that is the case, the researchers suggest that all comets may carry water in their nucleus with a D/H ratio more like our planet’s.\n\nMeech is not yet convinced. In 2005, NASA’s Deep Impact mission blasted a crater in comet Tempel 1. Meech, who was part of that mission, says it showed that fresh material was only a few centimeters beneath the surface rather than hidden deep inside the nucleus. Thus, material blown from the heart of a comet should be similar to what is sublimating from the near-surface. Other missions to comets seem to support that finding. “Based on what was seen with the Deep Impact, EPOXI and Rosetta missions, I, don’t see any reason why the stuff [a hyperactive comet is] ejecting would be any more or less primitive than any other comet,” she says.\n\nOthers, such as comet researcher David Jewitt at the University of California, Los Angeles, are more concerned with simply getting that water to Earth. In addition to D/H ratios, celestial mechanics make a solid argument for asteroids as a dominant source of Earth’s water. Asteroids from the asteroid belt can crash into Earth much more readily than even the closest comets in the outer solar system, and research has revealed that many asteroids contain water with Earth-like fingerprints locked up inside of minerals. And, given the relative ease with which asteroids can pummel the inner planets, it is straightforward to envision them bombarding Earth in necessary numbers to fill the oceans—something that cannot be readily said for comets. According to Jewitt, all of the water in Earth’s oceans would make a single ball about 600 kilometers across or about a billion one-kilometer sized comets roughly the size of 46P. (The average comet is less than 10 kilometers across.)\n\nThe idea that all comets carry Earth-like water in their nucleus remains “a very provocative idea,” says Sean Raymond, a researcher at the Laboratoire d’Astrophysique de Bordeaux in France who models early solar system evolution. “It’s definitely one worth testing.” More in-depth laboratory tests could help reveal whether a comet hiding Earth-like water could be giving off a different D/H ratio, Jewitt says, and that could provide insights into water in the early solar system. But alone, it’s not enough.\n\nRight now, with only three hyperactive comets and a handful of regular comets having measured D/H ratios, the connection between the two remains nebulous. Fundamentally, the most important way to test whether all comets harbor Earth-like water in their nuclei is to find and study many more. “We’ve got to go out and get more of these and see if that prediction holds true,” says Edwin Bergin, a researcher at the University of Michigan who hunts for water in the protoplanetary disks around other stars. Bergin was not part of the new research.\n\nImproving technology should continue to make it easier to measure the D/H ratio of more comets from the ground, while future missions could make even more detailed observations from space. “We need more measurements,” Lis says. “We have gathered a little more than a dozen measurements in the past 25 years. That’s not enough to make a statistical study.”","title":"Hyperactive Comets Hint at Origins of Earth’s Oceans","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/5FAB160C-5BC5-4932-B2FFBBCF17EC0912_source.jpg?w=590&h=800&46059617-9BD4-45A9-BCCFA66F9F48930B","link":"https://www.scientificamerican.com/article/hyperactive-comets-hint-at-origins-of-earths-oceans/"},{"authors":"Christopher Intagliata","pub_date":"May 8, 2019","abstract":"By dampening the energy of waves, coral reefs protect coastal cities from flooding damage and other economic losses. Christopher Intagliata reports.","title":"U.S. Coral Reefs Do $1.8 Billion of Work Per Year","origin":"Natural Disasters 60-Second ScienceSubscribe:Apple iTunesRSS","image":"https://static.scientificamerican.com/sciam/cache/file/C92D4CA4-EAF1-41B8-8081202A6FC06A48_source.jpg?w=590&h=800&393C1B23-444C-4660-907929A65CB17EFC","link":"https://www.scientificamerican.com/podcast/episode/u-s-coral-reefs-do-1-8-billion-of-work-per-year/"},{"authors":"Liza Mundy","pub_date":"Scientific American May 2019 Issue","abstract":"Sprightly yellow seems to be the hue of choice for corporate wellness chains designing a logo to attract health-minded women. There is the cleansing grapefruit of SoulCycle, the happy buttercup of Drybar. And last year vans started materializing at busy pedestrian spots in Manhattan and Los Angeles that sported the shade of sunflowers. These vans are mobile fertility clinics, inviting women to pop in and learn how to safeguard their reproductive germ line by freezing their eggs. “Own your future,” the ads on the side promise. “Your fertility, understood.”\n\nThe vehicles are emissaries of Kindbody, a boutique fertility practice that courts the same clientele that frequents spin classes and blow-dry bars. It is one of a small but growing number of outfits that offer fertility services, including retrieving a woman’s eggs, or oocytes, to be frozen for later use. Because eggs are one of the most important factors in female fertility, and both their quality and quantity declines with age, banking eggs promises to lengthen a woman’s window of fertility and postpone the decision of whether to have kids. As a rival service, Extend Fertility, puts it, “Women have more options today than ever before. And we’re giving you one more—the option to start your family when you’re ready.”\n\nThe appearance of boutique egg-freezing outfits is one of the most high-profile—but not the only—recent developments in assisted reproductive technology, which is the science (and commerce) of helping people have the babies they want. These stand-alone clinics exist thanks to a convergence of female financial empowerment, venture capital backing and real medical progress. And it is not just mobile clinics behind the push. Egg freezing is on the rise at gold-standard fertility clinics, such as the one at the University of Southern California. There, according to clinic director Richard Paulson, it accounts for almost 40 percent of egg-retrieval cycles—in which women inject themselves with hormones to stimulate their ovaries to release multiple eggs, and doctors then collect those eggs while the women are under anesthesia. (The other 60 percent of cycles at the clinic involve women undergoing infertility treatment who intend to use the eggs soon.)\n\nUltimately these providers are making the case that egg freezing has come far enough to justify the $10,000-plus bet women place by investing in the procedure and medications not covered by insurance (that price tag does not include the storage fees women must pay yearly to keep the eggs on ice). This confidence stems from significant breakthroughs in the science of fertility and conception made over the past decade, notably a process that allows doctors to flash-freeze eggs. Physicians have also come a long way in the science of in vitro fertilization (IVF)—the process that comes after egg freezing—which unites a thawed egg (or a fresh one) with a sperm for conception in a petri dish and then grows the resulting embryo to the point where it can be put back inside a woman’s uterus to implant.\n\nAll this amounts to a sea change in the science of making babies, one that suggests, in theory, that women are not bound by the traditional notion of the ticking biological clock. Yet in practice, the reality is more complicated. Women must consider other factors besides their eggs, such as their overall health and the health of the sperm they plan to use, in deciding when to get pregnant. And just how good of a bet these new technologies truly are remains to be determined: the vast majority of frozen eggs at clinics have yet to be thawed. The question remains: Will they all be viable? Can science really safeguard fertility for later?\n\nThe freezing boom\n\nIn some places, such as the San Francisco Bay Area, the rise in egg freezing is linked in part to nearby tech companies such as Facebook and Google, which now (and with some fanfare) cover the procedure for employees. In Silicon Valley, egg freezing has become part of the benefits package a prudent career woman may consider availing herself of, a kind of 401(k) for future family formation. The boom also stems from other converging trends. One is the millennial generation’s comfort with social media; boutique clinics have strong presences on Instagram and Twitter, as do a growing number of traditional clinics. Even online dating—which has sold the hope that much messiness of the human heart can be solved by downloading an app—has an impact. “Women have said to me, instead of looking at every date as ‘Is this someone I could marry?’ they can set that aside,” says Marcelle Cedars, director of the University of California, San Francisco’s Center for Reproductive Health.\n\nThe rise in freezing also bespeaks a public inured to paying a monthly fee for products. What egg freezing is—among other things—is one more paid-subscription service, like Netflix or Zipcar. Oocytes, once frozen, must be kept frozen until used. After a woman goes through the not easy or cheap process of having eggs retrieved, she will be powerfully motivated to continue paying the storage fee, which can be as much as $500 or $1,000 a year. Every batch of eggs in liquid nitrogen represents an income stream for years, for the clinic and its investors.\n\n\n\nVitrification devices such as the S-Cryolock (shown) help to freeze eggs and embryos almost instantly to prevent damage. Credit: Jamie Chung\n\n\n\nBut the freezing trend is also the outcome of science. Asked to reflect on stages of progress in the field, Paulson casts his mind back to when in vitro was in its infancy. The first IVF baby was Louise Brown, born in 1978, now a mother herself. The technology for the scheme was nonexistent to the point where doctors had to fashion their own utensils to retrieve eggs and incubate embryos; when the late gynecologist Patrick Steptoe and the late physiologist Robert Edwards were performing the experiments that would result in Brown’s birth, they kept embryos warm in a pouch created in the skin of a living rabbit.\n\nInto the 1980s IVF patients could expect, at best, a 10 to 15 percent delivery rate. “We were able to help a handful of people,” says Alan Penzias, an associate professor at Harvard Medical School and a doctor at Boston IVF. “But not the majority. Most people failed.”\n\nThe retrieval of eggs—the well-protected female germ line—has always been hard. The 1980s saw basic techniques developed and refined; at first, doctors had to perform laparoscopic surgery to extract a single egg the instant it was ovulated. They learned to administer hormones that could cause eggs to ovulate in greater quantity and at a more predictable time and to retrieve them vaginally, with a needle that pokes through to the ovaries. The 1990s were—unexpectedly—the decade of the man. Male-factor infertility—slow or misshapen sperm or low sperm count—is a common reason couples may be unable to conceive. For a long time the only “cure” for male-factor infertility was sperm donation. Then, in 1992, scientists in Belgium announced the first live birth after using ICSI—intracytoplasmic sperm injection—in which a single sperm is injected into the egg. ICSI was a disruptive technology that cured male-factor infertility, for couples who can afford it.\n\nFor more than half a century it has been almost ridiculously easy to freeze sperm, which are stripped-down DNA missiles. The first reported human birth from frozen sperm occurred back in 1953. Not so for the egg, which is among the largest cells in the body and difficult to freeze well. Eggs are mostly water, meaning ice crystals can form, with sharp edges that damage organelles and other delicate structures. For years freezing an egg entailed dehydrating it to the fullest extent possible, then introducing tiny amounts of cryoprotectant, a kind of antifreeze that aims to prevent crystals from forming. Everything was done very slowly. “It would be this painful process that would take about two to three hours,” says Amy Sparks, an embryologist at the University of Iowa, who remembers the agony of ratcheting down the temperature bit by bit. This technology enabled the first human birth from a frozen embryo in 1984; the first birth from a frozen oocyte was reported two years later, in 1986. But for eggs, freezing remained both difficult and damaging: the upshot often was like what happens when you thaw ice cream and refreeze it: icy granulation. “When it thaws, all of a sudden the water from those crystals has nowhere to go and causes damage to the cell,” Sparks says.\n\nThen, about 10 years ago, came the most important recent scientific breakthrough in assisted reproductive technology. Vitrification—from vitrum, Latin for “glass”—is the ability to freeze eggs (and embryos) breathtakingly fast. The procedure involves larger quantities of cryoprotectant than earlier methods and a direct plunge into liquid nitrogen, which triggers “ultrarapid cooling,” minimizes the formation of ice crystals and almost instantly transforms the egg into a glasslike state. “In the past 10 years the impact of vitrification ... has really transformed the field in ways that we could not have foreseen,” says Serena Chen, director of the clinic at Saint Barnabas Medical Center in New Jersey.\n\n\n\nInstead of growing embryos in incubators in the lab, the INVOcell device can be inserted into a patient's vagina to incubate them there. Credit: Jamie Chung\n\n\n\nVitrification is akin to pushing the “pause” button, Chen says; when the time comes, the laboratory pushes “play” and commences rapid thawing. The results are so show-stopping that in 2018, the ethics committee of the American Society for Reproductive Medicine (ASRM)—which up to that point had declined to recommend social use of the technology—issued a paper saying egg freezing “for women attempting to safeguard their reproductive potential for the future” could now be considered “ethically permissible.” In short: egg freezing has gone mainstream. Clinics disagree over whether frozen eggs are as viable as fresh, but most experts, including Paulson and Sparks, say they are very, very close. And there is no question that eggs frozen when a woman is 32 are better than fresh eggs retrieved from the same woman at 42.\n\nBut even great eggs, just like sex, do not always make a baby. Cedars explains to patients that they should not wait to use frozen eggs until their early 40s, because if they do not work, the old-fashioned method might not either. Yet here lies a quandary—if women cannot wait until their fresh eggs have declined, what is the point of freezing in the first place?\n\nIVF strides\n\nVitrification is not the only advance helping to buoy the promise of egg freezing. Other elements of IVF have seen major improvements, such as the new standard of growing an embryo for five days in the lab before transferring it back to a woman. A decade ago embryos were often transferred at the three-day stage, when they consisted of just eight cells. Human embryos now arrive in the uterus as “blastocysts,” with roughly 100 cells, which are more mature and robust and have a much greater chance of success. According to CDC data from 2016, for women younger than 35, nearly 50 percent of fresh embryos transferred at day five resulted in a live birth as compared with 34.4 percent of embryos transferred at day three. For women between 35 and 37, the percentages were 42.1 for day five versus 28.6 for day three.\n\nSuccess rates are also getting better because labs can now closely replicate the chemical environment of the fallopian tube, where embryos spend their first five or so days when pregnancy happens naturally. Labs have gotten much better at regulating the amounts and concentrations of nitrogen, oxygen and carbon dioxide. Current incubators also feature more solid-state technology that requires less opening and closing of doors so that embryos can rest undisturbed.\n\nThe ability to develop embryos to the blastocyst stage means embryologists can more easily recognize the best of the batch before deciding which to try to implant. These judgment calls are also improved by a process called preimplantation genetic selection. Back in the three-day-embryo era, if scientists wanted to gauge the genetic health of an embryo, they had to pry one cell from an eight-cell mass, a lab procedure so harrowing that Sparks still has “nightmares” about it. Now it is much easier to use lasers to grab a couple of cells from the part of the blastocyst that will create the placenta—the less vital section than the one that is destined for the fetus.\n\nAll in all, embryologists’ improved ability to freeze and test embryos amounts to “a huge change,” Penzias says. About 10 years ago, frozen embryos had a 10 percent lower success rate than fresh. “Now we’re talking about parity,” he says. The improved odds mean, in theory, that whether women are using embryos created from eggs retrieved the same month or from those frozen years before, clinics can transfer just one embryo at a time rather than the two or three that used to be the norm. For 14 years it has been the University of Iowa’s policy that if a woman is younger than 38, has no prior failed transfers at the clinic and has at least a single good-looking blastocyst (a five-day-old embryo), then one is “all they get,” Sparks says. These trends have reduced the prevalence of twins, and especially of triplets and higher-order multiples, which are much riskier pregnancies than carrying singletons, for both babies and moms. At the University of Iowa, the rate of twin birth used to be 40 percent in 2001; now it is under 5 percent. Industrywide, according to the CDC, the portion of transfers involving a single embryo has more than tripled, from 12 percent in 2007 to 40 percent in 2016. Equally important: the percentage of fresh single-embryo transfers resulting in a live birth increased from 21 percent in 2007 to 37 percent in 2016.\n\nThese innovations are just the beginning. A new invention allows a woman to incubate embryos inside a device inserted in her vagina rather than an incubator in the lab. And even more radical technologies are on the horizon: Mitochondrial replacement therapy, for instance, is a controversial procedure that can eliminate the risk of genetic mitochondrial disease by injecting the nucleus of a mother’s egg into an egg from a woman without the disease whose nucleus has been removed but whose mitochondria remain. The procedure is banned in the U.S., out of concerns about mixing the DNA of two women, but is being developed in England. The day is also coming, Paulson says, when it will be possible to use stem cell technology to manufacture sperm and eggs from normal body cells, such as skin cells. Although it sounds like science fiction, the procedure would involve no changes to a cell’s DNA, so that part, at least, is less worrisome than mitochondrial transfer. With this technology, women would no longer need to bank eggs. “At 45, you can still have an egg made out of your skin cells,” Paulson says. It sounds wild, but so did IVF 40 years ago. “It’s going to happen.”\n\nTicking clocks\n\nIt is a fact that a woman is born with all the oocytes she will have; over time her ovarian reserve diminishes, as does the quality of her eggs.\n\nTalking about this subject has always been fraught. Back in 2001, when the ASRM launched an ad campaign partly about age-related infertility, the National Organization for Women attacked it as coercive and antifeminist. Chen says this reaction does women a major disservice; older eggs are more likely to be chromosomally abnormal, with a higher risk for miscarriage and the grief that follows. She adds that egg freezing is often depicted as elective and narcissistic, “kind of like plastic surgery or getting a cute Mini Cooper.” But women face many pressures, particularly in their mid-30s, when each year of delayed childbearing means an increase in earning power. “It’s not about women just being selfish and trying to work on their careers,” Chen says. “The truth is, a lot of people just haven’t found the right partner.”\n\nStill, Chen shares concerns about the commercialization of a technology that originally aimed to help cancer patients preserve fertility during treatment. Jake Anderson-Bialis, co-founder of the consumer education Web site FertilityIQ, worries that women do not realize taking hormones and then undergoing retrieval is not a minor lunch-hour-type procedure. And there is still no guarantee the eggs will result in a live birth. The backlash could be huge if many of the women now freezing their eggs later attempt to use them, only to find out their investment failed. The dirty secret of the fertility industry, up to now, has been multiple births; going forward, Anderson-Bialis says, “if there’s going to be a black eye, it’s egg freezing.” By this, he means the danger that the eggs, once thawed, will not be viable—a potentially devastating outcome to women sold on the promise of egg freezing. Cedars agrees that some women are too bullish on what technology can accomplish. “We have to repeatedly say to patients, ‘There’s not a baby in the freezer,’” she says. “‘There is the potential for a baby.’”","title":"Pausing Fertility: What Will Happen When the Eggs Thaw?","origin":"Medical & Biotech","image":"https://static.scientificamerican.com/sciam/cache/file/6B5508D9-2E75-43D6-A5348FDC2E9834C6_source.jpg?w=590&h=800&CB34AD6B-2151-4288-834BC982BFD191E6","link":"https://www.scientificamerican.com/article/pausing-fertility-what-will-happen-when-the-eggs-thaw/"},{"authors":"Jonathan O'Callaghan","pub_date":"May 13, 2019","abstract":"This Wednesday SpaceX will launch its first batch of Starlink satellites—a “mega constellation” of thousands of spacecraft to provide high-speed Internet access to billions of people at any location on the planet. Starlink is only the first of many such projects; there are at least eight more mega constellations in the works from other companies. Although they promise to revolutionize global telecommunications, these efforts are not free of peril: as the number of satellites inexorably grows, so, too, does the risk of creating dangerous debris that could threaten the continued safe use of Earth orbit. “This is something we need to pay attention to,” says Glenn Peterson, a senior engineering specialist at the Aerospace Corporation, headquartered in El Segundo, Calif. “We have to be proactive.”\n\nToday Earth orbit is a busy place. Almost 2,000 active satellites whiz around our planet, along with nearly 3,000 dead satellites and 34,000 pieces of “space junk” larger than 10 centimeters in size. Whenever debris or a defunct spacecraft gets too close for comfort to an active satellite—typically when a collision risk rises to one part in several thousand—the satellite’s operator must perform a collision-avoidance maneuver. The International Space Station, for example, is moved when the chance of a collision isgreater than one in 10,000.\n\nThese close encounters already occur thousands of times each year, but the sheer vastness of mega constellations such as Starlink will change the game, resulting in an estimated 67,000 annual collision-avoidance maneuvers if all of them are launched. As Earth orbit becomes jam-packed with satellites, the risk increases. A worst-case scenario would be the Kessler syndrome, a positive feedback loop in which debris-generating collisions create more and more collisions, which in turn create more and more debris, rendering parts of Earth orbit essentially unusable.\n\nNine companies total—including SpaceX, Amazon, Telesat and LeoSat—have been licensed by the U.S. Federal Communications Commission to launch such constellations. SpaceX alone plans to launch nearly 12,000 satellites by the mid-2020s, which will operate either at an altitude about 500 kilometers in low-Earth orbit (LEO) or a higher altitude of roughly 1,200 kilometers in nongeostationary orbit (NGSO). It is the first company of the nine to launch any fully functional satellites of its constellation. OneWeb, the next front-runner, has plans for a 650-strong constellation in NGSO. Six of its test satellites were launched this past February, and its first proper launch of three dozen or so satellites are planned for later this year. Monthly launches of 30 to 36 satellites will follow, with the service coming online in 2021. Every other company has similar plans for incrementally launching hundreds to thousands of satellites of its own.\n\nRisk versus Reward\n\nThe benefits of mega constellations would be manifold. Blanketing the entire planet with high-bandwidth, low-latency, always-on Internet access means ships out at sea, high-flying planes and people in remote, undeveloped areas (even Antarctica!) will suddenly be connected as never before. “Connectivity is just not [currently] available to everybody,” says Mike Lindsay, a space mission designer at OneWeb. “Half the world lacks an affordable access point to broadband Internet.”\n\nQuestions remain, however, on how to safely operate so many satellites in orbit. If the satellites fail, they could easily add to the growing problem  of space junk. At altitudes of 500 kilometers, failed satellites will not be a huge problem: within several years, atmospheric drag will naturally pull them back toward Earth to burn up on reentry. Indeed, to combat space junk, SpaceX recently modified its license with the FCC to lower the planned altitudes of more than 1,500 of its satellites by half. But at an altitude of 1,200 kilometers, where satellites remain aloft for longer, the dilemma becomes clear: “It’ll be thousands of years at those altitudes,” says Hugh Lewis, a professor of engineering and physical sciences at the University of Southampton in England, who developed a model called DAMAGE to track and monitor space debris.\n\nThere are no binding rules currently in place for how long a satellite can safely linger in orbit. The United Nations recommends that satellites be deorbited no more than 25 years after the end of their missions, but these guidelines lack strict penalties for noncompliance. “They are voluntary guidelines,” says Brian Weeden, director of program planning at the Secure World Foundation. The longer a satellite is in orbit, the greater the odds of it colliding with another one are. And such collisions are not unprecedented—in 2009 the American Iridium 33 satellite slammed into the defunct Russian Kosmos 2251 satellite, producing thousands of new pieces of debris.\n\nSome companies are being proactive in how to approach this problem. OneWeb, for example, will attach a handle to each of its satellites, offering an easy way for future orbital scrappers to haul them back down for disposal. No company has yet proved such technology, but progress is being made by entities such as the Japan-based Astroscale. “It is expected that a very small percentage of satellites will fail in such a way that the satellite operator is unable to deorbit them,” says Harriet Brettle, a business analyst at Astroscale. But “Astroscale and other emerging companies are looking to provide a backup service that will remove such failed satellites and maintain a sustainable space environment.”\n\nOther companies licensed by the FCC, however, plan to solely use the onboard propulsion of each of their satellites to ensure a safe deorbit. In principle, doing so seems fine, but in practice, satellite failure rates are not negligible. Even a 99 percent reliability rate for mega constellations would still result in hundreds of dead satellites adrift in orbit. As these numbers stack up, the chance of catastrophe would only grow.\n\n“The real problem is that we don’t have a great track record of getting [satellites] back out of orbit,” says Stijn Lemmens, a space debris analyst at the European Space Agency. “Long-term environment simulations indicate that we would need to reduce the orbital lifetime of about 90 percent of all objects that are launched into orbit. And in reality, we see this is happening successfully for about 5 to 15 percent. So we’re way off the target goal.”\n\nNoisy Skies\n\nAnother issue is the radio-based communications of the satellites themselves. Each satellite constellation will be awarded a chunk of the electromagnetic spectrum in which to communicate, but picking out a satellite amids the noise of so many can be tricky. With thousands more satellites set to enter orbit, actually communicating with a single one among those flying  overhead could be difficult. “The radio frequency interference is a big thing that is overshadowed by the potential collision risk,” Weeden says.\n\nThese mega constellations could cause problems for astronomy, too. Already, astronomers using optical telescopes have to contend with satellites occasionally crossing their view. Such interference could increase by a factor of several times with the emergence of mega constellations, says Mark Hammergren, a planetary scientist at the Adler Planetarium in Chicago. And for radio astronomers, things could become even more vexing. “Any time a satellite would pass through the observing beam of a radio telescope, there’s a chance that its transmission might be received and interpreted as a celestial signal,” Hammergren says.\n\nWednesday’s Starlink launch will be rightly lauded as a means to bring the Internet to the masses, but the greater plan of more than doubling the number of active satellites in orbit unavoidably comes with huge complications and seemingly scant room for contingencies. Even if launches and operations unfold smoothly for every mega constellation operator, just one of them experiencing financial difficulties could make the risk of space junk suddenly skyrocket. “The worst case is: you launch all your satellites, you go bankrupt, and they all stay there,” Lemmens says. “Then you have thousands of new satellites without a plan of getting them out of there. And you would have a Kessler-type of syndrome.”","title":"SpaceX's Starlink Could Cause Cascades of Space Junk","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/B6F541A6-4D9A-465B-9D5052911235B36E_source.jpg?w=590&h=800&8181615B-3C69-48AF-A8A0B0A8A2EF8E5B","link":"https://www.scientificamerican.com/article/spacexs-starlink-could-cause-cascades-of-space-junk/"},{"authors":"Jean Chemnick, E&E News","pub_date":"May 10, 2019","abstract":"EPA Administrator Andrew Wheeler used an overseas gathering of environment ministers this week to hint that the United States might overhaul the way it uses climate data and modeling. Five days after his assertion was included in an official document from the Group of Seven meeting in Metz, France, it remains unclear if Wheeler revealed a potential policy to reexamine climate modeling.\n\nIt’s become common for the United States to have its own climate and energy paragraph in multilateral statements, and on Monday, Wheeler broke away from the six other nations on issues like the Paris Agreement, providing support for poor and climate-affected countries, and overseas investments in fossil fuels.\n\nThat much was normal. It’s happened ever since President Trump took office in January 2017.\n\nBut Wheeler added something new that’s raising concern among some environmentalists that the United States might be formally questioning climate science inside federal agencies.\n\n“The United States reaffirms its commitment to re-examine comprehensive modeling that best reflects the actual state of climate science in order to inform its policy-making decisions, including comparing actual monitored climate data against the modeled climate trajectories on an on-going basis,” says the U.S. portion of the communiqué.\n\nGreens who follow the G-7 process were dismayed.\n\nAlden Meyer, director of policy and strategy at the Union of Concerned Scientists, called the language “pretty troubling,” and Luca Bergamaschi of the Britain-based E3G called it “a major step back.”\n\nThey read Wheeler’s language as an attempt to undercut a report last year by the U.N. Intergovernmental Panel on Climate Change. The report drew on thousands of peer-reviewed studies to warn of the importance of holding postindustrial warming to no more than 1.5 degrees Celsius.\n\nWheeler has been critical of the IPCC’s conclusions and of the National Climate Assessment, a U.S. report that issued similar warnings last year. He’s not alone in the Trump administration. In December, U.S. delegates to the U.N. climate talks in Katowice, Poland, joined Russia and Saudi Arabia to block language to “welcome” the IPCC’s findings.\n\nIt’s unclear if Wheeler meant to slight the IPCC on Monday. In fact, he joined his counterparts from France, Canada, the United Kingdom, Italy, Germany and Japan in praising the international body’s work to “strengthen the science-policy interface on the environment including by providing reliable assessments of the state of knowledge in response to the requests of policy makers and build capacity to use science effectively in decision-making at all levels.”\n\nThe statement leaves little to “re-examine” from the IPCC’s work.\n\nSo, was he announcing an alternative climate modeling initiative, either at EPA or another federal agency?\n\n“Currently, there are no specific efforts underway at EPA,” said agency spokesman James Hewitt. He didn’t respond to follow-ups about future plans or initiatives at other agencies.\n\nMeyer and others suggested that Wheeler might be referring to plans within the White House to convene a task force within the National Security Council to undermine the scientific underpinnings of the National Climate Assessment. But that proposal—to be spearheaded by William Happer, a senior director on the National Security Council—has yet to be accepted by Trump. NSC didn’t respond to inquiries (Climatewire, Feb. 21).\n\nMyron Ebell, a senior fellow at the Competitive Enterprise Institute, said a White House meeting last week to brief the president on the Happer proposal “went well.” But he said the concept remains controversial among some senior officials.\n\n“The president is enthusiastic about setting up the Happer commission,” said Ebell, who oversaw the EPA transition team before Trump’s inauguration. But he noted that Wheeler would have been unlikely to reference a program that Trump has yet to bless at an international forum.\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"Trump Administration Might “Re-Examine” Climate Modeling","origin":"Policy & Ethics","image":"https://static.scientificamerican.com/sciam/cache/file/9B94D236-E595-4388-B447F424BD452366_source.jpg?w=590&h=800&C4DF7DF0-B393-40EE-8EF6903C3A248653","link":"https://www.scientificamerican.com/article/trump-administration-might-re-examine-climate-modeling/"},{"authors":"Caleb A. Scharf","pub_date":"April 25, 2019","abstract":"As scientific fields go, both physics and cosmology arguably get to have the most fun. I don’t mean in terms of day-to-day humdrum research, but in terms of speculation at the frontiers of knowledge.\n\nConsider for example the pleasures of the multiverse. The harder astronomers work to pin down the fundamental parameterizations of the cosmos, from its matter contents to its ordinary energy and dark energy, the more it looks like a reality borne from the physics of inflation. This is a phenomenon that produces exponential expansion of space, resulting in the noise of quantum fluctuations on teeny tiny scales ending up as the seeds of structure on cosmic scales – like galaxies and stars. It also propels a universe towards a spatially flat geometry. And inflation, as we currently think of it, seems to almost inevitably lead to many, many, many universes. \n\nThat’s fun (in the loosest definition of that term) because with enough physical realities maybe there really are repeats of everything that we know – right down to you, your dog, what you had for breakfast, and the text of this article that you’re reading right now.\n\nThen there are more philosophically motivated arguments that perhaps our universe is the result of experimentation or deliberate simulation. Maybe it was born in a super-powerful particle accelerator out of something like an inflating, energetic monopole, or in a hugely advanced quantum computer capable of modeling an entire cosmos of atoms and photons. In either case the line between real and unreal is irrevocably blurred. For example, to simulate a universe that exhibits the mind-boggling complexity that we experience – or think that we experience – requires the construction of a model that is pretty much as mind-bogglingly complex and physical as if it actually existed as a mind-bogglingly complex and physical reality.\n\nThere are even arguments for why it is actually quite likely for us to be ‘inside’ such a simulation (where ‘quite likely’ is philosopher-speak for ‘who knows, but it’s good for the lecture circuit’). Specifically, even if only a very few species (assuming an external physical reality like the one we experience) are sophisticated enough to construct a universe simulation, they might end up running huge numbers of such simulations. Perhaps to explore the lives of their ancestors, or perhaps to show off to the neighbors. \n\nIn all cases, the consequence of there being vast numbers of simulated realities would be that it is far more likely that you are simulated than real – it’s just a numbers game. Indeed, since we are not yet technologically sophisticated enough to build such models the odds may be even greater that we are in fact a simulated ancestor species. \n\nBut whether this is a simulation, or a bona-fide physical reality produced by someone’s laboratory tinkering, an important question is raised.\n\nThat is: why aren’t things a bit better?\n\nI mean, come on. A universe with an accelerating cosmic expansion – as we seem to have - is astonishingly inconvenient. In a few hundred billion years it will become extremely difficult, if not impossible, for a sentient species to make any kind of meaningful sense out of the cosmos – as distant matter becomes effectively unseeable due to the expansion of spacetime. There are other issues too. Already the rate of star formation has dropped to a mediocre level, ensuring a future consisting mostly of dismal little red dwarfs and few new planets. And what about the peculiarities of physics – from quantum mechanics to thermodynamics and all of this ‘emergent phenomena' stuff? Honestly, it does seem a bit patched together.\n\nWhich brings me to a disquieting conclusion and new twist to the idea that we might exist within a manufactured universe. Even for some hyper-advanced intelligent species, building or simulating universes would have to be quite costly in terms of resources. Therefore, it’s not unreasonable to expect that some corners have to be cut, some expenses kept under control. \n\nI’m reminded of the legend of the dry comment often attributed to the astronaut Alan Shepard when asked how he felt sitting atop an enormous rocket about to blast off to space. His response was (with some likely paraphrasing added over the years) “I just kept looking around at all those dozens of instruments in front of me and reminding myself that every one was supplied by the lowest bidder.” \n\nPerhaps this is indeed the ultimate answer to why our universe is a little squirrely. While it is remarkable how well much of it can be understood – albeit with centuries of effort on our part – in other respects it is also highly resistant to being easily decoded. Built by the lowest bidder it would suffer from some corner-cutting, some inconsistencies and illogical quirks. \n\nAnd that leads to the ultimate question, the one that we all seek the answer to. \n\nHow do I get in touch with customer service?","title":"The Lowest Bid Universe","origin":"Life, Unbounded","image":"https://static.scientificamerican.com/blogs/cache/file/AEBD30B0-065B-4003-9107B8672FDED09C_source.jpg?w=590&h=800&F547C62E-DB43-43FA-97F9D4286B14D052","link":"https://blogs.scientificamerican.com/life-unbounded/the-lowest-bid-universe/"},{"authors":"Jennifer Frazer","pub_date":"May 2, 2019","abstract":"The fire chaser beetle, as its name implies, spends its life trying to find a forest fire.\n\nWhy a creature would choose to enter a situation from which all other forest creatures are enthusiastically attempting to exit is a compelling question of natural history. But it turns out the beetle has a very good reason. Freshly burnt trees are fire chaser beetle baby food. Their only baby food.\n\nFire chaser beetles are thus so hell bent on that objective that they have been known to bite firefighters, mistaking them, perhaps, for unusually squishy and unpleasant-smelling trees.\n\nThey have descended on at least one UC Berkeley football game at California Memorial Stadium -- rather unfortunately situated in the midst of some recently burnt pine hills -- at which an estimated 20,000 cigarettes were being smoked. The beetles’ disappointment on discovering the source of the “fire” was probably only matched by the irritation of the smokers swatting confused beetles attempting to bite their necks and hands.\n\nThey have shown up on hot pipes and other equipment at lumber yards and sugar mills, tar plants, cement kilns, smelters, and on one occasion, a colossal 1925 oil tank explosion in Coalinga, California. In that last case, the flames reached hundreds of feet into the air and were visible for over 30 miles … but the nearest plausible beetle-bearing forest was 80 miles away.\n\nThat last detail implies something amazing about fire chaser beetles: they can sense fires from distances over which car stereos are hard pressed to pick up FM radio.\n\nIn fact, because the infrared emission of a burning oil tank of known volume (in this case, 750,000 barrels) can be calculated with reasonable certainty, scientists that studied the Coalinga oil tank explosion have inferred the beetles can detect infrared radiation intensities so low that they are buried in the thermal noise around them. But … how?\n\nInfrared radiation, a proxy for heat, is a reliable source of information about fire because it propagates outward in a clear gradient, dampened only by humidity. It gives a very accurate indication of distance and direction from the source. A highly sensitive infrared sensor can detect a surface fire from space.\n\nA flying fire chaser beetle appears to be trying to give itself up to the authorities. Its second set of legs reach for the sky at what appears to be an awkward and uncomfortable angle.\n\n\n\tFire chaser beetle flying posture (top), heat eye (middle), and cross section of an individual sensillum in the array (bottom). Credit: Schmitz and Bleckmann 1998\n\n\nBut the beetle has a good reason. It’s getting its legs out of the way of its heat eyes, pits filled with infrared sensors tucked just behind its legs.\n\nThe heat eyes on the sides of fire chaser beetles are filled with about 70 infrared sensilla. Inside each sensillum is a hair-like sensor (called a dendritic tip in the diagram above) that physically deforms when the sensillum expands in response to heat, triggering a neural response.\n\nSuch arthropod hair sensors are incredibly sensitive. Spiders possess versions called trichobothria that detect air movement – such as that caused by movement of web or prey – with such sensitivity that they are tripped by levels not much higher than the random movement of air molecules (Brownian motion), or, as the authors of recent paper on the oil-tank-fire-beetle-sensitivity-question put it, “at the limit of the physically possible”.\n\nIn addition to containing similar hypersensitive mechanoreceptors, the sensilla in fire chaser beetle heat eyes are found in arrays of 70-90. A signal picked up by more than one of them can be summed up and amplified by the neurons that wire the array. As a result, the heat eye can detect softer signals than a single sensor could.\n\nFinally, it is also possible the beetles are better able to detect a signal buried in noise due to a spooky (to me) phenomenon called “stochastic resonance”. In this scenario, added thermal noise counterintuitively helps a sensor pick up a signal.\n\nA signal below the threshold for triggering a sensor – but still close to it – will resonate by chance with a portion of thermal noise that is the same frequency. When there is more noise, there is more signal at that resonant frequency. Together, noise plus signal adds up to an impulse sufficient enough to trip the sensor when signal alone or signal with less noise would not. Incredibly, the measurement gets more precise in the presence of noise than without.\n\nThough deeply counterintuitive, stochastic resonance has been demonstrated over and over in biological systems, including several times in humans. For example, humans can detect a touch stimulus that would normally be undetectable when they are exposed to a mechanical vibration at the same time. The portion of the vibration that “resonates” with the touch sums to trigger mechanoreceptors in skin. Crazy but true.\n\nThus, though the fire chaser beetle’s ability to detect fire may seem supernatural, it may operate on physical principles that are also at our very own fingertips.\n\nReferences\n\nSchmitz, H., and H. Bleckmann. \"The photomechanic infrared receptor for the detection of forest fires in the beetle Melanophila acuminata (Coleoptera: Buprestidae).\" Journal of Comparative Physiology A 182, no. 5 (1998): 647-657.\n\nSchmitz, H., and H. Bousack. \"Modelling a historic oil-tank fire allows an estimation of the sensitivity of the infrared receptors in pyrophilous Melanophila beetles.\" PLoS One 7, no. 5 (2012): e37627.","title":"How a Half-Inch Beetle Finds Fires 80 Miles Away","origin":"The Artful Amoeba","image":"https://static.scientificamerican.com/blogs/cache/file/1EE77E5A-293D-428E-AE545E111D202764_source.jpg?w=590&h=800&CE1F9762-3583-4233-A82C7BD12B2E176C","link":"https://blogs.scientificamerican.com/artful-amoeba/how-a-half-inch-beetle-finds-fires-80-miles-away/"},{"authors":"Karen Weintraub","pub_date":"May 9, 2019","abstract":"As of this month, there have been more than 750 cases of measles in the U.S. this year across 23 states—the most since 1994, according to the Centers for Disease Control and Prevention. Measles was considered “eliminated” in the U.S. in 2000, although there have been small, sporadic outbreaks since then. A new study looks at how countries have pulled themselves out of past outbreaks of the disease—strategies that may need to be adapted in light of current vaccine hesitancy.\n\nAccording to the study, published Thursday in Science, a country’s control of measles passes along a continuum with three different categories: a large number of cases every year, fewer cases overall but lots of year-to-year variability, and finally, consistently few or no cases. Knowing where a country lies in this continuum–referred to as a “canonical path”—could help it plan its response to the next outbreak, says senior author Justin Lessler, an epidemiologist and associate professor at the Johns Hopkins Bloomberg School of Public Health.\n\n“This was really driven by the laws that govern measles transmission and measles epidemic dynamics,” Lessler says. In the past, “as you had increases in vaccination rates and decreases in birth rates it would really drive countries along this expected path.”\n\n\n\nHow different countries have progressed along the consistent and predictable path for measles outbreaks, 1990-2017. Credit: Matthew Graham, Amy K. Winter, Matthew Ferrari, Bryan Grenfell, William J. Moss, Andrew S. Azman, C. Jessica E. Metcalf, Justin Lessler\n\n\n\nLessler and his colleagues conducted a statistical analysis of measles outbreaks in countries worldwide between 1980 and 2017. By looking at weighted averages of measles cases and year-to-year variability, the researchers placed countries and regions at different points on the continuum. For example, Africa in 2008 was at almost exactly the same stage the Americas were in 1995, according to the research.\n\nThe study should also help a country direct its vaccination efforts, rather than fighting an outbreak based on the patterns of previous ones, Lessler says. If a prior outbreak was particularly severe among small children, many countries will be inclined to focus vaccination efforts on this age bracket, he says. But that is probably not the right approach. If childhood vaccination rates are high and birth rates low, the new analysis suggests that older children and teens may now be the most vulnerable, he says. “The path [the outbreak takes is] dictated by the size of the population you have that’s susceptible to measles,” Lessler says. “You could use the position along the path to understand the age distribution of susceptibility, which could help target vaccination efforts.”\n\nShweta Bansal, an associate professor of biology at Georgetown University in Washington, D.C., says the study allows countries to use a minimal amount of data to identify where they might be on that path. “As a public health communication tool, I think it’s quite powerful,” says Bansal, who was not involved in the research.\n\nBut as the current U.S. outbreaks demonstrate, even countries that had been almost completely measles-free for years are suddenly vulnerable again because people are declining to get vaccinated.\n\nJohn Brownstein, an epidemiologist at Harvard Medical School who was not involved in the new study, says social media has changed the dynamics around measles and other vaccine-preventable diseases—and it is unclear what the repercussions will be. Brownstein says that when he was featured in a recent Facebook video encouraging measles vaccination, the post was flooded with comments opposing vaccines and spreading inaccurate information about both the disease and the vaccine. “It was pretty unbelievable,” says Brownstein, who is also Chief Innovation Officer at Boston Children’s Hospital. “I started trying to comment back to clarify, and the wave [of responses] just was too big for me to be able to handle.”\n\nIt is not clear, Brownstein says, whether historic trends of controlling diseases with vaccines can continue when so many people are passionately opposed to them. Vaccine hesitancy is not new or U.S. specific, he says: “Every location on earth has vaccine confidence issues.” But the internet makes it easier for people who oppose vaccines to find each other and share their opinions.\n\n“There’s a combination of mistrust around government and pharmaceutical companies that is probably different” than with other public concerns, Brownstein says. “There’s also a component of the invasiveness of the needle that’s also at play in our psychology.”\n\nBefore vaccination, measles infected more than 95 percent of all children and was responsible for more than four million deaths worldwide each year. After the introduction of the measles vaccine in the 1960s, childhood deaths from not just measles but a wide range of infectious diseases dropped substantially. Measles seems to erase immune protections that the child has from other infectious diseases. According to a 2015 study in Science that examined historical data, measles outbreaks predict deaths from other childhood diseases two to three years later, suggesting that a measles infection made these children more vulnerable to diseases such as pneumonia and diarrhea.\n\nMany people see measles infections as benign, particularly in young children, but teens and young adults suffer terribly, says Jeffrey Griffiths, a professor in the Department of Public Health and Community Medicine at Tufts University School of Medicine. “It’s a vicious, bad disease and it’s not like getting a cold,” he says. Malnourished children and those with vitamin A deficiencies are particularly vulnerable, with a death rate as high as 50 percent in parts of Africa, Griffiths adds.\n\nThe World Health Organization had hoped to eliminate measles worldwide by 2020. Lessler says that date is not realistic, but he and Bansal say they still believe it will someday be possible to eradicate measles. “Doing this kind of work requires strong optimism,” Bansal says. She adds that measles “represents an ideal case for eradication” because the pathogen is well understood, an effective vaccine exists—the recommended two doses seem to provide long-lasting immunity—and past U.S. experience shows it is possible to limit transmission of the disease for an extended period. “We have a much better chance of [eradicating measles] than other infections, but the challenge of vaccine hesitancy is certainly giving us all cause for concern,” she says.","title":"Measles Outbreaks Follow a Predictable Path—Provided People Get Vaccinated","origin":"Public Health","image":"https://static.scientificamerican.com/sciam/cache/file/4680AE5B-6551-4B75-905E462D9349172B_source.jpg?w=590&h=800&6265D5D4-AFB0-4214-985C31634FEAF4F9","link":"https://www.scientificamerican.com/article/measles-outbreaks-follow-a-predictable-path-provided-people-get-vaccinated/"},{"authors":"THE EDITORS","pub_date":"September 1, 2017","abstract":"Editor’s Note (5/8/19): This article is being republished because Georgia’s governor signed a bill into law Tuesday that bans abortions as soon as a fetal heartbeat can be detected, as early as six weeks into a pregnancy.\n\nThere's something rotten in the state of women's health. As this article is being written in July, Republicans in Congress are engaged in a frenzied effort to repeal and replace the Affordable Care Act (ACA) put in place by the Obama administration. At least 22 million Americans would lose medical insurance by 2026 under the latest version of this plan—which includes large cuts to Medicaid—and lack of insurance means more sickness and death for thousands, data show. These cuts threaten to affect women more than men—whether by removing basic health coverage, cutting maternity care or sharply limiting reproductive rights.\n\nIt's time to take a stand against this war on women's health.\n\nCurrent events are just the latest insult in a long history of male-centric medicine, often driven not by politicians but by scientists and physicians. Before the National Institutes of Health Revitalization Act of 1993, which required the inclusion of women and minorities in final-stage medication and therapy trials, women were actively excluded from such tests because scientists worried that female hormonal cycles would interfere with the results. The omission meant women did not know how drugs would affect them. They respond differently to illness and medication than men do, and even today those differences are inadequately understood. Women report more intense pain than men in almost every category of disease, and we do not know why. Heart disease is the number-one killer of women in the U. S., yet only a third of clinical trial subjects in cardiovascular research are female—and fewer than a third of trials that include women report results by sex.\n\nThe Republican assault on health care will just make things worse. The proposed legislation includes provisions that would let states eliminate services known as “essential health benefits,” which include maternity care. Before the ACA made coverage mandatory, eight out of 10 insurance plans for individuals and small businesses did not cover such care. The proposed cuts would have little effect on reducing insurance premiums, and the cost would be shifted to women and their families—who would have to take out private insurance or go on Medicaid (which the proposed bill greatly limits)—or to hospitals, which are required by law to provide maternity care to uninsured mothers.\n\nThe bill, in its current form, would also effectively block funding for Planned Parenthood, which provides reproductive health services to 2.4 million women and men. The clinics are already banned from using federal funding for abortions except in cases of rape or incest or when the mother's life is in danger, in accordance with the federal Hyde Amendment. So the Planned Parenthood cuts would primarily affect routine health services such as gynecological exams, cancer screenings, STD testing and contraception—and these clinics are sometimes the only source for such care. Regardless of which side you are on in the pro-life/pro-choice debate, these attempts to remove access to such basic services should alarm us all.\n\nThe Trump administration also has been chipping away at the ACA's birth-control mandate. A proposed regulation leaked in May suggested the White House was working to create an exemption to allow almost any employer to opt out of covering contraception on religious or moral grounds. Nationwide, women are increasingly turning to highly effective long-acting reversible contraceptives (LARCs) such as intrauterine devices (IUDs). The percentage of women aged 15 to 44 using LARCs increased nearly fivefold from 2002 to 2013. Decreased coverage for contraceptives translates to less widespread use and will likely mean more unintended pregnancies and abortions.\n\nAnd abortions will become harder to obtain. After Roe v. Wade, many states tried to put in place laws to hamstring abortion clinics. These efforts have only ramped up in recent years, as many states have enacted so-called TRAP laws (short for targeted regulation of abortion providers), unnecessarily burdensome regulations that make it very difficult for these clinics to operate. Recognizing this fact, the Supreme Court struck down some of these laws in Texas in 2016, but many are still in place in other states. Rather than making women safer, as proponents claim, these restrictions interfere with their Supreme Court–affirmed right to safely terminate a pregnancy.\n\nWhether or not the repeal-and-replace legislation passes this year, these attacks are part of a larger war on women's health that is not likely to abate anytime soon. We must resist this assault. Never mind “America First”—it's time to put women first.","title":"It’s Time to End the War on Women’s Health","origin":"Public Health","image":"https://static.scientificamerican.com/sciam/cache/file/C1DEB68A-DD7C-40C9-A715C0BD5C2DFED1_source.jpg?w=590&h=800&D8646F89-7E8B-4150-8212D9ACA4602802","link":"https://www.scientificamerican.com/article/it-rsquo-s-time-to-end-the-war-on-women-rsquo-s-health/"},{"authors":"Chelsea Harvey, E&E News","pub_date":"May 9, 2019","abstract":"With spring in full bloom, winter’s last stores of snow are beginning to melt. As they do, they’ll release much-needed fresh water into streams or the surrounding soil, fueling plant growth and replenishing drinking resources for communities.\n\nIt’s one of nature’s most important annual rituals.\n\nBut how soon the snow starts to liquefy, and how quickly it disappears, may depend on more than just the outside temperature. Scientists are finding that wildfires in the western United States may alter the landscape in ways that lead to earlier, faster snowmelt.\n\nThat’s a big concern for Western water resources. If the snowpack melts and runs off too quickly, it could cause regional freshwater resources to dry up before the cooler fall temperatures set in, increasing the probability of drought.\n\nBut there’s another concern, as well. Many researchers believe a faster snowmelt and a drier summer landscape may also worsen the fire season in some areas, leading to bigger, hotter blazes.\n\nThe whole process offers the possibility of a climate feedback cycle, said researcher Kelly Gleason of the Desert Research Institute in Nevada. Wildfires lead to faster melting, and faster melting in turn leads to more wildfires.\n\n“Earlier snowmelt is already linked to big fires in the mountains,” she said. “And that those fires could be feeding back and accelerating that snowmelt further—there’s this kind of vicious cycle that’s occurring, or we think is occurring.”\n\nGleason, along with other colleagues from the Desert Research Institute and the University of Nevada, has just published a new study that demonstrates the side effects of wildfires on snow, using a combination of satellite observations from across the West and snow samples from sites in Colorado, Wyoming and Utah.\n\nThe research finds that snow starts to melt about five days earlier in the season after a fire has occurred on the landscape. And based on satellite data from the 1980s onward, it suggests that earlier melting may persist for at least a decade after a fire has occurred.\n\nThis happens for several reasons, according to Gleason.\n\nWildfires tend to clear out the forest canopy, leaving more space for sunlight to get through the trees and warm up the snow. They also leave behind burned leaves and branches, which drop bits of ash and char onto the snow below. These burned bits darken the bright white surface of the snow, causing it to absorb more solar energy.\n\nBetween 1999 and 2018, the researchers found that there’s been about a fourfold increase in the amount of solar energy being absorbed by the Western snowpack after the occurrence of wildfires. They also note that Western forests in the seasonal “snow zone”—that is, forests that also see winter snow cover—are experiencing more wildfires, with the total burned area increasing by about 9% every year.\n\nAltogether, the researchers estimate that about 11% of all Western forests in the snow zone are absorbing more solar energy and melting earlier as a result of wildfires.\n\nThe new study only demonstrates the effects of wildfires on snow—not the other way around. But other research has pointed to potential links between earlier snowmelt and the Western fire season.\n\nAt the annual meeting of the American Geophysical Union in December, University of Maryland doctoral candidate Donal O’Leary presented new research on the timing of snowmelt and the severity of fire seasons in the Western states. He found that the effects are not the same on every kind of landscape. But in most forested areas, early snowmelt is associated with a greater amount of burned area during the fire season.\n\nSuch findings would seem to suggest that, in some Western forests, the effects of wildfire on snowmelt and snowmelt on wildfire may be able to mutually fuel each other.\n\n“I want to say that this is a really important, groundbreaking paper, because it shows us for the first time snowpack feeding back to fire regimes in a very direct, mechanistic way,” said wildfire expert Donald Falk of the University of Arizona, who commented on the new research for E&E News. “They highlight this as a much more highly interactive system than we’ve understood previously.”\n\nIn future research, it may be useful to collect snow samples from a wider variety of landscapes across the Western states, to be sure the same effects hold true throughout the region, Falk noted. But generally, he said, the study “absolutely suggests a kind of local landscape-level feedback, which we really haven’t understood as well.”\n\nAt the same time, the researchers suggest, climate change is likely making the entire process more sensitive.\n\nNumerous studies suggest that rising temperatures are causing the total snowpack area to shrink in the Western states, while snow is also accumulating later in the fall and melting earlier in the spring (Climatewire, Dec. 13, 2018). Models project that this effect will worsen as the climate continues to warm.\n\nCombined with the effects of climate change, the influence of wildfires just makes an already vulnerable snowpack even more sensitive to the sun, Gleason noted.\n\n“Climate change is already melting snowpack and increasing forest fires,” she said. “But then there’s this feedback, which could amplify that impact earlier.”\n\nReprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news atwww.eenews.net.","title":"In “Vicious Cycle,” Snowmelt Fuels Wildfires and Wildfires Melt Snow","origin":"EARTH","image":"https://static.scientificamerican.com/sciam/cache/file/A1A872A3-4640-4A85-8DBB031AF8765DC2_source.jpg?w=590&h=800&1C0C50FA-655A-4002-B79B44E9FFAA6252","link":"https://www.scientificamerican.com/article/in-vicious-cycle-snowmelt-fuels-wildfires-and-wildfires-melt-snow/"},{"authors":"Saad B Omer, Robb Butler","pub_date":"May 9, 2019","abstract":"At the beginning of this year, the World Health Organization (WHO) issued a list of top 10 threats to Global Health. These threats ranged from climate change and non-communicable diseases, to antimicrobial resistance and vaccine hesitancy. The list also included HIV, dengue, weak primary care, fragile and vulnerable settings (e.g. regions with drought and conflict), Ebola, and threat of a global influenza pandemic.\n\nOne underlying theme is the relevance of human behavior to many, if not all, of these threats. For some global health threats, the connection is obvious: non-communicable diseases and their associated behavioral risk factors (i.e. smoking or poor diet), or the reluctance of some parents to vaccinate their children and over-prescription and over-demand of antibiotics—a reason for emergence of antibiotic resistance—have clear behavioral connotations. For many others, the link is less obvious but equally important. For example, human behavior is largely at the center of global climate change and will be at the core of any substantial response to it. Similarly, HIV prevention, avoiding dengue carrying mosquitos, shoring up primary care delivery, and responding to Ebola and influenza outbreaks require modifying or working with human behavior.   \n\nAnd yet, the global health response to these threats lacks a coherent focus on behavioral insights. In recent years, fields such as economics and poverty alleviation have embraced behavioral insights as central to understanding and responding to major challenges in these fields. The 2002 and 2017 Nobel prizes in economics were awarded for research on behavioral economics. While behavioral tools have been used for health promotion for several decades, they are inconsistently included in global health policy-making.\n\nFortunately, there are a few models for incorporating insights from behavioral research into large-scale policy initiatives. One approach, used by many governments and some multi-lateral institutions, is establishing so called “nudge units.” These units use lessons from behavioral economics and psychology to inform public policy.\n\nThe first such unit, officially called the Behavioral Insights Team, was established in the United Kingdom in 2010 and was initially based within the UK Cabinet Office. It now exists as a company co-owned by the Cabinet Office. The Obama administration established a U.S. nudge unit, initially known as the White House Social and Behavioral Sciences Team. This unit has evolved into the Office of Evaluation Science within the General Services Administration. Other countries such as Australia and Singapore have established similar entities. In fact, the concept of promoting behavioral insights-based policy-making has also been adopted by multi-lateral organizations such as the World Bank and the Organization for Economic Co-operation and Development.\n\nWhile not every program initiated by a nudge unit has been equally successful, there are plenty of examples of policy interventions that establish the utility of these units. For example, the UK nudge unit demonstrated that behavioral insights can be used to reduce medication errors, increase commitment to organ donations, and ensure that people show up for their doctor’s appointments.\n\nDr. Tedros Adhanom Ghebreyesus, the WHO Director General who soon after his election to this position promised “a transformed WHO,” has encouraged countries and the WHO’s partners to deliver people-centered care.  Last month, Dr. Tedros (as he prefers to be called) announced a major restructuring of the WHO. He also indicated that “the process of fully implementing the new operating model will take more time.” This period of transition is precisely the right time for establishing a nudge unit at WHO.\n\nWhile there are templates of effective nudge units from various countries and organizations, WHO’s behavioral insights unit will have to reflect its own unique role: First, a WHO nudge unit should support ministries of health of WHO Member States in addition to working with WHO’s core programs—including the newly established health emergencies program.  Second, global health problems are multi-faceted and, therefore, require interdisciplinary solutions. A WHO nudge unit must be staffed by individuals with diverse backgrounds, not just those from the social sciences or medical humanities but also epidemiologists and public health practitioners with behavioral sciences training. Lastly, all initiatives of this unit must be evidence-based and all new interventions must be rigorously evaluated—a tradition upheld by effective nudge units.\n\nAs heath ministers and global health leaders prepare to convene at the World Health Assembly in Geneva this month, the WHO would be well-advised to reflect. The WHO was established to advance human health—and human behavior is a core determinant of human health and well-being. Now is the time for this fact to fully accommodated in its structure and programs.","title":"The World Health Organization Needs to Put Human Behavior at the Center of Its Initiatives","origin":"Behavior & Society","image":"https://static.scientificamerican.com/sciam/cache/file/335E727C-96C0-482B-9650EDE41486F929_source.jpg?w=590&h=800&91F3CB27-E15A-437B-B30046818A09AF5A","link":"https://www.scientificamerican.com/article/the-world-health-organization-needs-to-put-human-behavior-at-the-center-of-its-initiatives/"},{"authors":"Hanneke Weitering, SPACE.com","pub_date":"May 10, 2019","abstract":"Blue Origin is shooting for the moon!\n\nThe private spaceflight company revealed the first life-size mockup of its new lunar lander, named “Blue Moon,” at the Washington Convention Center yesterday (May 9). \n\n“This is an incredible vehicle, and it’s going to the moon,” Blue Origin founder and chief executive Jeff Bezos told a room full of spectators after the curtain dropped to reveal the big, shiny spacecraft. \n\nBlue Moon is designed to carry rovers and other large payloads to the lunar surface, but it could also take astronauts to the moon, said Bezos, who also founded Amazon.com and is the richest person in the world. To modify Blue Moon for a crewed spaceflight, the company would top the spacecraft with an attachable, pressurized ascent vehicle. \n\nBefore launching astronauts to the moon, Blue Origin would first test out the lunar lander with an uncrewed mission, Bezos said. \n\nWhile Bezos did not explicitly state that Blue Origin plans to offer its new vehicle to NASA for the agency’s ambitious push to land American astronauts on the moon in 2024, a newly posted description on the company’s website states that the crew-carrying variant of Blue Moon “has been designed to land an ascent vehicle that will allow us to return Americans to the moon by 2024.” \n\n(Blue Origin representatives had mentioned Blue Moon before, but they hadn’t given us a good look until this week.)\n\nNASA has not yet selected a lander for that historic trip, so Blue Moon may be a contender. Just last month, Lockheed Martin revealed its proposed plans to build a lunar lander. Lockheed’s lander (which has yet to receive a proper name) would be part of the company’s “early Gateway” infrastructure for a sustainable human presence on the moon.\n\nWhether NASA astronauts can really make it to the moon by 2024 is still a subject of debate, but a few things are certain: private companies and other space agencies around the world are gearing up for a new wave of lunar exploration, and Blue Origin has entered the new moon race. \n\nCopyright 2019 Space.com, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.","title":"Blue Origin Unveils “Blue Moon,” Its Big Lunar Lander","origin":"Space","image":"https://static.scientificamerican.com/sciam/cache/file/8B925766-F527-4324-B9A114CE76B766E8_source.jpg?w=590&h=800&55909832-0B53-4FEB-B3C6C74F72D592AA","link":"https://www.scientificamerican.com/article/blue-origin-unveils-blue-moon-its-big-lunar-lander/"},{"authors":"Andrea Thompson","pub_date":"May 10, 2019","abstract":"A rapidly growing body of research shows plastic pollution accumulating around the planet at an alarming rate. Tiny bits known as microplastic result from the breakdown of larger items and have proven especially pervasive, turning up everywhere from oceans to rivers to soil, even hanging in the air we breathe.\n\nAs public awareness grows and concerns mount, cities, states and countries have been looking for ways to curb the release of plastic into the environment and to slow production of the material. Policies have ranged from bans on “single-use” plastics, such as grocery bags or straws, to rules requiring producers help pay for collecting and recycling their products.\n\nThe issue is also gaining traction at the international level. María Fernanda Espinosa Garcés, president of the 73rd session of the United Nations General Assembly, singled it out as a key environmental concern she wants the body to address during her tenure, which began in September. She worked with several countries on launching a campaign in December to raise awareness and encourage phasing out single-use plastics, and has initiated a phase-out of such products at U.N. headquarters. Espinosa spoke with Scientific American in her office about the growing awareness of plastic pollution and the role she sees the U.N. playing in tackling it.\n\n[An edited transcript of the interview follows.]\n\nYou identified protecting the environment as one of the key priorities of your presidency, calling out plastic pollution particularly—why did you single out that issue? \n\nI think that the issue of single-use plastics is perhaps one of the defining factors of the current ocean pollution, but also, it's very much connected to human health and our food security. It is an issue that really is affecting now and today—not only the health of consumers, but also the livelihoods of the hundreds of thousands of people living from coastal resources.\n\nIs plastic pollution a growing concern among member states?\n\nYes, definitely. When I launched the campaign, I teamed up with Norway, Antigua and Barbuda. Then I saw that more and more member states are paying attention to that, at different levels. At the international policy level (during the last U.N. Environment Assembly in Nairobi, Kenya, there were two resolutions that were passed: to fight plastic pollution, and to really address the use of single-use plastics), but there are also efforts at the national level. Today we have 127 countries that have passed legislation in the use of single-use plastic bags. So, I think that we are seeing a very strong response from the international community.\n\nThis is a collective action where you need to bring together civil society, academia, science and the private sector. At the same time, we want to really have the younger generations be very plastic-conscious when they have to take consumer decisions. We wanted to make sure that this wasn't seen as a technical scientific issue, but as a personal issue—as a personal choice. And also, we have teamed up with the private sector. The U.N. has launched an agreement [with plastics producers] to say, “Yes, we are going to make profound changes in the way we produce.” That agreement accounted for about 20 percent of the companies that produce single-use plastics.\n\nSo, there is a world movement, I would call it. But this world movement—I hope it bears fruit very soon. Otherwise we will be in deep trouble.\n\nA number of scientists who study plastic pollution say curbing single-use plastics is a great place to start, but they’re concerned action will end there. Are there things the U.N. can do to help create more systemic change around plastic pollution?\n\nWe know that we are singling out one issue and creating awareness; this is not going to solve the entire ocean crisis, as we call it. It's a huge thing, but we have to start somewhere. We understand that this is one problem, and that it is interconnected to a broader production and consumption pattern. It has to also do with the efforts that the U.N. is doing, and the member states are doing, to combat poverty and inequality—because this has to be part of the equation as well. So, this is not an isolated environmental issue. After 25 years of experience in negotiations in the international arena, I can tell you that the only way to build a safer world—a sustainable world for the future—is about understanding holistically what the situation is. But one of the biggest challenges that we face here at the U.N. is to connect the science and the knowledge with the policy and the action.\n\nThere are still many gaps in our knowledge of the impacts of plastic pollution and the best ways to tackle it. Is there a role for the U.N. to play in terms of gathering the research that has been done, to show where gaps are and where research priorities need to be to focus the world’s efforts?\n\nWhat I think honestly, and without being a scientist in the field, is that we need to put together all the evidence that we have already. And this should be perhaps a task of U.N. Environment: to team up perhaps with a body of authority on this issue—for example, the IUCN [the International Union for the Conservation of Nature]—to bring all the evidence together and come up with very concrete policy recommendations.\n\nLast month, the Nordic countries called for a global agreement to tackle plastic pollution. Do you think there is appetite for that among member nations? And given that coordinated global action on climate change has been slow to materialize, are there ways to learn from that process to inform action on plastic? \n\nOn the plastics front, I think that there is very encouraging news. There are the two resolutions [passed by] the U.N. Environment Assembly, so this is an intergovernmental effort already. There are countries that are really thinking about an international legally binding instrument on plastic pollution, and I see that perhaps there is momentum for progress on that front. I know there are countries that are pushing for that, and as president of the General Assembly, I will be more than supportive. And perhaps this is going to be quicker than the climate negotiations.\n\nI think it's not an easy issue, but it is something where we see that it can be done. And we have so many success stories, starting with the Caribbean initiatives to ban not only single-use plastics but Styrofoam, for example. And if they can do it, the European countries can do it, the other Latin American countries can do it. India is also undertaking a very, very ambitious plan to de-plastify their economy and their society. And when India does something, it has a global effect. So, I think that the commitment is there, the drive is there, and I think the momentum also is there to advancing something perhaps more concrete, more universal, more ambitious.\n\nYou’ve also been working to reduce the use of plastic in U.N. facilities. What changes have been made on that front?\n\nYes, I am personally pushing our own community to really have a U.N. single-use-plastic–free venue—and we really need to walk the talk. It is about going to a progressive process to de-plastify the U.N. I hope that when I leave my role as president of the General Assembly, we will see fundamental changes. We have had, in only seven months of my presidency, already, some very important gains: no more plastic straws at the U.N., and we are progressively getting rid of the single-use plastic bottles. We are having very rapid responses, and we are really changing our own culture. If the U.N. cannot be a single-use-plastic-free organization, then we are in deep trouble. And so, I'm pushing hard.","title":"U.N. General Assembly President Sets Her Sights on Plastic Pollution","origin":"Policy & Ethics","image":"https://static.scientificamerican.com/sciam/cache/file/6DB0BE82-4CCC-4FAE-A1F74A028F922D36_source.jpg?w=590&h=800&2A5ED05D-2E0C-466F-B43A661CBE7B04EA","link":"https://www.scientificamerican.com/article/u-n-general-assembly-president-sets-her-sights-on-plastic-pollution/"}]